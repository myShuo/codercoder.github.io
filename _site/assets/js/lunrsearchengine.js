
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "http://localhost:4000/about",
    "title": "Blog",
    "body": "This is Shuo's blog, i'm a DBA(Database Administrator), we can share and discuss MySQL, MongoDB, Redis and other databases here, also including learning Python, Shell, Golang together.  Subscribe on WechatThank you for your support! Get contact by Wechat.  "
    }, {
    "id": 2,
    "url": "http://localhost:4000/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "http://localhost:4000/",
    "title": "Home",
    "body": "      All Stories:                                                                                                     Tips：MongoDB中的embedded document（嵌套文档）查询注意事项              :       MongoDB查询嵌套的文档时候，字段顺序需要与存储时候的保持一致，否则会查询不到数据. :                                                                               Shuo                13 Nov 2020                                                                                                                                     你真的了解线程池ThreadPoolExecutor吗？              :       背景:                                                                                               29 Jul 2020                                                                                                                                     手记&#8211;InfluxDB使用介绍              :       介绍InfluxDB的基础操作，包括增删、http操作、retention policy、Continuous Queries；influxDB的文件结构；如何运维InfluxDB等方面。:                                                                               Shuo                24 Jul 2020                                                                                                                                     MySQL手记23 &#8212; MySQL运行情况统计小工具mysqltuner              :       mysqltuner，用以统计MySQL实例运行时候的基本情况，会给出基础的一些建议，DBA可进行参考，优化实例配置。:                                                                               Shuo                20 Jul 2020                                                                                                                                     MySQL手记22 &#8212; Tips：不走索引就锁全表数据吗？              :       在RC隔离级别下，没走索引时，可以更新不同的行；RR级别下，没走索引时，不可以更新不同的行。RC级别只锁定加锁的一行，但是提交之后，再进行查询时，可能会获取到其它事务更新的结果，所以为不可重复读；RR级别通过GAP锁，防止其它的session更新所有的行与间隙，从而得到了一个可重复读取的结果。:                                                                               Shuo                12 Jun 2020                                                                                                                                     MySQL手记21 &#8212; MySQL的分库分表              :       MySQL的分库分表是业内常用的数据库拆分手段，能够解决绝大部分的“核心大表”情况。分库分表后，运维难度增大，所以在初期，就要估计好量，并作出一定冗余。对于分库分表的运维，需要有一套完善的平台进行，降低“人肉运维”出错几率。:                                                                               Shuo                11 Jun 2020                                                                                                                                     如何将图片导入到Oracle数据库              :       前言:                                                                                               02 Jun 2020                                                                                                                                     MySQL手记20 &#8212; MySQL Group Replication(MGR组复制)              :       MGR（MySQL Group Replication）是MySQL原生的数据库集群架构，底层使用Paxos协议实现多写、选举等过程，MySQL官方也在不断添加相应的内容，使MGR更加可控稳定。可配合Router、ProxySQL进行使用。:                                                                               Shuo                27 May 2020                                                                                                                                     MySQL手记19 &#8212; MySQL代理工具ProxySQL              :       本文介绍了ProxySQL这一强大且灵活的MySQL代理，需要按需进行测试，包括对于连接的转发是否均衡、节点宕机是否能够将连接发到其它节点、是否能够承受住非常大量的连接、自身的高可用等。数据库加了一层代理，还需要考虑到代理与实例间的延迟，很灵敏的业务是否使用。对于MySQL的集群，需要稳定、灵活且方便的进行管理，包括之前介绍的MySQL高可用集群拓扑结构管理工具Orchestrator，本篇的ProxySQL等，都是集群运维中的一个部分，需要我们谨慎的完成管理。:                                                                               Shuo                24 May 2020                                                                                                                                     好剧推荐2 &#8212; 外星也难民(Solar Opposites)              :       外星也难民(Solar Opposites)，通过动画的方式，简单直接的反应当下社会的情况：包括科技、成长、偏见、信仰、人性、嘲讽、种族等等，通过动画喜剧的方式，把握得很准确，赞！:                                                                               Shuo                16 May 2020                                                                                                                                     MySQL手记18 &#8212; MySQL高可用及复制管理工具Orchestrator              :       Orchestrator是一款提供页面和命令行和MySQL高可用和复制拓扑关系管理工具，Github也使用了Orchestrator进行了MySQL高可用拓扑结构的管理。还能进行主从等切换，只需在页面上进行节点的拖拽，就能完成切换。:                                                                               Shuo                10 May 2020                                                                                                                                     MySQL手记17 &#8212; MySQL的复制Replication              :       MySQL的复制replication有许多的使用方式，例如使用多源复制和延迟复制，进行数据的备份，除了能恢复误操作的数据，还能节省成本；lossless半同步复制，能够让我们的高可用环境数据一致性得以更好的保证，降低了数据不一致的风险等等:                                                                               Shuo                05 May 2020                                               &laquo; Prev       1        2        3        4        5        6      Next &raquo; "
    }, {
    "id": 4,
    "url": "http://localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 5,
    "url": "http://localhost:4000/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %} {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 6,
    "url": "http://localhost:4000/page3/",
    "title": "Home",
    "body": "{% if page. url == “/” %} {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 7,
    "url": "http://localhost:4000/page4/",
    "title": "Home",
    "body": "{% if page. url == “/” %} {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 8,
    "url": "http://localhost:4000/page5/",
    "title": "Home",
    "body": "{% if page. url == “/” %} {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 9,
    "url": "http://localhost:4000/page6/",
    "title": "Home",
    "body": "{% if page. url == “/” %} {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 10,
    "url": "http://localhost:4000/index.php/2020/11/tips-mongodb-find-embedded-document/",
    "title": "Tips：MongoDB中的embedded document（嵌套文档）查询注意事项",
    "body": "2020/11/13 - 背景最近在查询MongoDB中的数据时，发现查询不到数据，查询语句为：db. person. find({“name”:{ last: “Matsumoto”, first: “Yukihiro”}})数据库中数据为： 123456789101112{   _id  : &lt;value&gt;,   name  : {  first  : &lt;string&gt;,  last  : &lt;string&gt; },    // embedded document   birth  : &lt;ISODate&gt;,   death  : &lt;ISODate&gt;,   contribs  : [ &lt;string&gt;, . . . ],              // Array of Strings   awards  : [    {  award  : &lt;string&gt;, year: &lt;number&gt;, by: &lt;string&gt; } // Array of embedded documents    . . .   ]}问题定位交换“name”中的属性顺序，发现必须与数据库中的一致，才能查询到数据～ 官方文档: The name field must match the embedded document exactly. 果然，在查询嵌套的文档时候，字段顺序需要与存储时候的保持一致，否则会查询不到数据。https://docs. mongodb. com/manual/reference/method/db. collection. find/ "
    }, {
    "id": 11,
    "url": "http://localhost:4000/index.php/2020/07/know-threadpoolexecutor/",
    "title": "你真的了解线程池ThreadPoolExecutor吗？",
    "body": "2020/07/29 - 背景: 最近被别人问到有关线程池的问题，自己没有答上来，自己觉得之前还是比较了解线程池的，所以又重新学习了一下这块内容，然后记录一下与大家分享。 从两个问题说起:  线程池线程数增加过程是怎样的？ 如果线程池线程运行过程中抛异常了，线程池怎么处理该异常线程（是否抛异常、是否回收线程再次利用）Part 1:: 线程池线程增加逻辑: 参考图： 如果线程池队列设置为无限大，最大线程数还有用吗？: 12从图中可以得知，当线程池队列设置为无限大的时候，最大线程数是没有用的，线程池的活跃线程最大就为核心线程数大小。JDK线程池为什么要实现成先放队列然后在增加到最大线程数，为什么不是像Tomcat线程池实现一样先增大到最大线程数在放队列?:  自我感觉没有好坏之分，可能适用场景不一样。如果不能容忍延迟，期望应用能尽快的为用户提供服务，就选tomcat实现的，如果能容忍一定的延迟来换取性能上的提升就采用JDK方式。 而且也区分应用是CPU密集型还是IO密集型，如果是CPU密集型，是需要线程长时间进行复杂运算，增加线程会造成线程上下文切换频繁，处理速度反而会降低。如果是IO密集型，线程大部分时间是在等待IO读取和写入，增加线程可以提高并发度，处理更多任务。 还有一个原因可能就是创建线程addWorker的是时候是需要获取mainLock这个全局锁，影响并发效率，先放队列时候使用到同步队列可以做为一个缓冲。上面的是自我的几点理解，如果大家有觉得有更好的理解的，希望补充。 如果想要先增加线程到最大之后才放队列怎么做？: 两种做法： 调整核心线程数大小和最大线程数大小一样 就是基于ArrayBlockingQueue实现自己的BlockingQueue，重写其中的offer方法，在里面增加判断如果当前线程数小于最大线程数，则返回false，否则就执行队列自身的offer方法。Part 2: 线程池线程抛异常了会打印错误日志吗?: 线程池执行任务分为两种方式，一种execute，一种submit方式：  如果是execute方式，则会在java. util. concurrent. ThreadPoolExecutor#runWorker中会抛出异常在java. lang. ThreadGroup#uncaughtException中会将异常打印到控制台 如果是通过submit方式提交，则不会有异常打印，看下submit代码：java. util. concurrent. AbstractExecutorService#submit task被包装成一个FutureTask执行，在java. util. concurrent. FutureTask#run方法里看到异常被捕获并没有抛出，而是设置到了对象中一个字段中线程池线程抛异常了线程会被回收吗?: 答案是线程会被remove掉，然后重新创建一个新的线程加入到线程池查看java. util. concurrent. ThreadPoolExecutor#runWorker代码，发现如果抛出异常时候，最后走到java. util. concurrent. ThreadPoolExecutor#processWorkerExit方法，核心代码如下图 如果想要获取到异常怎么办?: 两种做法： 通过submit方式提交时候，future. get时候会抛出异常 通过实现线程池java. util. concurrent. ThreadPoolExecutor#afterExecute方式，可以获得到异常信息为什么线程抛异常被移除之后又会创建一个新的线程加入？: 12个人理解：可能是为了避免线程池还有任务但是线程异常被移除了之后没有线程在工作了，所以又新创建了一个新的线程到线程池。"
    }, {
    "id": 12,
    "url": "http://localhost:4000/index.php/2020/07/note-influxdb-introduction/",
    "title": "手记&#8211;InfluxDB使用介绍",
    "body": "2020/07/24 - 话说上次说把设备状态信息上报到influxDB进行存储，即存储设备的监控信息，既然说了介绍InfluxDB的使用，那这次就按数据库使用维护的角度，介绍下时序数据库InfluxDB。 通常说到数据库会说到库、表、行，这在influxDB中对应database、measurement、point，当然还有时序数据特有的timestamp，以及过期策略：Retention Policy。此外，还有其特别的结构： Point：Series + timestamp Series：按照同一个database中，Series = retention policy + measument + tag set相同，即为相同series Shard：在我们设定Retention Policy的时候，往往就会看到shard关键字，其体现为：一个retention policy下，会根据其设定，拆分为很多个部分，而这些部分，则为shard。 InfluxDB的存储引擎为TSM（从LSM+timestamp演变），每一个SHARD，都对应一个TSM存储引擎，有独立的cache、wal、tsm file。（LSM树结构后续再说，又有下次的主题了:grin:）https://www. influxdata. com/blog/new-storage-engine-time-structured-merge-tree/https://docs. influxdata. com/influxdb/v1. 8/concepts/storage_engine/ 一、常见操作上次设备监控上报的时候 (文末公众号：涂鸦玩法2 — 设备状态存储展示)，简单介绍了如下的SQL： 123456789101112131415161718192021$ influx -host 127. 0. 0. 1 -port 8089 -username admin -password 123421Connected to http://127. 0. 0. 1:8089 version 1. 8. 1InfluxDB shell version: 1. 8. 1​&gt; show databases;name: databasesname----_internalwstestdb​&gt; use wstestdbUsing database wstestdb​&gt; select time,pir,dev_id from pir_status limit 3;name: pir_statustime        pir dev_id----        --- ------1594810825095426778 0  z{&amp;#140;y{_Z1594810835293097585 0  z{&amp;#140;y{_Z1594810845430362859 1  z{&amp;#140;y{_Z此外，influxDB本身也支持http POST的方式进行数据的操作。例如：插入： 12curl -i -XPOST 'http://localhost:8083/write?db=mydb' --data-binary 'cpu_load_short,host=server02 value=0. 67查询： 12curl -GET 'http://localhost:8086/query?pretty=true' --data-urlencode  db=mydb  --data-urlencode  q=SELECT value FROM cpu_load_short WHERE region='us' 对于运维人员，需要额外关注一些其它信息。 二、基础运维2. 1 Retention Policy 数据保留策略: （1）创建： 12create RETENTION POLICY  wstestdb_1d  ON  wstestdb  DURATION 1d REPLICATION 1 SHARD DURATION 1d ;这里可以看到上部分提到的SHARD DURATION，在一个保留策略里，需要设定好过期的时间，还有SHARD的周期，influxDB会按照这个周期拆分、过期数据文件。 （2）修改： 1234567891011121314&gt; show retention policiesname  duration shardGroupDuration replicaN default----  -------- ------------------ -------- -------autogen 0s    168h0m0s      1    true​&gt; alter RETENTION POLICY  autogen  ON  wstestdb  DURATION 200w REPLICATION 1 SHARD DURATION 1d DEFAULT&gt; show retention policiesname  duration  shardGroupDuration replicaN default----  --------  ------------------ -------- -------autogen 33600h0m0s 24h0m0s      1    true​通常生产环境中，我们会针对不同类型的measurement，采用不同的retention policy，例如：精度高的表保留3个月，精度低的表保留3年等。 2. 2 持续查询 Continuous Queries: InfluxDB深知自己使用的环境，例如在很久以前的数据，大部分用户只关注类似平均值、最大最小值等的情况，而历史的大量数据，会使成本大幅度提高。此时，就出现了持续查询： 12CREATE continuous query cq_30 ON  mydb  RESAMPLE EVERY 15m FOR 60m BEGIN select mean(value) into mean_value from cpu_load_short group by time(30m) END即把cpu_load_short表的每15分钟平均值，存放在一张新表mean_value中。 这样，Retention Policy加上Continuous Queries，可以在精度和持续性上达到一个平衡。 三、InfluxDB的文件3. 1 文件目录分布: InfluxDB的文件结构较为简单（上次说到，在配置文件中的不同板块进行配置）： data：数据文件目录 meta：数据库元信息 wal：Write Ahead Log目录重点关注数据文件目录，更便于我们去理解和使用InfluxDB。 3. 2 数据目录: 数据目录下，每一个database，分为单独的目录；在不同的database下，不同的retention policy，又分别位于不同的目录下： 特别注意，“_series”目录，用以存放series索引： （1）必须在配置中限制series的数目，防止大量的series导致OOM的情况 （2）当series数据太大时，需要及时处理 3. 3 Retention Policy与SHARD在文件上的体现: 查看_interval库的retention policies： 12345678&gt; use _internalUsing database _internal&gt; show retention policiesname  duration shardGroupDuration replicaN default----  -------- ------------------ -------- -------monitor 168h0m0s 24h0m0s      1    true对应的文件目录： 可以看出，文件是按照每24h进行分割的，即Retention Policy中的SHARD DURATION的大小进行，同样，在168h后，将会进行过期处理。 四、InfluxDB的配置4. 1 基础配置: 通常我们会修改如下几项： 占用内存的大小：cache-max-memory-size = “2g” 并发查询数：max-concurrent-queries = 1000 慢查询阈值：log-queries-after = “3s” metadata/数据文件地址：[meta]、[data]中的dir 端口地址：bind-address 4. 2 业务实用性配置: 根据前三部分的介绍，还需关注： series相关配置： 例如：max-series-per-database、max-select-series TSM引擎： 例如：compact-full-write-cold-duration SHARD相关： 例如：cache-snapshot-write-cold-duration、compact-full-write-cold-duration timeout相关： 例如：连接超时、查询超时等等 同所有关系型数据库一样，数据库的配置，需要根据业务的使用场景进行适时的调整和优化，已得到更融合的体系。 欢迎关注公众号：朔的话： "
    }, {
    "id": 13,
    "url": "http://localhost:4000/index.php/2020/07/mysql-note-23-mysqltuner/",
    "title": "MySQL手记23 &#8212; MySQL运行情况统计小工具mysqltuner",
    "body": "2020/07/20 - 无意中发现一个小工具，perl语言开发的mysqltuner. pl，可以用来展示MySQL实例的状态： Github地址：https://github. com/major/MySQLTuner-perl 运行结果如下图所示，运行结果将会按照分类进行分块展示，后文将进行分析讨论： 测试情况下面展示我在测试环境MySQL8. 0的情况： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120&gt;&gt; MySQLTuner 1. 7. 19 - Major Hayden &lt;major@mhtx. net&gt; &gt;&gt; Bug reports, feature requests, and downloads at http://mysqltuner. com/ &gt;&gt; Run with '--help' for additional options and output filtering​[--] Skipped version check for MySQLTuner script[--] Performing tests on 127. 0. 0. 1:4406[OK] Logged in using credentials passed on the command lineArgument    isn't numeric in numeric ge (&gt;=) at mysqltuner. pl line 302 (#1)  (W numeric) The indicated string was fed as an argument to an operator  that expected a numeric value instead.  If you're fortunate the message  will identify which operator was so unfortunate. ​[OK] Currently running supported MySQL version 8. 0. 17[OK] Operating on 64-bit architecture​-------- Log file Recommendations ------------------------------------------------------------------[!!] Log file /tmp/4406-error. log doesn't exist​-------- Storage Engine Statistics -----------------------------------------------------------------[--] Status: +ARCHIVE +BLACKHOLE +CSV -FEDERATED +InnoDB +MEMORY +MRG_MYISAM +MyISAM +PERFORMANCE_SCHEMA[--] Data in InnoDB tables: 146. 6M (Tables: 1889)[OK] Total fragmented tables: 0​-------- Analysis Performance Metrics --------------------------------------------------------------[--] innodb_stats_on_metadata: OFF[OK] No stat updates during querying INFORMATION_SCHEMA. ​-------- Security Recommendations ------------------------------------------------------------------[--] Skipped due to unsupported feature for MySQL 8​-------- CVE Security Recommendations --------------------------------------------------------------[--] Skipped due to --cvefile option undefined​-------- Performance Metrics -----------------------------------------------------------------------[--] Up for: 2d 19h 43m 16s (62K q [0. 257 qps], 276 conn, TX: 23M, RX: 10M)[--] Reads / Writes: 98% / 2%[--] Binary logging is enabled (GTID MODE: ON)[--] Physical Memory   : 8. 0G[--] Max MySQL memory  : 12. 8G[--] Other process memory: 0B[--] Total buffers: 784. 0M global + 24. 6M per thread (500 max threads)[--] P_S Max memory usage: 72B[--] Galera GCache Max memory usage: 0B[OK] Maximum reached memory usage: 857. 9M (10. 47% of installed RAM)[!!] Maximum possible memory usage: 12. 8G (160. 01% of installed RAM)[!!] Overall possible memory usage with other process exceeded memory[OK] Slow queries: 2% (1K/62K)[OK] Highest usage of available connections: 0% (3/500)[!!] Aborted connections: 14. 86% (41/276)[--] Query cache have been removed in MySQL 8[OK] Sorts requiring temporary tables: 0% (0 temp sorts / 1K sorts)[!!] Joins performed without indexes: 3013[OK] Temporary tables created on disk: 0% (0 on disk / 4K total)[OK] Thread cache hit rate: 98% (3 created / 276 connections)[OK] Table cache hit rate: 61% (2K open / 3K opened)[!!] table_definition_cache(2000) is lower than number of tables(2194) [OK] Open file limit used: 0% (39/1M)[OK] Table locks acquired immediately: 100% (480 immediate / 480 locks)[OK] Binlog cache memory access: 100. 00% (4255 Memory / 4255 Total)​-------- Performance schema ------------------------------------------------------------------------[--] Memory used by P_S: 72B[--] Sys schema is installed. ​-------- ThreadPool Metrics ------------------------------------------------------------------------[--] ThreadPool stat is disabled. ​-------- MyISAM Metrics ----------------------------------------------------------------------------[--] MyISAM Metrics are disabled on last MySQL versions. ​-------- InnoDB Metrics ----------------------------------------------------------------------------[--] InnoDB is enabled. [--] InnoDB Thread Concurrency: 0[OK] InnoDB File per table is activated[OK] InnoDB buffer pool / data size: 512. 0M/146. 6M[!!] Ratio InnoDB log file size / InnoDB Buffer pool size (18. 75 %): 48. 0M * 2/512. 0M should be equal to 25%[OK] InnoDB buffer pool instances: 1[--] Number of InnoDB Buffer Pool Chunk : 4 for 1 Buffer Pool Instance(s)[OK] Innodb_buffer_pool_size aligned with Innodb_buffer_pool_chunk_size &amp; Innodb_buffer_pool_instances[OK] InnoDB Read buffer efficiency: 100. 00% (123128483 hits/ 123129674 total)[OK] InnoDB Write log efficiency: 92. 19% (2024330 hits/ 2195892 total)[OK] InnoDB log waits: 0. 00% (0 waits / 171562 writes)​-------- AriaDB Metrics ----------------------------------------------------------------------------[--] AriaDB is disabled. ​-------- TokuDB Metrics ----------------------------------------------------------------------------[--] TokuDB is disabled. ​-------- XtraDB Metrics ----------------------------------------------------------------------------[--] XtraDB is disabled. ​-------- Galera Metrics ----------------------------------------------------------------------------[--] Galera is disabled. ​-------- Replication Metrics -----------------------------------------------------------------------[--] Galera Synchronous replication: NO[--] No replication slave(s) for this server. [--] Binlog format: ROW[--] XA support enabled: ON[--] Semi synchronous replication Master: Not Activated[--] Semi synchronous replication Slave: Not Activated[--] This is a standalone server​-------- Recommendations ---------------------------------------------------------------------------General recommendations:Reduce your overall MySQL memory footprint for system stabilityDedicate this server to your database for highest performance. Reduce or eliminate unclosed connections and network issuesWe will suggest raising the 'join_buffer_size' until JOINs not using indexes are found. See https://dev. mysql. com/doc/internals/en/join-buffer-size. html       (specially the conclusions at the bottom of the page). Before changing innodb_log_file_size and/or innodb_log_files_in_group read this: https://bit. ly/2TcGgtUVariables to adjust: *** MySQL's maximum memory usage is dangerously high *** *** Add RAM before increasing MySQL buffer variables ***  join_buffer_size (&gt; 8. 0M, or always use indexes with JOINs)  table_definition_cache(2000) &gt; 2194 or -1 (autosizing if supported)  innodb_log_file_size should be (=64M) if possible, so InnoDB total log files size equals to 25% of buffer pool size. 结果分析分析结果分为如下几个部分： 1. 实例基本信息: 版本、实例系统配置简介等 2. Storage Engine Statistics: 存储引擎统计信息 Innodb表的数目、总大小 3. Analysis Performance Metrics: innodb_stats_on_metadata开启情况 4. Performance Metrics: 性能相关的统计信息： uptime、QPS、读写操作情况 binlog是否开启？ 内存情况、buffer缓存情况 慢查比例 连接情况 临时表创建情况 open files 获取锁等待的情况（乍眼一看，指标和我们平时看的MySQL监控大同小异，PMM提供的面板中，也是这些个指标：MySQL手记9 — Percona Monitoring Management（PMM监控）] 5. Performance schema: P_S使用内存的情况 6. ThreadPool Metrics: 是否打开线程池 7. MyISAM Metrics、AriaDB Metrics、TokuDB Metrics、XtraDB Metrics、Galera Metrics: 各种存储引擎情况 8. InnoDB Metrics: InnoDB情况 是否开启InnoDB File per table InnoDB buffer pool / data size InnoDB buffer pool instances数目 InnoDB读写效率 9. Replication Metrics：: 复制情况： Binlog format: ROW Slave情况 是否半同步 10. Recommendation:: Log file Recommendations 例如本例中提示：Log file /tmp/4406-error. log doesn’t exist Security Recommendations 由于我使用的是MySQL8. 0版本，所以本项不支持，跳过 CVE Security Recommendations Skipped due to –cvefile option undefined 汇总的Recommendation：: 降低MySQL内存使用率，以提高系统稳定性 由于我的实例为单实例，所以建议组建高可用集群 减少或消除未封闭的连接和网络问题 建议调整的参数：: Variables to adjust: *** MySQL’s maximum memory usage is dangerously high ***MySQL实例可用的内存，配置太高，可能会发生OOM *** Add RAM before increasing MySQL buffer variables ***（在调高buffer相关配置前，先升级内存） join_buffer_size (&gt; 8. 0M, or always use indexes with JOINs) table_definition_cache(2000) &gt; 2194 or -1 (autosizing if supported) innodb_log_file_size should be (=64M) if possible, so InnoDB total log files size equals to 25% of buffer pool size. ​ ps. 这个项目github上的一个FAQ:) 欢迎关注公众号：朔的话： "
    }, {
    "id": 14,
    "url": "http://localhost:4000/index.php/2020/06/mysql-note-22-tips-lock-status-when-not-using-index/",
    "title": "MySQL手记22 &#8212; Tips：不走索引就锁全表数据吗？",
    "body": "2020/06/12 - 今天和小伙伴讨论到： 如果MySQL的加锁，没有走索引，走全表扫描的话，那么加锁是把所有的数据行都锁住，还是只锁住符合where条件的数据？ 确实，我们在工作中经常提醒开发人员，让SQL都能走索引，以使得加锁的范围越小越好。所以这个问题，还需要看一个方面：事务的隔离级别。 Repeatable_Read隔离级别表结构：name字段没有索引，在name字段上进行update操作： 123456789101112131415161718CREATE TABLE if not exists `test3` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(30) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8​mysql&amp;gt; select * from test3;+----+-----------+| id | name   |+----+-----------+| 1 | aaa    || 2 | bbb    || 3 | ccc333ccc || 4 | ddd    || 5 | eee    |+----+-----------+5 rows in set (0. 00 sec)开启一个事务，执行update进行加锁： 1234567mysql&amp;gt; begin;Query OK, 0 rows affected (0. 01 sec)​​mysql&amp;gt; update test3 set name='abc' where name='ccc333ccc';Query OK, 1 row affected (0. 02 sec)查看当前加锁的情况： 123456789101112131415161718192021222324252627root:information_schema&amp;gt; select * from INNODB_TRX \G*************************** 1. row ***************************          trx_id: 458026         trx_state: RUNNING        trx_started: 2020-06-12 05:00:40   trx_requested_lock_id: NULL     trx_wait_started: NULL        trx_weight: 3    trx_mysql_thread_id: 972         trx_query: NULL    trx_operation_state: NULL     trx_tables_in_use: 0     trx_tables_locked: 1     trx_lock_structs: 2   trx_lock_memory_bytes: 1136      trx_rows_locked: 6     trx_rows_modified: 1  trx_concurrency_tickets: 0    trx_isolation_level: REPEATABLE READ     trx_unique_checks: 1  trx_foreign_key_checks: 1trx_last_foreign_key_error: NULLtrx_adaptive_hash_latched: 0trx_adaptive_hash_timeout: 0     trx_is_read_only: 0trx_autocommit_non_locking: 0或者可使用**show engine innodb status **查看： 12345678910------------TRANSACTIONS------------Trx id counter 458027Purge done for trx's n:o &amp;lt; 458010 undo n:o begin;Query OK, 0 rows affected (0. 00 sec)​root:wstestdb&amp;gt; update test3 set name----等待第二个事务执行后，处于等待状态，此时查看加锁的情况： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253mysql&amp;gt; select * from information_schema. INNODB_TRX \G*************************** 1. row ***************************          trx_id: 458027         trx_state: LOCK WAIT        trx_started: 2020-06-12 05:10:27   trx_requested_lock_id: 458027:77:3:2     trx_wait_started: 2020-06-12 05:10:27        trx_weight: 2    trx_mysql_thread_id: 993         trx_query: update test3 set name='abc' where name='eee'    trx_operation_state: starting index read     trx_tables_in_use: 1     trx_tables_locked: 1     trx_lock_structs: 2   trx_lock_memory_bytes: 1136      trx_rows_locked: 1     trx_rows_modified: 0  trx_concurrency_tickets: 0    trx_isolation_level: REPEATABLE READ     trx_unique_checks: 1  trx_foreign_key_checks: 1trx_last_foreign_key_error: NULLtrx_adaptive_hash_latched: 0trx_adaptive_hash_timeout: 0     trx_is_read_only: 0trx_autocommit_non_locking: 0*************************** 2. row ***************************          trx_id: 458026         trx_state: RUNNING        trx_started: 2020-06-12 05:00:40   trx_requested_lock_id: NULL     trx_wait_started: NULL        trx_weight: 3    trx_mysql_thread_id: 972         trx_query: select * from information_schema. INNODB_TRX    trx_operation_state: NULL     trx_tables_in_use: 0     trx_tables_locked: 1     trx_lock_structs: 2   trx_lock_memory_bytes: 1136      trx_rows_locked: 6     trx_rows_modified: 1  trx_concurrency_tickets: 0    trx_isolation_level: REPEATABLE READ     trx_unique_checks: 1  trx_foreign_key_checks: 1trx_last_foreign_key_error: NULLtrx_adaptive_hash_latched: 0trx_adaptive_hash_timeout: 0     trx_is_read_only: 0trx_autocommit_non_locking: 02 rows in set (0. 01 sec)第二个事务的状态显示：trx_state: LOCK WAIT，即由于不能马上获得锁，所以需要等待。 结果二：: 即使第二个事务中，update的是不同的行，但是由于name字段上没有索引，所以InnoDB需要对所有的行及间隙上锁，所以会出现“LOCK WAIT”的状态。 Read-Committed隔离级别由于RC隔离级别是没有GAP锁的，所以在进行加锁的时候，只会对于符合条件的数据进行加锁： 1234567mysql&amp;gt; begin;Query OK, 0 rows affected (0. 00 sec)​​mysql&amp;gt; update test3 set name='abc' where name='ccc333ccc';Query OK, 1 row affected (0. 00 sec)查看此时的加锁情况： 12345678910111213141516171819202122232425262728mysql&amp;gt; select * from information_schema. INNODB_TRX \G*************************** 1. row ***************************          trx_id: 458034         trx_state: RUNNING        trx_started: 2020-06-12 06:15:58   trx_requested_lock_id: NULL     trx_wait_started: NULL        trx_weight: 3    trx_mysql_thread_id: 998         trx_query: select * from information_schema. INNODB_TRX    trx_operation_state: NULL     trx_tables_in_use: 0     trx_tables_locked: 1     trx_lock_structs: 2   trx_lock_memory_bytes: 1136      trx_rows_locked: 1     trx_rows_modified: 1  trx_concurrency_tickets: 0    trx_isolation_level: READ COMMITTED     trx_unique_checks: 1  trx_foreign_key_checks: 1trx_last_foreign_key_error: NULLtrx_adaptive_hash_latched: 0trx_adaptive_hash_timeout: 0     trx_is_read_only: 0trx_autocommit_non_locking: 01 row in set (0. 01 sec)第二个session执行： 12345678root:wstestdb&amp;gt; begin;Query OK, 0 rows affected (0. 00 sec)​​root:wstestdb&amp;gt; update test3 set name='abc' where name='eee';Query OK, 1 row affected (0. 01 sec)​结果一：: 可以看出，第二个session也是能够成功执行的，因为更改的是不同的行。 查看加锁的情况： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253mysql&amp;gt; select * from information_schema. INNODB_TRX \G*************************** 1. row ***************************          trx_id: 458035         trx_state: RUNNING        trx_started: 2020-06-12 06:16:22   trx_requested_lock_id: NULL     trx_wait_started: NULL        trx_weight: 3    trx_mysql_thread_id: 997         trx_query: NULL    trx_operation_state: NULL     trx_tables_in_use: 0     trx_tables_locked: 1     trx_lock_structs: 2   trx_lock_memory_bytes: 1136      trx_rows_locked: 2     trx_rows_modified: 1  trx_concurrency_tickets: 0    trx_isolation_level: READ COMMITTED     trx_unique_checks: 1  trx_foreign_key_checks: 1trx_last_foreign_key_error: NULLtrx_adaptive_hash_latched: 0trx_adaptive_hash_timeout: 0     trx_is_read_only: 0trx_autocommit_non_locking: 0*************************** 2. row ***************************          trx_id: 458034         trx_state: RUNNING        trx_started: 2020-06-12 06:15:58   trx_requested_lock_id: NULL     trx_wait_started: NULL        trx_weight: 3    trx_mysql_thread_id: 998         trx_query: select * from information_schema. INNODB_TRX    trx_operation_state: NULL     trx_tables_in_use: 0     trx_tables_locked: 1     trx_lock_structs: 2   trx_lock_memory_bytes: 1136      trx_rows_locked: 1     trx_rows_modified: 1  trx_concurrency_tickets: 0    trx_isolation_level: READ COMMITTED     trx_unique_checks: 1  trx_foreign_key_checks: 1trx_last_foreign_key_error: NULLtrx_adaptive_hash_latched: 0trx_adaptive_hash_timeout: 0     trx_is_read_only: 0trx_autocommit_non_locking: 02 rows in set (0. 01 sec)小结这个例子也是“不可重复读”的一个体现： RC：没走索引时，可以更新不同的行 RR：没走索引时，不可以更新不同的行 在RC级别下，虽然只更新了一行数据update test3 set name=’abc’ where name=’ccc333ccc’;，但是提交之后，再进行查询时，得到name=‘eee’的这行数据也被更新了。 而RR级别通过GAP锁，防止其它的session更新所有的行与间隙，从而得到了一个可重复读取的结果。 "
    }, {
    "id": 15,
    "url": "http://localhost:4000/index.php/2020/06/mysql-note-21-mysql-sharding-table/",
    "title": "MySQL手记21 &#8212; MySQL的分库分表",
    "body": "2020/06/11 - 一、基本情况随着数据量的增多，往往带来数据库的负载加大，有时甚至会影响线上的正常业务，在此情况下，常有几种解决方案：数据归档、配置升级、数据拆分。对于数据库表的拆分，又分为：垂直拆分、水平拆分。 垂直拆分：将不同业务需要访问到的库，分在不同的数据库实例下，以降低单个实例的负载 水平拆分：常见两种方案：分库不分表、分库加分表（图片来源https://www. digitalocean. com/community/tutorials/understanding-database-sharding） 数据归档：对于数据量或QPS较为稳定，不会“爆棚式”增长的库表，还有可能是公司内部难以推动或者关联较多导致拆分的环境，而可以采用的临时解决方案。 升级配置：将数据库所在的硬件设施进行升级，以便于更好的支撑当前的数据环境​ 由于数据归档、升级配置两种方案的思路很简单，不过多介绍，这里就说一些注意事项：（1）数据下游若下游有数据订阅，或者离线的任务，那么： 数据归档：部分业务可能会存在离线任务，那么离线任务的时间需要和归档时间错开，防止造成较高的负载； 订阅任务：需要判断是否需要过滤归档产生的DELETE语句（归档产生的DELETE的量可能会随数据量的大小，而变得很大，影响订阅的通道，造成订阅阻塞或者延迟较大的影响） 实例配置升级：大部分情况，进行实例配置的升级，涉及到新老实例的切换，会影响binlog的位点，在切换后，更改订阅的binlog的位点信息所以下游有订阅任务时，需要进行调整切换的时间，应错开离线、归档任务 （2）数据归档注意事项查阅：MySQL手记11 — MySQL归档工具：pt-archiver（3）配置升级可参考：MySQL手记14 — 数据迁移注意事项 二、数据库拆分2. 1 垂直拆分: 将不同业务所需要访问的库表进行拆分，不同的业务访问不同的库表，访问其他业务的数据库表，则通过程序接口调用方式进行。 2. 2 水平拆分: 1. 仅分库: 例如，应用A访问db1库的db1表，此时将db1拆分为16个库：db1_0 ~ db1_15，每个库中仅有一个同名表tb1。应用则通过分库的规则访问到不同的数据库实例。 2. 分库分表: 例如，应用A访问db-1，此时将db1拆分为16个库16个表：db1_0 ~ db1_15，每个数据库中有16个表：tb0 ~ tb15。应用则通过分库分表的规则访问到不同的数据库实例下的不同表。 3. 仅分库 or 分库分表？: （1）数据量、QPS是否会大幅度上升?: 数据量、QPS上升，业务量飞速上涨，以至于实例升配等的方案很有可能在短期内出现硬件的瓶颈，所以需要提前将数据库表进行拆分。（数据库巡检：通常我们会对数据库进行巡检。每个一段时间，统计各个数据库大表信息，讨论是否需要进行拆分处理。） （2）当前是否出现查询缓慢的瓶颈？: 对于出现慢查的环境，DBA因首先进行SQL或者结构的优化，尽量降低慢查数，使当前的配置能够尽可能支撑更多的查询。 （3）业务对于响应速度的要求？: 部分边缘的业务，哪怕是数据量很大，但是由于其对数据库的响应速度要求不高，需要根据需求判断。 三、分表分库3. 1 拆分前准备工作: 对于数据库来说，做拆分之前一定要做足充分的准备，再拆分迁移后，分表分库的环境是很难进行回滚的。（1）分库分表算法：先按库取模，再按照表取模按照总表的数目取模… 计算需要拆分为多少个库表，评估业务量，根据目前环境中的QPS与配置的比例，从而得到需要的实例的数目. 例如： 业务量为最大20万的QPS（其中读、写各占一半），当前环境16核64GB的实例QPS为2万：可拆分为16个库，每个库一个16核64GB实例，这样，最终每个实例的最大QPS的量为20万/16 同时，采用读写分离的方式，添加多个只读节点，分散主库压力 （2）选取分片键 谨慎选择分片键，使业务尽量为分片键上的等值查询。 分片键上的范围查询（应避免） （3）分表的数目 &amp; 运维复杂度分库分表，意味着更高的运维复杂度。各种对于子表的操作，都需要完善的流程进行。 （4）子表上的结构变更？怎么验证？（5）雪花算法生成整型递增主键（6）数据下游 订阅、同步任务 需要接入多个数据源 离线任务 从不同的数据源进行拉取，再聚合 3. 2 数据同步: （1）历史数据迁移 按照分表分库的规则，使用数据库中间价，将数据分批次迁移到目标端。应用常用的分表分库方案有：Sharding-JDBC，对于数据库分库分表中间件，可以用同一产品的分支：Sharding-Proxy。该项目从4. 0版本开始，已经收录为了Apache的项目，start的数据也在升高（https://github. com/apache/shardingsphere）。 对于Sharding-Proxy，配置数据库分表分库的路由，即可将数据按规则分发到对应的分表中，并且兼容基本的MySQL语法。 全量同步，可直接将数据dump为sql文件，再通过Sharding-Proxy进行回放。 （2）增量同步 在全量数据迁移时，记录下binlog位点，然后从该位点开始进行增量同步，使用binlog订阅的方式，将源端的binlog在目标端回放。 对于源端的数据库配置注意事项，例如：binlog_format=ROW、binlog_row_image=full等的配置项，可参照：http://codercoder. cn/index. php/2020/04/mysql-note-14-attention-when-migrating-data/ 对于binlog的同步： （1）可在源端订阅binlog，解析得到的SQL，在目标端执行 （2）使用同步工具，例如：阿里开源的binlog订阅和消费组件—-canal, MySQL binlog 增量订阅&amp;消费组件；或是阿里的另一个开源项目otter,分布式数据库同步系统（ps. 对比了阿里云、微软云、AWS、腾讯云的数据同步服务，其实哪怕是在商业的解决方案里，阿里云的数据同步方案是灵活性最高，并且兼容性最好的） 3. 3 数据校验: 在数据同步后，需要对数据进行校验，常用的方式有： a. 按照主键，分批次逐行对比（效率低，结果精确） b. 对比源端和目标端的数据行数 总结MySQL的分库分表死活业内常用的数据库拆分手段，能够解决绝大部分的“核心大表”情况。但是分库分表后，若需要进行再次拆分，运维难度就会很大，所以在初期制定时，就要估计好数据量、QPS等的情况，并作出一定冗余。 此外，对于分库分表的运维，由于其复杂度增大，也需要有一套完善的平台进行，降低“人肉运维”出错几率。 若出现了分库分表也支撑不起的业务，那么就可以考虑其它类型的数据库，近年来很火热的分布式数据库不失为一个很好的选择。 后续将会详细介绍“数据同步”、“数据库代理Sharding-Proxy”等内容，敬请期待。 欢迎关注公众号：朔的话： "
    }, {
    "id": 16,
    "url": "http://localhost:4000/index.php/2020/06/pic_to_db/",
    "title": "如何将图片导入到Oracle数据库",
    "body": "2020/06/02 - 前言: 主要介绍使用Oracle函数包dbms_lob如何将图片存到数据库里面。关于函数的更多用法可以阅读官方文档(https://docs. oracle. com/cd/E11882_01/timesten. 112/e21645/d_lob. htm#TTPLP600) 建立测试表: 123456789101112131415161718192021222324252627282930promptprompt Creating table T_PIC_1prompt =============================promptcreate table T_PIC_1( ID      NUMBER(10) not null, ZP       BLOB);comment on table T_PIC_1 is '测试数据表';comment on column T_PIC_1. ID is '照片唯一ID ';comment on column T_PIC_1. ZP is '照片';-- alter table T_PIC_1 add constraint PK_T_PIC_1 primary key (ID);promptprompt Creating sequence SEQ_T_PIC_1prompt ================================promptcreate sequence SEQ_T_PIC_1minvalue 1maxvalue 9999999999999999999999999999start with 1increment by 1cache 200;图片路径: 123456[oracle@db-Bbo8Jg1B zp]$ pwd/home/oracle/zp[oracle@db-Bbo8Jg1B zp]$ ls -lrt-rw-r--r-- 1 root root 42775 Jun 2 13:56 20200602135647. jpg-rw-r--r-- 1 root root 44189 Jun 2 13:59 20200602135648. jpg建立逻辑目录: 1234SQL&gt; create or replace directory IMAGES as '/home/oracle/zp';SQL&gt; grant read,write on directory IMAGES to u_test1;入库方式: 特定命名规则循环入库: 1234567891011121314151617181920212223242526272829[oracle@db-Bbo8Jg1B ~]$ cd /home/oracle/zp/[oracle@db-Bbo8Jg1B zp]$ i=0;for img in *. jpg;do ((i++));mv  $img  ${i}. jpg;done[oracle@db-Bbo8Jg1B zp]$ ls -l-rw-r--r-- 1 oracle oinstall 42775 Jun 2 13:56 1. jpg-rw-r--r-- 1 oracle oinstall 44189 Jun 2 13:59 2. jpg[oracle@db-Bbo8Jg1B zp]$ sqlplus u_test1/u_test1declare l_blob blob; l_bfile bfile;begin for i in 1 . . 2 loop  -- 确认好表与表字段  insert into T_PIC_1   (ID, ZP)  values   (i, empty_blob())  returning ZP into l_blob;  -- 照片的命名必须为规则的从1到10w,如:10. jpg , IMAGES代表逻辑目录名称  l_bfile := bfilename('IMAGES', i || '. jpg');  dbms_lob. fileopen(l_bfile);  dbms_lob. loadfromfile(l_blob, l_bfile, dbms_lob. getlength(l_bfile));  dbms_lob. fileclose(l_bfile); end loop; commit; -- 可自行调整为单次commit或者批量commitend;/可以使用PLSQL去查看下表： 使用存储过程的方式入库: 123456789101112131415161718CREATE OR REPLACE PROCEDURE IMG_INSERT_ACS(FILENAME VARCHAR2) AS F_LOB BFILE; B_LOB BLOB;BEGIN INSERT /*+ append */ INTO T_PIC_1  (ID, ZP) VALUES -- ID通过调用序列SEQ_T_PIC_1取唯一自增值,IMAGES代表逻辑目录名称  (seq_T_PIC_1. nextval, EMPTY_BLOB()) RETURN ZP INTO B_LOB; F_LOB := BFILENAME('IMAGES', FILENAME); DBMS_LOB. FILEOPEN(F_LOB, DBMS_LOB. FILE_READONLY); DBMS_LOB. LOADFROMFILE(B_LOB, F_LOB, DBMS_LOB. GETLENGTH(F_LOB)); DBMS_LOB. FILECLOSE(F_LOB); COMMIT;END;/1234567begin -- Call the procedure img_insert_acs(filename =&gt; '1. jpg');end;/再去通过PLSQL查看表： "
    }, {
    "id": 17,
    "url": "http://localhost:4000/index.php/2020/05/mysql-note-20-mysql-group-replication/",
    "title": "MySQL手记20 &#8212; MySQL Group Replication(MGR组复制)",
    "body": "2020/05/27 - 一、简介MGR（MySQL Group Replication）是MySQL原生的数据库集群架构，底层使用Paxos协议实现多写、选举等过程，目前最大支持9个节点。可分为单写（Single-Primary）、多写（Multiple-Primary）两类集群，虽然能够多写，但是还是建议单写，因为多写需要有选举的过程，在节点较多、或者网络环境较差的情况下，会严重影响性能。官方work有相关的测试报告：http://mysqlhighavailability. com/zooming-in-on-group-replication-performance/ 二、安装部署（1）数据库配置: 在启动前，需要修改启动的配置文件： 12345678910111213141516171819#gtidgtid_mode=onenforce_gtid_consistency=onbinlog_checksum=nonetransaction_write_set_extraction  = XXHASH64loose-group_replication_group_name =  8cb61fd9-8931-11ea-ad6f-0242ac110003 loose_group_replication_single_primary_mode = 0  #0:single-primary; 1:multiple-primaryloose-group_replication_start_on_boot = OFFloose_group_replication_compression_threshold = 100loose_group_replication_flow_control_mode = 0loose-group_replication_bootstrap_group = OFFloose_group_replication_enforce_update_everywhere_checks =true  #single-primary需设为关闭，multiple-primary则必须打开，主要是使（serialized隔离级别的事务，或者是使事务中有外键关系的表的）事务失败loose-group_replication_transaction_size_limit = 10485760   #事务的大小，若太大，则会影响集群的性能loose_group_replication_unreachable_majority_timeout = 120loose-group_replication_auto_increment_increment = 7  #自增值的跨度大小loose-group_replication_local_address= 172. 21. 0. 2:15501   #当前主机的ip，可动态修改loose-group_replication_group_seeds='172. 21. 0. 2:15501,172. 21. 0. 4:15503,172. 21. 0. 3:15502'  ##集群中所有节点的信息，可动态修改loose_group_replication_ip_whitelist='172. 21. 0. 4,172. 21. 0. 2,172. 21. 0. 3' #节点的ip白名单，可动态修改其中loose开头的为group replication安装插件时候启动的配置。MGR不支持binlog_checksum，切gtid必须打开。 （2）添加插件: Group Replication是以插件的形式加入到集群中的，所以需要进行插件的安装： 12345678910mysql&gt; INSTALL PLUGIN group_replication SONAME 'group_replication. so';​mysql&gt; SHOW PLUGINS;+---------------------------------+----------+--------------------+----------------------+---------+| Name              | Status  | Type        | Library       | License |+---------------------------------+----------+--------------------+----------------------+---------+. . . | group_replication        | ACTIVE  | GROUP REPLICATION | group_replication. so | GPL   |+---------------------------------+----------+--------------------+----------------------+---------+a. 启动第一个节点: 第一个节点启动时，需要先设置： 12SET GLOBAL group_replication_bootstrap_group=ON;即表示该节点为运行集群中的第一个节点，启动Group Replication： 12START GROUP_REPLICATION;日志中打印的信息为： 12[System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_applier' executed'. Previous state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. b . 启动第二个节点: 在第二个节点执行： 12START GROUP_REPLICATION;由于集群中已经有第一个节点，所以不需要再设置group_replication_bootstrap_group=on日志： 123456[System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_applier' executed'. Previous state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. [System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_recovery' executed'. Previous state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='70b353672cdc', master_port= 5501, master_log_file='', master_log_pos= 4, master_bind=''. [Warning] [MY-010897] [Repl] Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the 'START SLAVE Syntax' in the MySQL Manual for more information. 2020-05-22T07:34:16. 119089-00:00 27 [System] [MY-010562] [Repl] Slave I/O thread for channel 'group_replication_recovery': connected to master 'root@70b353672cdc:5501',replication started in log 'FIRST' at position 4[System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_recovery' executed'. Previous state master_host='70b353672cdc', master_port= 5501, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. 查看第二个节点的添加情况： 123456789mysql&gt; select * from performance_schema. replication_group_members;+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+| CHANNEL_NAME       | MEMBER_ID              | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+| group_replication_applier | e3f0850e-8936-11ea-98ba-0242ac150004 | 2bd38a52527e |    5502 | ONLINE    | PRIMARY   | 8. 0. 20     || group_replication_applier | e4a14f46-8936-11ea-b379-0242ac150005 | 70b353672cdc |    5501 | ONLINE    | PRIMARY   | 8. 0. 20     |+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+2 rows in set (0. 00 sec)重启group replication时，状态为RECOVERY: 123456789mysql&gt; select * from performance_schema. replication_group_members;+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+| CHANNEL_NAME       | MEMBER_ID              | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+| group_replication_applier | e3f0850e-8936-11ea-98ba-0242ac150004 | 2bd38a52527e |    5502 | RECOVERING  | PRIMARY   | 8. 0. 20     || group_replication_applier | e4a14f46-8936-11ea-b379-0242ac150005 | 70b353672cdc |    5501 | ONLINE    | PRIMARY   | 8. 0. 20     |+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+2 rows in set (0. 03 sec)c. 添加第三个节点: 直接执行start group_replication;，打印日志为： 12345678[Warning] [MY-011735] [Repl] Plugin group_replication reported: '[GCS] Automatically adding IPv4 localhost address to the whitelist. It is mandatory that it is added. '[Warning] [MY-011735] [Repl] Plugin group_replication reported: '[GCS] Automatically adding IPv6 localhost address to the whitelist. It is mandatory that it is added. '[System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_applier' executed'. Previous state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. [System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_recovery' executed'. Previous state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='70b353672cdc', master_port= 5501, master_log_file='', master_log_pos= 4, master_bind=''. [Warning] [MY-010897] [Repl] Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the 'START SLAVE Syntax' in the MySQL Manual for more information. [System] [MY-010562] [Repl] Slave I/O thread for channel 'group_replication_recovery': connected to master 'root@70b353672cdc:5501',replication started in log 'FIRST' at position 4[System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_recovery' executed'. Previous state master_host='70b353672cdc', master_port= 5501, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. 通过以上的日志可以看出，在各个节点启动的时候，均会有CHANGE MASTER TO FOR CHANNEL …的操作。 完成后，查看集群中节点的状态，查看集群的状态： 1234567891011mysql&gt; SELECT * FROM performance_schema. replication_group_members;​+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+| CHANNEL_NAME       | MEMBER_ID              | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+| group_replication_applier | e0dd6e3d-8936-11ea-9176-0242ac150003 | 7bcecb1807d5 |    5503 | ONLINE    | PRIMARY   | 8. 0. 20     || group_replication_applier | e3f0850e-8936-11ea-98ba-0242ac150004 | 2bd38a52527e |    5502 | ONLINE    | PRIMARY   | 8. 0. 20     || group_replication_applier | e4a14f46-8936-11ea-b379-0242ac150005 | 70b353672cdc |    5501 | ONLINE    | PRIMARY   | 8. 0. 20     |+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+3 rows in set (0. 02 sec)三、MGR相关参数MGR为了保证数据的一致性以及提升集群的性能，用户可进行相关的配置，当前版本8. 0. 20： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162mysql&gt; show variables like '%group_repl%';+-----------------------------------------------------+----------------------------------------------------+| Variable_name                    | Value                       |+-----------------------------------------------------+----------------------------------------------------+| group_replication_allow_local_lower_version_join  | OFF                        || group_replication_auto_increment_increment     | 7                         || group_replication_autorejoin_tries         | 0                         || group_replication_bootstrap_group          | OFF                        || group_replication_clone_threshold          | 9223372036854775807                || group_replication_communication_debug_options    | GCS_DEBUG_NONE                   || group_replication_communication_max_message_size  | 10485760                      || group_replication_components_stop_timeout      | 31536000                      || group_replication_compression_threshold       | 100                        || group_replication_consistency            | EVENTUAL                      || group_replication_enforce_update_everywhere_checks | ON                         || group_replication_exit_state_action         | READ_ONLY                     || group_replication_flow_control_applier_threshold  | 25000                       || group_replication_flow_control_certifier_threshold | 25000                       || group_replication_flow_control_hold_percent     | 10                         || group_replication_flow_control_max_quota      | 0                         || group_replication_flow_control_member_quota_percent | 0                         || group_replication_flow_control_min_quota      | 0                         || group_replication_flow_control_min_recovery_quota  | 0                         || group_replication_flow_control_mode         | DISABLED                      || group_replication_flow_control_period        | 1                         || group_replication_flow_control_release_percent   | 50                         || group_replication_force_members           |                          || group_replication_group_name            | 8cb61fd9-8931-11ea-ad6f-0242ac110003        || group_replication_group_seeds            | 172. 21. 0. 2:15501,172. 21. 0. 4:15503,172. 21. 0. 3:15502 || group_replication_gtid_assignment_block_size    | 1000000                      || group_replication_ip_whitelist           | 172. 21. 0. 4,172. 21. 0. 2,172. 21. 0. 3,172. 21. 0. 5    || group_replication_local_address           | 172. 21. 0. 3:15502                  || group_replication_member_expel_timeout       | 0                         || group_replication_member_weight           | 50                         || group_replication_message_cache_size        | 1073741824                     || group_replication_poll_spin_loops          | 0                         || group_replication_recovery_complete_at       | TRANSACTIONS_APPLIED                || group_replication_recovery_compression_algorithms  | uncompressed                    || group_replication_recovery_get_public_key      | OFF                        || group_replication_recovery_public_key_path     |                          || group_replication_recovery_reconnect_interval    | 60                         || group_replication_recovery_retry_count       | 10                         || group_replication_recovery_ssl_ca          |                          || group_replication_recovery_ssl_capath        |                          || group_replication_recovery_ssl_cert         |                          || group_replication_recovery_ssl_cipher        |                          || group_replication_recovery_ssl_crl         |                          || group_replication_recovery_ssl_crlpath       |                          || group_replication_recovery_ssl_key         |                          || group_replication_recovery_ssl_verify_server_cert  | OFF                        || group_replication_recovery_tls_ciphersuites     |                          || group_replication_recovery_tls_version       | TLSv1,TLSv1. 1,TLSv1. 2,TLSv1. 3           || group_replication_recovery_use_ssl         | OFF                        || group_replication_recovery_zstd_compression_level  | 3                         || group_replication_single_primary_mode        | OFF                        || group_replication_ssl_mode             | DISABLED                      || group_replication_start_on_boot           | OFF                        || group_replication_transaction_size_limit      | 10485760                      || group_replication_unreachable_majority_timeout   | 120                        |+-----------------------------------------------------+----------------------------------------------------+55 rows in set (0. 12 sec)其中：group_replication_enforce_update_everywhere_checks=ON 该MGR集群为multiple-primary，即多主的集群，其中较为重要的参数配置：group_replication_consistency=EVENTUAL 事务一致性等级配置，本实例的配置为：在执行”读”或者”写”事务之前，不用等待之前的事务完成。即看到的是其它事务开始前的快照。 使用EVENTUAL，由于不需要进行等待其它事务的完成，所以可以获得较高的性能。当然，为了得到更高的事务一致性，还有其它配置可供选择，并且支持session级别的修改。http://codercoder. cn/index. php/2019/09/innodb-cluster-mgr-group_replication_consistency/group_replication_exit_state_action=READ_ONLY 从8. 0. 12开始加入该参数，节点非正常退出集群后记性的操作，非正常退出，包括：异常退出、由于网络等其它问题重试group_replication_autorejoin_tries次数之后，还是未能重新加入集群。为了防止异常的节点还能被访问，或者重新加入集群后影响正常的数据。所以提供此参数进行配置。 集群的基本连接信息，也可在实例启动后通过set global xxx进行配置：group_replication_start_on_boot 是否自动启动group_replicationgroup_replication_group_name 当前集群的名称group_replication_group_seeds 集群中的节点信息group_replication_ip_whitelist 节点所在机器的ip白名单group_replication_local_address 当前节点的地址 四、MGR相关表MGR相关的表，是存储在performance_schema库下的，两张表：replication_group_members：用以存储MGR集群的节点信息replication_group_member_stats：用以存储节点的状态信息，执行的事务数等 123456789101112mysql&gt; use performance_schemaDatabase changed​mysql&gt; show tables like '%group%';+----------------------------------------+| Tables_in_performance_schema (%group%) |+----------------------------------------+| replication_group_member_stats     || replication_group_members       |+----------------------------------------+2 rows in set (0. 00 sec)（1）replication_group_members表: 12345678910mysql&gt; select * from replication_group_members ;+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+| CHANNEL_NAME       | MEMBER_ID              | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+| group_replication_applier | e0dd6e3d-8936-11ea-9176-0242ac150003 | 7bcecb1807d5 |    5503 | ONLINE    | PRIMARY   | 8. 0. 20     || group_replication_applier | e3f0850e-8936-11ea-98ba-0242ac150004 | 2bd38a52527e |    5502 | ONLINE    | PRIMARY   | 8. 0. 20     || group_replication_applier | e4a14f46-8936-11ea-b379-0242ac150005 | 70b353672cdc |    5501 | ONLINE    | PRIMARY   | 8. 0. 20     |+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+3 rows in set (0. 01 sec)可以看出，该MGR集群一共三个节点，并且均为PRIMARY，MEMBER_STATE均为ONLINE状态，即三个节点均在正常运行。其中：MEMBER_HOST显示了三个节点的hostname，MEMBER_PORT为对应的端口。 （2）replication_group_member_stats表: 12345678910111213141516171819mysql&amp;gt; show create table replication_group_member_stats \G*************************** 1. row ***************************    Table: replication_group_member_statsCreate Table: CREATE TABLE if not exists `replication_group_member_stats` ( `CHANNEL_NAME` char(64) NOT NULL, `VIEW_ID` char(60) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL, `MEMBER_ID` char(36) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL, `COUNT_TRANSACTIONS_IN_QUEUE` bigint unsigned NOT NULL, `COUNT_TRANSACTIONS_CHECKED` bigint unsigned NOT NULL, `COUNT_CONFLICTS_DETECTED` bigint unsigned NOT NULL, `COUNT_TRANSACTIONS_ROWS_VALIDATING` bigint unsigned NOT NULL, `TRANSACTIONS_COMMITTED_ALL_MEMBERS` longtext NOT NULL, `LAST_CONFLICT_FREE_TRANSACTION` text NOT NULL, `COUNT_TRANSACTIONS_REMOTE_IN_APPLIER_QUEUE` bigint unsigned NOT NULL, `COUNT_TRANSACTIONS_REMOTE_APPLIED` bigint unsigned NOT NULL, `COUNT_TRANSACTIONS_LOCAL_PROPOSED` bigint unsigned NOT NULL, `COUNT_TRANSACTIONS_LOCAL_ROLLBACK` bigint unsigned NOT NULL) ENGINE=PERFORMANCE_SCHEMA DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci各个字段的介绍： CHANNEL_NAME：Name of the Group Replication channel 各个节点的名称 VIEW_ID：Current view identifier for this group. 当前MGR集群的view id MEMBER_ID：The member server UUID. This has a different value for each member in the group. This also serves as a key because it is unique to each member. 不同成员的UUID，每个集群中的成员UUID唯一 COUNT_TRANSACTIONS_IN_QUEUE：The number of transactions in the queue pending conflict detection checks. Once the transactions have been checked for conflicts, if they pass the check, they are queued to be applied as well. 队列中等待冲突检测检查的事务数。一旦检查了事务是否存在冲突，待通过检查，则将它们排队等待应用。 COUNT_TRANSACTIONS_CHECKED：The number of transactions that have been checked for conflicts. 已检查有冲突的事务数。 COUNT_CONFLICTS_DETECTED：The number of transactions that have not passed the conflict detection check. 尚未通过冲突检测检查的事务数。 COUNT_TRANSACTIONS_ROWS_VALIDATING： Number of transaction rows which can be used for certification, but have not been garbage collected. Can be thought of as the current size of the conflict detection database against which each transaction is certified. 可以用于认证但尚未被垃圾回收的交易行数。可以认为是每个事务都针对其进行认证的冲突检测数据库的当前大小。 TRANSACTIONS_COMMITTED_ALL_MEMBERS：The transactions that have been successfully committed on all members of the replication group, shown as GTID Sets. This is updated at a fixed time interval. 在复制组的所有成员上已成功提交的事务，显示为 GTID Sets。这将以固定的时间间隔进行更新。 LAST_CONFLICT_FREE_TRANSACTION：The transaction identifier of the last conflict free transaction which was checked. 最后检查的无冲突交易的交易标识符。 COUNT_TRANSACTIONS_REMOTE_IN_APPLIER_QUEUE：The number of transactions that this member has received from the replication group which are waiting to be applied. 该成员已从复制组收到的等待应用的事务数。 COUNT_TRANSACTIONS_REMOTE_APPLIED：Number of transactions this member has received from the group and applied. 该成员已从该组收到并应用的交易数。 COUNT_TRANSACTIONS_LOCAL_PROPOSED：Number of transactions which originated on this member and were sent to the group. 起源于此成员并发送到该组的交易数量。 COUNT_TRANSACTIONS_LOCAL_ROLLBACK：Number of transactions which originated on this member and were rolled back by the group. 该成员发起并被该组回滚的事务数。 ps. 注意：不能在replication_group_member_stats表上执行truncate table 命令。 12345678910111213mysql&amp;gt; select * from replication_group_member_stats;+---------------------------+---------------------+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+| CHANNEL_NAME       | VIEW_ID       | MEMBER_ID              | COUNT_TRANSACTIONS_IN_QUEUE | COUNT_TRANSACTIONS_CHECKED | COUNT_CONFLICTS_DETECTED | COUNT_TRANSACTIONS_ROWS_VALIDATING | TRANSACTIONS_COMMITTED_ALL_MEMBERS                                         | LAST_CONFLICT_FREE_TRANSACTION     | COUNT_TRANSACTIONS_REMOTE_IN_APPLIER_QUEUE | COUNT_TRANSACTIONS_REMOTE_APPLIED | COUNT_TRANSACTIONS_LOCAL_PROPOSED | COUNT_TRANSACTIONS_LOCAL_ROLLBACK |+---------------------------+---------------------+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+| group_replication_applier | 15903747614426007:3 | e0dd6e3d-8936-11ea-9176-0242ac150003 |              0 |            167 |            0 |                 1 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:1-43:1000020-1000167:2000020-2000037,e4a14f46-8936-11ea-b379-0242ac150005:1-5 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:43 |                     0 |                21 |                146 |                 0 || group_replication_applier | 15903747614426007:3 | e3f0850e-8936-11ea-98ba-0242ac150004 |              0 |            167 |            0 |                 1 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:1-43:1000020-1000167:2000020-2000037,e4a14f46-8936-11ea-b379-0242ac150005:1-5 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:43 |                     0 |                151 |                17 |                 0 || group_replication_applier | 15903747614426007:3 | e4a14f46-8936-11ea-b379-0242ac150005 |              0 |            167 |            0 |                 1 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:1-43:1000020-1000167:2000020-2000037,e4a14f46-8936-11ea-b379-0242ac150005:1-5 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:43 |                     0 |                166 |                 4 |                 0 |+---------------------------+---------------------+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+---------------------------------------------------------------------------------------------------------------------+-----------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+3 rows in set (0. 00 sec)（3）replication_group_member_stats表字段分类: 可以简单把replication_group_member_stats表的字段分为两类： a. 基础信息: 查看replication_group_member_stats表的数据情况： 12345678910111213mysql&amp;gt; select CHANNEL_NAME,VIEW_ID,MEMBER_ID,TRANSACTIONS_COMMITTED_ALL_MEMBERS from replication_group_member_stats;+---------------------------+---------------------+--------------------------------------+-------------------------------------------------------------------------------------------------------------+| CHANNEL_NAME       | VIEW_ID       | MEMBER_ID              | TRANSACTIONS_COMMITTED_ALL_MEMBERS                                     |+---------------------------+---------------------+--------------------------------------+-------------------------------------------------------------------------------------------------------------+| group_replication_applier | 15903747614426007:3 | e0dd6e3d-8936-11ea-9176-0242ac150003 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:1-39:1000020-1000021:2000020,e4a14f46-8936-11ea-b379-0242ac150005:1-5 || group_replication_applier | 15903747614426007:3 | e3f0850e-8936-11ea-98ba-0242ac150004 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:1-39:1000020-1000021:2000020,e4a14f46-8936-11ea-b379-0242ac150005:1-5 || group_replication_applier | 15903747614426007:3 | e4a14f46-8936-11ea-b379-0242ac150005 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:1-39:1000020-1000021:2000020,e4a14f46-8936-11ea-b379-0242ac150005:1-5 |+---------------------------+---------------------+--------------------------------------+-------------------------------------------------------------------------------------------------------------+3 rows in set (0. 00 sec)这几个字段展示了CHANNEL_NAME、成员信息、当前已提交的事务id。均属于基础信息类。 b. 计数类: 查看当前状态： 12345678910mysql&amp;gt; select MEMBER_ID,COUNT_TRANSACTIONS_IN_QUEUE,COUNT_TRANSACTIONS_CHECKED,COUNT_CONFLICTS_DETECTED,COUNT_TRANSACTIONS_ROWS_VALIDATING,LAST_CONFLICT_FREE_TRANSACTION,COUNT_TRANSACTIONS_REMOTE_IN_APPLIER_QUEUE,COUNT_TRANSACTIONS_REMOTE_APPLIED,COUNT_TRANSACTIONS_LOCAL_PROPOSED,COUNT_TRANSACTIONS_LOCAL_ROLLBACK from replication_group_member_stats;+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+----------------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+| MEMBER_ID              | COUNT_TRANSACTIONS_IN_QUEUE | COUNT_TRANSACTIONS_CHECKED | COUNT_CONFLICTS_DETECTED | COUNT_TRANSACTIONS_ROWS_VALIDATING | LAST_CONFLICT_FREE_TRANSACTION        | COUNT_TRANSACTIONS_REMOTE_IN_APPLIER_QUEUE | COUNT_TRANSACTIONS_REMOTE_APPLIED | COUNT_TRANSACTIONS_LOCAL_PROPOSED | COUNT_TRANSACTIONS_LOCAL_ROLLBACK |+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+----------------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+| e0dd6e3d-8936-11ea-9176-0242ac150003 |              0 |            166 |            0 |                 18 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:2000037 |                     0 |                20 |                146 |                 0 || e3f0850e-8936-11ea-98ba-0242ac150004 |              0 |            166 |            0 |                 18 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:2000037 |                     0 |                150 |                17 |                 0 || e4a14f46-8936-11ea-b379-0242ac150005 |              0 |            166 |            0 |                 18 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:2000037 |                     0 |                166 |                 3 |                 0 |+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+----------------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+3 rows in set (0. 01 sec)在5501节点（member_id=e4a14f46-8936-11ea-b379-0242ac150005）插入一条数据，再次查看： 12345678910111213mysql&amp;gt; insert into t2 values(6);Query OK, 1 row affected (0. 04 sec)​mysql&amp;gt; select MEMBER_ID,COUNT_TRANSACTIONS_IN_QUEUE,COUNT_TRANSACTIONS_CHECKED,COUNT_CONFLICTS_DETECTED,COUNT_TRANSACTIONS_ROWS_VALIDATING,LAST_CONFLICT_FREE_TRANSACTION,COUNT_TRANSACTIONS_REMOTE_IN_APPLIER_QUEUE,COUNT_TRANSACTIONS_REMOTE_APPLIED,COUNT_TRANSACTIONS_LOCAL_PROPOSED,COUNT_TRANSACTIONS_LOCAL_ROLLBACK from replication_group_member_stats;+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+----------------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+| MEMBER_ID              | COUNT_TRANSACTIONS_IN_QUEUE | COUNT_TRANSACTIONS_CHECKED | COUNT_CONFLICTS_DETECTED | COUNT_TRANSACTIONS_ROWS_VALIDATING | LAST_CONFLICT_FREE_TRANSACTION        | COUNT_TRANSACTIONS_REMOTE_IN_APPLIER_QUEUE | COUNT_TRANSACTIONS_REMOTE_APPLIED | COUNT_TRANSACTIONS_LOCAL_PROPOSED | COUNT_TRANSACTIONS_LOCAL_ROLLBACK |+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+----------------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+| e0dd6e3d-8936-11ea-9176-0242ac150003 |              0 |            167 |            0 |                 19 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:2000037 |                     0 |                21 |                146 |                 0 || e3f0850e-8936-11ea-98ba-0242ac150004 |              0 |            167 |            0 |                 19 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:43   |                     0 |                151 |                17 |                 0 || e4a14f46-8936-11ea-b379-0242ac150005 |              0 |            167 |            0 |                 19 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:2000037 |                     0 |                166 |                 4 |                 0 |+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+----------------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+3 rows in set (0. 01 sec)过一段时间，再次查询： 123456789mysql&amp;gt; select MEMBER_ID,COUNT_TRANSACTIONS_IN_QUEUE,COUNT_TRANSACTIONS_CHECKED,COUNT_CONFLICTS_DETECTED,COUNT_TRANSACTIONS_ROWS_VALIDATING,LAST_CONFLICT_FREE_TRANSACTION,COUNT_TRANSACTIONS_REMOTE_IN_APPLIER_QUEUE,COUNT_TRANSACTIONS_REMOTE_APPLIED,COUNT_TRANSACTIONS_LOCAL_PROPOSED,COUNT_TRANSACTIONS_LOCAL_ROLLBACK from replication_group_member_stats;+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+-----------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+| MEMBER_ID              | COUNT_TRANSACTIONS_IN_QUEUE | COUNT_TRANSACTIONS_CHECKED | COUNT_CONFLICTS_DETECTED | COUNT_TRANSACTIONS_ROWS_VALIDATING | LAST_CONFLICT_FREE_TRANSACTION     | COUNT_TRANSACTIONS_REMOTE_IN_APPLIER_QUEUE | COUNT_TRANSACTIONS_REMOTE_APPLIED | COUNT_TRANSACTIONS_LOCAL_PROPOSED | COUNT_TRANSACTIONS_LOCAL_ROLLBACK |+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+-----------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+| e0dd6e3d-8936-11ea-9176-0242ac150003 |              0 |            167 |            0 |                 1 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:43 |                     0 |                21 |                146 |                 0 || e3f0850e-8936-11ea-98ba-0242ac150004 |              0 |            167 |            0 |                 1 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:43 |                     0 |                151 |                17 |                 0 || e4a14f46-8936-11ea-b379-0242ac150005 |              0 |            167 |            0 |                 1 | 8cb61fd9-8931-11ea-ad6f-0242ac110003:43 |                     0 |                166 |                 4 |                 0 |+--------------------------------------+-----------------------------+----------------------------+--------------------------+------------------------------------+-----------------------------------------+--------------------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+可以看到： COUNT_TRANSACTIONS_IN_QUEUE： 三个节点+1 COUNT_TRANSACTIONS_LOCAL_PROPOSED：5501加1（由于事务从5501发出），其它节点不变 COUNT_TRANSACTIONS_REMOTE_APPLIED：5502、5503均加1，两个节点均为接收5501节点的事务 COUNT_TRANSACTIONS_ROWS_VALIDATING：三节点均+1 Number of transaction rows which can be used for certification, but have not been garbage collected. Can be thought of as the current size of the conflict detection database against which each transaction is certified. 未被GC的用以冲突检测的事务行数，该值会按照一定频率清零（已执行完成的事务，writeset存储在certification_info的数据结构中，而每当事务结束后，各个节点会每隔（在MySQL社区版中broadcast_gtid_executed_period_var硬编码为）60秒广播一次自己节点的gtid_executed。延续阅读：https://zhuanlan. zhihu. com/p/55323854）。\ &lt;/source&gt;&lt;http://codercoder. cn/wp-content/uploads/2020/05/2020-06-0154. mp4&gt;[/video] # 三、MGR_ProxySQL 了解了MGR的集群后，还需要在该集群上进行代理的搭建，以便于读写及宕机等情况的调度，完成高可用。常用的解决方案有：ProxySQL和MySQL Router。现简单介绍下ProxySQL+MGR： 即：ProxySQL作为数据库集群的代理，Client通过连接ProxySQL访问数据库，ProxySQL则按照配置的规则，将请求分发到不同的MySQL实例，而ProxySQL后端的MySQL实例，为原生的MGR集群。ProxySQL可查阅：MySQL手记19 — MySQL代理工具ProxySQL效果为： 小结对于MGR高可用的架构，5. 7后的讨论声越来越多，值得我们逐渐在生产环境中使用。MySQL官方也在不断添加相应的内容，使MGR更加可控稳定，例如group_replication_exit_state_action为了让事务的控制更为精细，group_replication_consistency让集群更稳定…再配合着代理，能够让宕机、网络差、读写切换等运维操作更加方便。(http://codercoder. cn/index. php/2020/05/mysql-note19-mysql-proxy-tool-proxysql/)）。 欢迎关注公众号：朔的话： "
    }, {
    "id": 18,
    "url": "http://localhost:4000/index.php/2020/05/mysql-note19-mysql-proxy-tool-proxysql/",
    "title": "MySQL手记19 &#8212; MySQL代理工具ProxySQL",
    "body": "2020/05/24 - 介绍ProxySQL是一个MySQL集群架构的代理，由于其本身支持高可用，常被用作包括Master-Slave，MGR在内的集群结构的代理。https://proxysql. com/documentation/图片来源：https://www. percona. com/blog/2017/07/20/where-do-i-put-proxysql/ 一、安装部署proxySQL支持直接使用rpm包安装，所以过程较为简单。在官网上下载rom包：https://proxysql. com/documentation/installing-proxysql/ 123456789[root@node1 proxysql]# rpm -ivh proxysql-2. 0. 12-1-centos7. x86_64. rpmwarning: proxysql-2. 0. 12-1-centos7. x86_64. rpm: Header V4 RSA/SHA256 Signature, key ID 79953b49: NOKEYPreparing. . .              ################################# [100%]Updating / installing. . .  1:proxysql-2. 0. 12-1        warning: group proxysql does not exist - using rootwarning: group proxysql does not exist - using root################################# [100%]Created symlink from /etc/systemd/system/multi-user. target. wants/proxysql. service to /etc/systemd/system/proxysql. service. 其中： 默认配置文件：/etc/proxysql. cnf 默认数据路径：/var/lib/proxy ProxySQL默认管理端口：6032 ProxySQL默认client端口：6033 启动：proxySQL可以先启动，再进行配置，所以可以在启动后添加相应的配置项： 12systemctl start proxysql查看启动状态： 123456789101112131415systemctl status proxysql -l● proxysql. service - LSB: High Performance Advanced Proxy for MySQL  Loaded: loaded (/etc/rc. d/init. d/proxysql; bad; vendor preset: disabled)  Active: active (running) since Fri 2020-05-22 12:08:10 UTC; 59s ago   Docs: man:systemd-sysv-generator(8) Process: 62807 ExecStart=/etc/rc. d/init. d/proxysql start (code=exited, status=0/SUCCESS)  CGroup: /docker/b0d7120efb2f7b0ae3a5344d6e1ce509d1e841ad238f2fc1ae4ca22ca5358aff/system. slice/proxysql. service      ├─62811 proxysql -c /etc/proxysql. cnf -D /var/lib/proxysql      └─62812 proxysql -c /etc/proxysql. cnf -D /var/lib/proxysqlMay 22 12:08:10 dev-mysql-248110 systemd[1]: Starting LSB: High Performance Advanced Proxy for MySQL. . . May 22 12:08:10 dev-mysql-248110 proxysql[62807]: Starting ProxySQL: 2020-05-22 12:08:10 [INFO] Using config file /etc/proxysql. cnfMay 22 12:08:10 dev-mysql-248110 proxysql[62807]: DONE!May 22 12:08:10 dev-mysql-248110 systemd[1]: Started LSB: High Performance Advanced Proxy for MySQL. 登录proxySQL进行管理（默认只能本地127. 0. 0. 1登录，由于proxySQL所需的用户权限要求较高，防止出现安全问题）： 用户名/密码：admin:admin web页面开关（默认用户名密码：stats/stats）： 123456789101112131415mysql&gt; show variables like '%web%';+-------------------+-------+| Variable_name   | Value |+-------------------+-------+| admin-web_enabled | false || admin-web_port  | 6080 |+-------------------+-------+2 rows in set (0. 00 sec)mysql&gt; set admin-web_enabled=1;Query OK, 1 row affected (0. 00 sec)mysql&gt; load admin variables to run;Query OK, 0 rows affected (0. 00 sec)ProxySQL的结构: 第一层：RUNTIME 目前在运行中的ProxySQL的配置，RUNTIME的配置是不能修改的，可以将其当作一个状态。修改需要从MEMORY层加载。 第二层：MEMORY 已在内存中的配置，为数据加载的中间层。ProxySQL启动时，从磁盘中读取配置文件，放到内存中，再将内存中的数据加载到RUNTIME层。 第三层：DISK/CONFIG FILE ProxySQL在磁盘上为SQLite数据库，所以需要将在内存中的数据，加载到磁盘中，否则重启proxySQL后会丢失内存中的信息。 例如需要修改MySQL的变量，对应的指令为： 123LOAD MYSQL VARIABLES TO RUNTIME; SAVE MYSQL VARIABLES TO DISK;三、基本信息登录管理后台，执行： 123456789101112131415161718192021222324252627282930313233343536373839mysql&gt; show databases;+-----+---------------+-------------------------------------+| seq | name     | file                |+-----+---------------+-------------------------------------+| 0  | main     |                   || 2  | disk     | /var/lib/proxysql/proxysql. db    || 3  | stats     |                   || 4  | monitor    |                   || 5  | stats_history | /var/lib/proxysql/proxysql_stats. db |+-----+---------------+-------------------------------------+5 rows in set (0. 00 sec)mysql&gt; show tables;+--------------------------------------------+| tables                   |+--------------------------------------------+| global_variables              || mysql_collations              || mysql_group_replication_hostgroups     || mysql_query_rules             || mysql_query_rules_fast_routing       || mysql_replication_hostgroups        || mysql_servers               || mysql_users                || proxysql_servers              || runtime_checksums_values          || runtime_global_variables          || runtime_mysql_group_replication_hostgroups || runtime_mysql_query_rules         || runtime_mysql_query_rules_fast_routing   || runtime_mysql_replication_hostgroups    || runtime_mysql_servers           || runtime_mysql_users            || runtime_proxysql_servers          || runtime_scheduler             || scheduler                 |+--------------------------------------------+常用的三类表: （1）变量：: ProxySQL作为一个代理，其必然会包含许多MySQL的参数： 数据库相关：max_connection、max_allowed_packed、wait_timeout、字符集等等。 限制相关：连接请求次数、数据包大小… 检测相关：连接的心跳状态、失败情况…在配置上极为灵活，可以通过global_variables表进行查看，修改后，别忘记： 123LOAD MYSQL VARIABLES TO RUNTIME; SAVE MYSQL VARIABLES TO DISK;修改的值加载到runtime，并保存在磁盘中。 （2）MySQL实例、用户：: 添加MySQL的实例： 12345678910111213141516mysql&gt; insert into mysql_servers (hostgroup_id, hostname, port) values(1, '172. 16. 120. 209', 5501);mysql&gt; select * from mysql_servers \G*************************** 1. row ***************************   hostgroup_id: 1     hostname: 172. 16. 120. 209       port: 5501      status: OFFLINE_HARD      weight: 1    compression: 0  max_connections: 1000max_replication_lag: 0      use_ssl: 0  max_latency_ms: 0      comment:可以从该表中，看到对应实例的运行情况：报错host、status、weight等。 修改MySQL的实例信息: 123LOAD MYSQL SERVERS TO RUNTIME;SAVE MYSQL SERVERS TO DISK;添加MySQL用户： 12INSERT INTO mysql_users(username,password,default_hostgroup) VALUES ('proxyuser','proxypasswd',0);直接查看该表，密码是明文的，不安全，所以需要进行密码的加密： 1234567891011121314151617mysql&gt; save mysql users from runtime; mysql&gt; select * from mysql_users \G*************************** 1. row ***************************       username: root       password: *FE1E37A7390CE06FF73D46CE034FE0C9A59A9681        active: 1       use_ssl: 0  default_hostgroup: 1    default_schema:    schema_locked: 0transaction_persistent: 1     fast_forward: 0       backend: 1       frontend: 1   max_connections: 10000transaction_persistent，同一个事务的查询，必须分发在一个节点，1. 4版本后默认为打开： https://github. com/sysown/proxysql/commit/b89de59f06261eac038c89ed3be5c083ceadfaa8 修改MySQL的用户信息，修改后，同样别忘记： 123LOAD MYSQL USERS TO RUNTIME; SAVE MYSQL USERS TO DISK;（3）scheduler定时任务: 对于集群的管理，我们还可以写脚本，来完成自动的节点上下线，切换为从节点等的一些操作。这个时候，就可以使用scheduler表进行配置： 123456789101112131415insert into scheduler(id, active, interval_ms, filename, arg1, arg2, arg3, arg4) values(1, 1, 3000, '/var/lib/proxysql/gr_mw_mode_sw_cheker. sh', 1, 2, 1, '/var/lib/proxysql/checker. log');mysql&gt; select * from scheduler \G*************************** 1. row ***************************    id: 1  active: 1interval_ms: 3000 filename: /var/lib/proxysql/gr_mw_mode_sw_cheker. sh   arg1: 1   arg2: 1   arg3: 1   arg4: /var/lib/proxysql/checker. log   arg5: NULL  comment:按照文档的介绍： id：scheduler的全剧唯一job id active：1为在运行中，否则即没有激活 interval_ms：执行周期，单位毫秒，最小值为100ms filename：可执行脚本的文件绝对路径 arg1~arg5：可以传递给脚本的参数 comment：备注 总结：本文简单介绍了ProxySQL这一强大且灵活的MySQL代理，需要按需进行测试，包括对于连接的转发是否均衡、节点宕机是否能够将连接发到其它节点、是否能够承受住非常大量的连接、自身的高可用等。 数据库加了一层代理，还需要考虑到代理与实例间的延迟，对延迟敏感的业务是否适用。对于MySQL的集群，需要稳定、灵活且方便的进行管理，包括之前介绍的MySQL高可用集群拓扑结构管理工具Orchestrator，本篇的ProxySQL等，都是集群运维中的一个部分，需要我们谨慎的完成管理。 欢迎关注公众号：朔的话： "
    }, {
    "id": 19,
    "url": "http://localhost:4000/index.php/2020/05/recommending-2-solar-opposites/",
    "title": "好剧推荐2 &#8212; 外星也难民(Solar Opposites)",
    "body": "2020/05/16 - 上次推荐了《瑞克和莫蒂》，苦苦等待的第四季第6集5月8号才更新，足足等了将近半年～ 在找其它的动画的时候，突然发现一部超有趣的《外星也难民》，与《瑞克和莫蒂》是同一个主创：Justin Roiland，也太有才了。 这两个剧有一个我很喜欢的共同点：通过动画的方式，简单直接的反应当下社会的情况：包括科技、成长、偏见、信仰、人性、嘲讽、种族等等，其中的一些，是没有办法出现在荧幕上的。 我目前也还在追剧，第一季已经全部更新了，讲的是一个外星人家庭，由于自己的星球没小行星撞击，所以逃难迫降到地球，在地球上生活的故事。 Justin Roiland厉害就厉害在，动画中单独拎出的某一个场景，就可以作为一个新的动画主题，可见其功力之深厚。 "
    }, {
    "id": 20,
    "url": "http://localhost:4000/index.php/2020/05/mysql-note-18-using-orchestrator-to-manage-mysql-high-availability/",
    "title": "MySQL手记18 &#8212; MySQL高可用及复制管理工具Orchestrator",
    "body": "2020/05/10 - Orchestrator是一款提供页面和命令行和MySQL高可用和复制拓扑关系管理工具，可以用其方便的管理和调整拓扑结构。著名交友网站“Github”也使用了Orchestrator进行了MySQL高可用拓扑结构的管理。 除了直观的展示拓扑关系外，还能进行主从、双主等花式切换，只需在页面上进行节点的拖拽，就能完成切换，可以说非常直观有效。 一、安装部署（1）下载安装: 下载Orchestrator的安装包，解压后编辑orchestrator. conf. json文件： 12345678. . .  MySQLOrchestratorHost :  127. 0. 0. 1 , MySQLOrchestratorPort : 3306, MySQLOrchestratorDatabase :  orchestrator , MySQLOrchestratorUser :  orchestrator , MySQLOrchestratorPassword :  orch_backend_password ,. . . （2）授权: Orchestrator的元数据信息需要使用MySQL或者Sqlite进行管理，所以需要在数据库中授予相应的权限. Orchestrator所需的元数据库建库： 1234CREATE DATABASE IF NOT EXISTS orchestrator;CREATE USER 'orchestrator'@'127. 0. 0. 1' IDENTIFIED BY 'orch_backend_password';GRANT ALL PRIVILEGES ON `orchestrator`. * TO 'orchestrator'@'127. 0. 0. 1';添加的实例数据源授权： 12345CREATE USER 'orchestrator'@'orch_host' IDENTIFIED BY 'orch_topology_password';GRANT SUPER, PROCESS, REPLICATION SLAVE, RELOAD ON *. * TO 'orchestrator'@'orch_host';GRANT SELECT ON mysql. slave_master_info TO 'orchestrator'@'orch_host';GRANT SELECT ON ndbinfo. processes TO 'orchestrator'@'orch_host'; -- Only for NDB Cluster权限说明： REPLICATION SLAVE is required for SHOW SLAVE HOSTS, and for scanning binary logs in favor of Pseudo GTID RELOAD required for RESET SLAVE operation PROCESS required to see replica processes in SHOW PROCESSLIST On MySQL 5. 6 and above, and if using master_info_repository = ‘TABLE’, let orchestrator have access to the mysql. slave_master_info table. This will allow orchestrator to grab replication credentials if need be. （3）启动: 12cd /usr/local/orchestrator &amp;amp;&amp;amp; . /orchestrator --debug --config=/path/to/config. file http参考：https://github. com/openark/orchestrator/blob/master/docs/install. md 二、使用介绍2. 1 基础面板: 安装完成后，打开页面（默认端口为3000），Home —-&gt; About中有Orchestrator的介绍： 选择Cluster —-&gt; Dashboard，即可看到集群的拓扑情况。 （1）展示: 部署好一个主从集群，添加到Orchestrator中：在Orchestrator中选择Cluster—-&gt;Discover： 填写数据库的信息： 若填写的是从库的信息，则会自动把主库实例也添加进来（show slave status得到的主库的信息），可以看到新添加的集群的Instances = 2： 在Cluster —-&gt; Dashboard中，选择需要管理的集群，进入后，即可看到拓扑情况： 点击各个节点上的设置按钮，可以看到节点连接的详细信息，并且可以修改其中的部分配置： 2. 2 基础测试: （1）主从 —-&gt; 双主: Orchestrator在切换时，并不是暴力的进行切换，而是会去避免出现数据不一致的情况。例如若需要将主从 —-&gt; 双主的时候，会提示需要先将原来的从库设置为read-only，才能切换为双主： 切换后，需要重新在Cluster —-&gt; Dashboard中，选择集群，即可看到已经修改为了co-master集群。 若需要交换主从，则需要进行再次切换，主库上stop slave后，将原主库拖拽到从库后，即可​。 （2）同级从库 —-&gt; 级联主从: 即B,C均为A的从库，现把C切换为B的从库，得到A —-&gt; B —-&gt; C的集群架构： 以上介绍了两种常见的情况，当然还有很多花样的切换方式，均可进行拖拽完成，Orchestrator支持命令行的方式进行切换，方便更加自动化的切换维护。 三、命令行3. 1 列出集群: 123456bash-4. 4# orchestrator-client -c clusters2bd38a52527e:55023a95cdf097fd:44075daa942fb07c:440770b353672cdc:55013. 2 查看集群状态: 12345bash-4. 4# orchestrator-client -c replication-analysis5daa942fb07c:4407 (cluster 5daa942fb07c:4407): ErrantGTIDStructureWarning2bd38a52527e:5502 (cluster 2bd38a52527e:5502): DeadMasterWithoutSlaves3a95cdf097fd:4407 (cluster 3a95cdf097fd:4407): DeadMasterWithoutSlaves3. 3 查看拓扑关系: 1234bash-4. 4# orchestrator-client -c topology-tabulated -i 5daa942fb07c:44075daa942fb07c:4407 |0s|ok|8. 0. 18|rw|ROW|&amp;gt;&amp;gt;,GTID+ b96697e765cc:4408|0s|ok|8. 0. 18|rw|ROW|&amp;gt;&amp;gt;,GTID3. 4 主-主结构: 12orchestrator-client -c make-co-master -i test1:33073. 5 同级slave变为自己的slave: 12orchestrator-client -c take-siblings -i test3:33073. 6 将实例转换为自己主人的主人，切换两个：take-master: 12orchestrator-client -c take-master -i test3:33073. 7 将slave在拓扑上向上移动一级: 对应web上的是在Classic Model下进行拖动：move-up 123bash-4. 4# orchestrator-client -c move-up -i b96697e765cc:4408 -d 5daa942fb07c:4407b96697e765cc:4408&amp;lt;5daa942fb07c:4407参考：https://github. com/openark/orchestrator/blob/master/docs/executing-via-command-line. md 相信看了那么多图，觉得想要蠢蠢欲动想要操作一把，原来数据库的维护也可以如此简单直观，可以说是很贴心的一个工具了。 欢迎关注公众号：朔的话： "
    }, {
    "id": 21,
    "url": "http://localhost:4000/index.php/2020/05/mysql-note-17-mysql-replication-introduction/",
    "title": "MySQL手记17 &#8212; MySQL的复制Replication",
    "body": "2020/05/05 - 一、介绍复制（Replication）是用以从源实例（主库，master）拷贝数据到目标实例（从库，slaves），使用的是MySQL自身的binlog文件进行，binlog记录了源实例的数据变更情况，以此在目标端回放，从而达到数据一致的效果（所以若需要进行复制，必须开启源端实例的binlog）。 默认情况下，Replication默认是异步复制，即binlog是异步复制到目标实例的，slaves的状态不会影响到master；此外，MySQL也提供了半同步复制（Semisynchronous Replication）：即master上的事务，需要等到至少一个slave确认收到事务的所有events，才能勾提交成功，否则会超时失败。MySQL在部分场景下支持“全同步复制”：即所有slaves写盘成功后，master才能提交成功，例如MySQL Cluster，但是“完全同步复制”会阻塞master，严重影响性能，依赖网路。 MySQL Cluster中存储引擎为NDB（Network Database），在实例环境中较少用到，用得更多的是InnoDB，因此官方也有对于InnoDB的集群方案—-InnoDB Cluster。 除了使用binlog中的file名称和位点信息进行顺序复制外，MySQL提供基于GTIDs（global transaction identifiers）的复制方式：即在集群中，GTID是唯一的，由于每个事务的GTID都不相同，这使得在事务的追溯，或是新增slave、master实例的fail over宕机切换等方面变得简单。 二、常见集群架构2. 1 一主一从: 即一个主库一个从库，是最为常见的集群架构。一主一从结构简单，常在很多环境进行使用，例如读写分离、数据库备份等。 2. 2 一主多从: 一个主库多个从库，多个从库可以提供给不同的应用方，例如业务方使用一个从库，大数据的离线任务使用另一个。 2. 3 多源复制: 把多个主库的数据复制到同一个从库，通常作为数据的备份归档使用。 2. 4 级联复制: 即从库作为另一个实例的主库，A复制到B，B复制到C。为了防止主库上的复制压力过大，例如主库上已经有3/4个从库了，若继续添加，会导致主库的性能有所下降（复制也是需要消耗硬件资源的，例如网络带宽），而若是半同步，则影响会更为明显，所以可以用级联复制的方式，减轻主库的负担。 2. 5 组复制: Group replication（https://dev. mysql. com/doc/refman/8. 0/en/group-replication. html），是MySQL官方通过插件形式（plugin）提供的高可用容错的复制拓扑结构。简单来说就是把多个MySQL的实例，组成一个集群，共同向clinets提供服务，以减轻单点的负担，同时还能提供高可用，在master故障时候，使用其它的节点提供master的服务。由于涉及到的内容过多，后续会详细介绍。官方文档甚至单列了一章来介绍Group Replication。 2. 6 双主复制: 双主复制，其实是两个实例互为主从，可以调整自增值、步长等配置，使两端的实例能够正常运行，但是在实际环境中，双主容易出现数据不一致的情况。 三、Replication的主要功能：3. 1 横向拓展/降低主库负载: 部分对于延迟要求不高的查询，或是较为复杂的统计分析累查询，可以放在从库进行，以降低这类查询对于主库的影响。如下图所示，master主要负责“写”操作，其它的从库，则分担不同的读查询。 3. 1 用以备份: 在异步复制中，从库的状态不会影响到主库，所以我们可以使用mysqldump或者是xtranbackup等工具，在从库上备份数据，防止备份过程影响到主库。 3. 2 从库使用不同的表结构: 由于复制是不区分目标和源的部分状态的（即只要binlog中的SQL能够正常回放即可）。所以，从库上可以建立不同的索引，甚至是使用不同的存储引擎，以适应需要在从库上进行查询的业务。 3. 3 数据库拆分: 通常在业务上线前期，部分量小的数据库，会被放在同一个实例中，但是随着数据量或者QPS的升高，需要将其中的数据库进行拆分，就可以使用复制Replication，将不同的数据库，复制到不同的实例中。可以使用–replicate-wild-do-table=databaseA. %进行数据库、表的过滤。 3. 4 高可用: 复制可用以把master复制到另一个实例，当master意外宕机时，立即切换到新的实例上，从而降低对于业务的影响。这其中有数据一致性的相关要求，例如半同步复制中的：lossless replication，即无损复制，从5. 7. 2版本开始加入，相关配置为：rpl_semi_sync_master_wait_point，具体可参考：http://codercoder. cn/index. php/2019/09/mysql5-7-lossless-semi-replication/ 3. 5 延迟复制: 即人为让从库产生多长时间的延迟，通过CHANGE MASTER TO MASTER_DELAY = N;进行指定。作用：（1）若主库上产生误操作，可以及时使用正常数据的从库进行恢复（2）测试延迟对于某些业务功能的影响（3）可以在从库上看到历史的数据参考：https://dev. mysql. com/doc/refman/5. 7/en/replication-delayed. html 实际环境中，复制还有许许多多的使用方式，例如搭配着多源复制和延迟复制，进行数据的备份，除了能恢复误操作的数据，一个实例存放多个源实例的数据备份，还能节省成本；使用lossless半同步复制，能够让我们的高可用环境数据一致性得以更好的保证，降低了数据不一致的风险等等…… 而只要是涉及到MySQL的迁移、同步等等，均是基于复制进行的，所以需要深刻了解复制的过程，发挥其最大的作用。 欢迎关注公众号：朔的话： "
    }, {
    "id": 22,
    "url": "http://localhost:4000/index.php/2020/05/tips-donot-use-percona-xtrabackup-8-0-11-to-back-up-mysql-8-0-20/",
    "title": "Tips:升级到MySQL8.0.20后暂不能使用Xtrabackup进行备份",
    "body": "2020/05/04 - 序前文有说到，在做数据库升级之前，一定要多加小心谨慎，避免兼容问题。这也就要求DBA除了知道新版本特性之外，还需要知道为这些特性，做了哪些修改。MySQL手记5 — 数据库升级准备 4月27日，MySQL官方发布了8. 0. 20的GA版本，新增了许多振奋人心的特性，同时，也带了了很多差异，需要进行测试。较为关注的是Percona Xtrabackup在对MySQL8. 0. 20进行备份恢复的时候，会出现报错： 一、环境准备1. 1 MySQL 8. 0. 20: 下载MySQL官方的8. 0. 20版本进行安装，建库建表： 1234567891011mysql&amp;gt; create database wstestdb;​mysql&amp;gt; use wstestdbmysql&amp;gt; CREATE TABLE if not exists `test1` ( `id` int NOT NULL AUTO_INCREMENT, `name` varchar(30) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;​mysql&amp;gt; insert into test1 values(1,'aaa');1. 2 下载安装最新版本Percona Xtrabackup: 截止5月4日，最新版本为percona-xtrabackup-8. 0. 11，下载解压后，进入到bin目录下，执行： 12. /xtrabackup --defaults-file=/soft/my5501. cnf --user=root --password=abc1abc --host=127. 0. 0. 1 --port=5501 --parallel=4 --databases=wstestdb --backup其中： –defaults-file：MySQL实例的配置文件 其余项目为MySQL实例的连接、需要备份的数据库信息，最后使用–backup指明需要进行备份。 二、xtrabackup备份报错打印信息： 12345678910111213141516171819202122232425[root@mysql-01 bin]# . /xtrabackup --defaults-file=/soft/my5501. cnf --user=root --password=abc1abc --host=127. 0. 0. 1 --port=5501 --parallel=4 --databases=wstestdb --backupxtrabackup: recognized server arguments: --datadir=/data/mysql5501 --innodb_undo_tablespaces=3 --tmpdir=/tmp --log_bin=/data/mysql5501/mysql5501 --server-id=1845501 --innodb_file_per_table=1 --innodb_flush_log_at_trx_commit=1 --innodb_page_size=16k --innodb_buffer_pool_size=256M --innodb_data_file_path=ibdata1:400M:autoextend --innodb_log_files_in_group=2 --innodb_log_buffer_size=200M --innodb_open_files=2000 --innodb_io_capacity=1200 --innodb_read_io_threads=32 --innodb_write_io_threads=32 --innodb_max_dirty_pages_pct=75xtrabackup: recognized client arguments: --port=5501 --user=root --password=* --host=127. 0. 0. 1 --port=5501 --parallel=4 --databases=wstestdb --backup=1. /xtrabackup version 8. 0. 11 based on MySQL server 8. 0. 18 Linux (x86_64) (revision id: 486c270)200504 09:29:43 version_check Connecting to MySQL server with DSN 'dbi:mysql:;mysql_read_default_group=xtrabackup;host=127. 0. 0. 1;port=5501' as 'root' (using password: YES). 200504 09:29:43 version_check Connected to MySQL server200504 09:29:43 version_check Executing a version check against the server. . . 200504 09:29:43 version_check Done. 200504 09:29:43 Connecting to MySQL server host: 127. 0. 0. 1, user: root, password: set, port: 5501, socket: not setUsing server version 8. 0. 20xtrabackup: uses posix_fadvise(). xtrabackup: cd to /data/mysql5501xtrabackup: open files limit requested 0, set to 1048576xtrabackup: using the following InnoDB configuration:xtrabackup:  innodb_data_home_dir = . xtrabackup:  innodb_data_file_path = ibdata1:400M:autoextendxtrabackup:  innodb_log_group_home_dir = . /xtrabackup:  innodb_log_files_in_group = 2xtrabackup:  innodb_log_file_size = 50331648Number of pools: 1200504 09:29:44 Connecting to MySQL server host: 127. 0. 0. 1, user: root, password: set, port: 5501, socket: not setxtrabackup: Redo Log Archiving is not set up. Unknown redo log format (4). Please follow the instructions at http://dev. mysql. com/doc/refman/8. 0/en/ upgrading-downgrading. html. xtrabackup: Error: recv_find_max_checkpoint() failed. 报错信息为： xtrabackup: Redo Log Archiving is not set up. Unknown redo log format (4). Please follow the instructions at http://dev. mysql. com/doc/refman/8. 0/en/ upgrading-downgrading. html. xtrabackup: Error: recv_find_max_checkpoint() failed. 原因MySQL8. 0. 20的Release Notes中有这样的介绍： InnoDB: Redo log records for modifications to undo tablespaces increased in size in MySQL 8. 0 due to a change in undo tablespace ID values, which required additional bytes. The change in redo log record size caused a performance regression in workloads with heavy write I/O. To address this issue, the redo log format was modified to reduce redo log record size for modifications to undo tablespaces. (Bug #29536710) 为了在redo log中记录undo表空间的修改信息（记录undo表空间的ID），所以会增加redo log的大小，导致影响到I/O性能。为了解决这个问题，redo log的格式被修改了，以减小其记录所占的大小。 Percona-xtrabackup-8. 0. 11是基于MySQL 8. 0. 18进行开发的，所以当前若使用MySQL 8. 0. 20版本，暂时不要使用Percona Xtrabackup进行备份操作。 参考：https://forums. percona. com/discussion/comment/55828欢迎关注公众号：朔的话： "
    }, {
    "id": 23,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-15-case-sensitivity-and-case-insensitivity/",
    "title": "MySQL手记15 &#8212; 大小写问题",
    "body": "2020/04/29 - 最近在测试时候，看到一个字符集校验规则的问题，由于设置了不同的校验规则，获取到的数据结果也就不一致。 MySQL的大小写规则，包含：表结构大小写、数据的大小写。结构的大小写在实例初始化的时候就需要进行指定：lower_case_table_names；数据的大小写，则由表或者字段的COLLATE进行指定。 一、表结构大小写表结构大小写通常在实例初始化时候就行指定，lower_case_table_names，https://dev. mysql. com/doc/refman/8. 0/en/server-system-variables. html#sysvar_lower_case_table_names 官方文档中的介绍：identifier-case-sensitivity 修改lower_case_table_names: （1）调整为区分大小写，会报错，因为该参数不可以进行动态调整： （2）在实例初始化后修改my. cnf也是不能够启动成功的，错误信息：[ERROR] [MY-011087] [Server] Different lower_case_table_names settings for server (‘0’) and data dictionary (‘1’). [ERROR] [MY-010020] [Server] Data Dictionary initialization failed. [ERROR] [MY-010119] [Server] Aborting 二、数据字符串大小写对于数据中字符串的大小写是否做区分，主要是看指定的字符集： 字符集_ci结尾的排序规则，则是不区分大小写的， _bin结尾，区分大小写 可以查看select * from INFORMATION_SCHEMA. COLLATIONS; 查看支持的字符集校对规则。 2. 1 表级别COLLATIONS: 两张表test1、test2 1234567891011121314CREATE TABLE if not exists `test1` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(30) COLLATE utf8mb4_general_ci NOT NULL DEFAULT '', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ciCREATE TABLE if not exists `test2` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(30) COLLATE utf8mb4_bin NOT NULL DEFAULT '', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin分别插入相同的数据： 12345678910111213141516171819202122232425mysql&amp;gt; insert into test1 values(1,'aaa');Query OK, 1 row affected (0. 05 sec)mysql&amp;gt; insert into test2 values(1,'aaa');Query OK, 1 row affected (0. 02 sec)mysql&amp;gt; select * from test1 where name='AAA';+----+------+| id | name |+----+------+| 1 | aaa |+----+------+1 row in set (0. 00 sec)mysql&amp;gt; select * from test2 where name='AAA';Empty set (0. 00 sec)mysql&amp;gt; select * from test2 where name='aaa';+----+------+| id | name |+----+------+| 1 | aaa |+----+------+1 row in set (0. 00 sec) 在test1表中查询select * from test1 where name=’AAA’; 虽然是大写，但是由于表的collation为：utf8mb4_general_ci，所以是不区分大小写的，可以查询到结果。 在test2中执行相同的查询，查询不到结果，因为test2的collation是utf8mb4_bin，区分大小写，’AAA’不等于’aaa’，返回空。 2. 2 字段级别: 一个表test3，表的collate为utf8mb4_general_ci，字段name为utf8mb4_general_ci，addr为utf8mb4_bin： 1234567CREATE TABLE if not exists `test3` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(30) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL DEFAULT '', `addr` varchar(30) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL DEFAULT '', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci插入一行数据： 按照大写进行查询： 结果: 对于不区分大小写的name为utf8mb4_general_ci：使用大写字符可以查询到结果 对于区分大小写的addr为utf8mb4_bin：使用大写字符查询不到结果 三、小结在初始化MySQL实例、建表时候，需要注意到大小写的问题，并与开发人员沟通，若需要表结构大小写敏感，则调整lower_case_table_names；若需要数据的大小写敏感，调整utf8mb4_general_ci/utf8mb4_bin，当然常见的还有utf8_general_ci/utf8_bin。 欢迎关注公众号：朔的话： "
    }, {
    "id": 24,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-14-attention-when-migrating-data/",
    "title": "MySQL手记14 &#8212; 数据迁移注意事项",
    "body": "2020/04/28 - 一、提要对DBA来说，数据迁移可能是维护工作中最常见的操作了，很多场景，都需要进行数据的迁移，所以需要总结一套迁移的流程，按照既定的流程进行操作。本篇主要是阐述一些迁移过程中的注意事项，后续将逐渐介绍迁移的方案。 数据库的迁移，涉及到运维团队、开发团队，在进行之前，一定要协调好相关的人员。在这个过程中，极有可能出现一些问题（从第二部分就可以看出“坑”是相当多的），需要及时反馈。 参考步骤：: 1. 业务方发起数据库迁移申请： 新建群，拉取DBA和相关的人员（特别是数据涉及到的业务方人员和大数据人员，注意一个库表，多个应用使用的情况） 2. 业务方和上述人员确认数据库、表，是否有订阅或者定时离线任务 3. DBA开启同步通道，待同步延迟在1s以内时： 有订阅或者离线任务：业务方群里通知订阅人员修改数据源 没有订阅或者离线任务：修改数据源配置 4. DBA通知应用方读取新的配置 5. DBA观察发布连接情况，待全部发布后，释放同步连接（通常会等待3天左右的时间，观察无流量后释放，防止部分离线任务未进行切换） 6. 业务方申请下线老的数据源 7. DBA验证原实例无连接，3日之内审计没有对应库、表的访问后，备份并下线库表 二、注意事项2. 1 防止踩“坑”: 上部分说到的每一步，几乎都存在各式各样的“坑”，但是，如果去避免？（1）DBA本身对于整个流程的把控（2）在迁移之前的全链路测试（3）数据一致性的验证（4）可能发生的情况的预测 2. 2 花样“踩坑”: （1）流程发起: 流程发起通常需要和开发确认，开发人员对于业务的需求，都会比DBA更为了解。公司若有条件，可以开发平台，用来统计和管理数据的流向，便于数据的管控。 （2）离线任务、订阅等的确认: 需要有相关的记录，防止出现“背锅”现象。而且对于流程管理来说，每一步都有对应的记录和对接的人员，更会让技术流程更加标准化。 （3）同步通道的延迟: DBA需要提前部署，根据数据量已经binlog产生的速度，建立合理规格的同步通道：（何为合适？主要从以下两个方面进行评估： a. 数据量的大小：判断全量拉取完全部的数据，需要的耗时时间，尽量使全量同步在3天内完成，并且越短时间越好，因为生产环境中，binlog往往不会全量保存，会有过期时间。所以，如果全量同步很慢，则增量的binlog可能已经过期，导致同步失败 b. binlog产生的速度：例如创建的同步通道最高只能达到3000QPS，若源端产生的binlog速度大于3000QPS，则目标端会永远追不上源端，导致同步失败） 所以选择同步通道的大小，也是关键的一步。 123对于阿里云DTS（Data Transmission Service）：按照同步通道的不同规格进行收费，不同的规则对应不同的QPS大小对于亚马逊DMS（Database Migration Service）：同步通道为一个实例，购买相应大小的实例，再在实例上进行传输服务各个同步的工具，几乎都会反应同步的延迟情况。DBA需要进行关注。 （4）数据一致性: 涉及到数据的同步，往往有这样的问题，就是怎么防止两端的数据不一致？什么情况会导致不一致的情况？怎么去验证？对于验证数据一致性的工具很多，例如：MySQL手记13 — 使用mysqldbcompare对比数据一致性，也有既定的对比思路可以进行自己开发，例如需要怎么对比数据，对比多少的数据量，每次对比多少量等等。 （5）回滚: 对于回滚，也非常有讲究，什么样的情况需要回滚？为了回滚，需要DBA前期做什么工作？等等之类的情况，都需要进行测试和模拟。 三、同步通道类型3. 1 同步通道: 目前的通用的方法都是通过实时订阅binlog消息进行的同步。之前提到过，有阿里云的DTS、亚马逊的DMS、腾讯云的数据迁移服务相比之下灵活性不如阿里云DTS和亚马逊DMS（但是腾讯云的迁移服务目前是免费的2020-04-28）。 同样，也可以使用自建的数据库同步通道，开源的产品有：canal（阿里巴巴）、Otter（基于canal做的产品）、Syncer（PingCAP公司开发的同步工具） 3. 2 单向同步: 单向同步往往适用于不需要回滚的场景：应用跳转到目标段后，若产生了数据，则这部分数据已经落实在目标端，所以若需要回滚，则这部分数据难以重新同步到源端（会耗费巨大运维资源） 单向同步的好处在于：场景即情况简单，几乎不会出问题，就类似与MySQL本身的主从，属于比较稳定、常见的解决方案。 3. 3 双向同步: 双向同步需要考虑的问题就很多，例如“数据回环”的问题。Otter工具，对于“数据回环”就给出了自己的解决方案：https://github. com/alibaba/otter/wiki/Otter%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7优点： 对于很对核心的业务，为了防止在切换时出现问题，所以都需要做兜底的方案。那么双向同步就是一个不错的选择： 在应用切到目标端后，若出现异常需要回滚，那么在目标端进行的变更，同样会实时同步到源端，业务切回时，就能有一致的数据。 由于双向同步是非常重要的，甚至是非常必要的，所以，在部署使用双向同步之前，一定要做足充分的测试。特别是“数据一致性”的测试，不然双向同步会让整一个的运维难度和业务切换进入到一个非常复杂的局面。 控制数据的流向，在整个双向同步的过程尤为重要，DBA也必须通过现想去看到本质，数据是怎么流的，binlog里到底记录了什么信息，如果需要回滚，怎么去使用binlog查找到错误或者冲突的数据，数据冲突时候，怎么去解决…… 亚马逊DMS：https://aws. amazon. com/cn/dms/faqs/ 四、数据一致性数据一致性，是整个数据库迁移过程中的难点，需要DBA对整个链路都有非常严格和熟练的把控，一环出问题，后果不堪设想。（例如，在数据冲突上出问题，如果有一行数据除了问题，那么除了后续数据也会受影响以外，同步通道会整个堵住，应用也会出现相应的报错，写入的数据查询不到，导致灾难性问题） 4. 1 测试同步通道: 同步通道搭建起来后，需要进行测试，可以使用Sysbench工具进行。在两端分别/同时插入和更新数据，对比两边的数据是否一致。MySQL手记4 — Sysbench进行QPS性能测试 4. 2 双写（两端同时写入）: （1）两端并发insert自增问题（2）两端并发update唯一索引问题…后续文章会全面展开双写的测试，及如何避免出现数据不一致的情况 五、确认数据迁移成功应用切换完成后，DBA需要根据原实例和目标实例的： 连接情况：判断原实例是否有连接，目标实例的连接数是否正常 SQL执行情况：可以根据审计日志、慢查、general log等日志查看原实例上是否仍有SQL的执行 完成后，还需要保留同步通道和原实例，防止部分应用遗漏的情况。 欢迎关注公众号：朔的话： "
    }, {
    "id": 25,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-13-comparing-data-difference-by-using-mysqldbcompare/",
    "title": "MySQL手记13 &#8212; 使用mysqldbcompare对比数据一致性",
    "body": "2020/04/26 - 一、简介前面说到使用mysqldiff工具进行不同数据源的结构差异的对比，本篇将介绍对比不同数据源中的数据差异。在生产环境中非常有用，可以用来对比迁移的数据是否一致，又或是用来对比数据间差异，进行数据的补齐。 二、使用说明同样通过–help查看相关的帮助信息，选择合适的对比策略： 12345678# mysqldbcompare --helpMySQL Utilities mysqldbcompare version 1. 6. 5License type: GPLv2Usage: mysqldbcompare --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1:db2mysqldbcompare - compare databases for consistency. . . 比较有意思的是，可以选择多种不同的跳过类型： 2. 1 对比不同数据源的数据: 使用mysqldbcompare对比两个数据库的结构及数据差异： （1）–run-all-test: 若不加run-all-test，则当遇到第一个差异时候，就会退出： 12mysqldbcompare --server1=root:root@172. 16. 3. 3:4407 --server2=root:root@172. 16. 3. 3:4408 wstestdb1:wstestdb2 --difftype=SQL --show-reverse -vvv --changes-for=server1 截图即找到第一个差异时，就直接退出，不再进行其它对象的比较。 （2）–skip-diff: mysqldbcompare –server1=root:root@172. 16. 3. 3:4407 –server2=root:root@172. 16. 3. 3:4408 wstestdb1:wstestdb2 –difftype=SQL –show-reverse -vvv –changes-for=server1 –skip-diff 跳过对象差异的步骤，例如上部分的defination，在对比时可以忽略，并在注释中提示：Definination Diff — Skip 但是–skip-diff不会跳过数据比较时的差异！ （3）加上–run-all-test，: 会把库中的对象全部进行对比：mysqldbcompare –server1=root:root@172. 16. 3. 3:4407 –server2=root:root@172. 16. 3. 3:4408 wstestdb1:wstestdb2 –difftype=SQL –show-reverse -vvv –changes-for=server1 –skip-table-options –run-all-test 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364$ mysqldbcompare --server1=root:root@172. 16. 3. 3:4407 --server2=root:root@172. 16. 3. 3:4408 wstestdb1:wstestdb2 --difftype=SQL --show-reverse -vvv --changes-for=server1 --skip-table-options --run-all-test​# WARNING: Using a password on the command line interface can be insecure. # server1 on 172. 16. 3. 3: . . . connected. # server2 on 172. 16. 3. 3: . . . connected. # Checking databases wstestdb1 on server1 and wstestdb2 on server2#Looking for object types table, view, trigger, procedure, function, and event. Object types found common to both databases:   FUNCTION : 0   TRIGGER : 0    TABLE : 3    EVENT : 0  PROCEDURE : 0     VIEW : 0#                          Defn  Row   Data# Type   Object Name               Diff  Count  Check# -------------------------------------------------------------------------# TABLE   wm_order                FAIL  pass  -#      - Compare table checksum                FAIL#      - Find row differences                 pass# Definition for object wstestdb1. wm_order:. . . . ## INFO: for table wm_order the index PRIMARY is used to compare. ## Transformation for --changes-for=server1:#ALTER TABLE `wstestdb1`. `wm_order` DROP COLUMN company;## Transformation for reverse changes (--changes-for=server2):## ALTER TABLE `wstestdb2`. `wm_order`#  ADD COLUMN company varchar(100) NOT NULL DEFAULT 'Tuya' COMMENT 'company' AFTER alias_name;## TABLE   ws_test_0                pass  pass  -#      - Compare table checksum                FAIL#      - Find row differences                 FAIL# Definition for object wstestdb1. ws_test_0:. . . . ## INFO: for table ws_test_0 the index PRIMARY is used to compare. ## Transformation for --changes-for=server1:#DELETE FROM `wstestdb1`. `ws_test_0` WHERE `id` = '10';INSERT INTO `wstestdb1`. `ws_test_0` (`id`, `name`, `device_id`, `addr`, `alias_name`, `company`) VALUES('12', 'e11', '11', 'D11', 'd11-d', 'd-d-d4');## Transformation for reverse changes (--changes-for=server2):## DELETE FROM `wstestdb2`. `ws_test_0` WHERE `id` = '12';# INSERT INTO `wstestdb2`. `ws_test_0` (`id`, `name`, `device_id`, `addr`, `alias_name`, `company`) VALUES('10', 'e10', '10', 'D10', 'd10-d', 'd-d-d');## TABLE   ws_test_1                pass  FAIL  -#      - Compare table checksum                FAIL#      - Find row differences                 FAIL# Definition for object wstestdb1. ws_test_1:. . . . . . . . . # Database consistency check failed. ## . . . done只要有任何的不一致，结果均为：Database consistency check failed. 查看对比的情况：例如： 一共需要对比两个库的3张TABLES，其中： wm_order表： —- Defination Diff：失败 —- Row count：通过 —-compare checksum：失败 2. 2 注意事项：: （1）由于数据的对比需要抽取源端和目标端的数据进行逐行比对，所以会消耗大量的内存资源，在使用时应该注意 （2）尽量阶段性对比数据，不要一次全量对比很大的数据量，防止对数据源产生影响 三、小结mysqldbcompare可以说是非常常用的一个数据对比工具，在我们测试数据同步、数据迁移的时候，经常会用到，用来判断是否会出现数据不一致的情况，DBA只需使用工具，就可以对于环境中的差异，使得效率大大提高。 欢迎关注公众号：朔的话： "
    }, {
    "id": 26,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-12-comparing-table-difference-by-using-mysqldiff/",
    "title": "MySQL手记12 &#8212; 表结构对比工具mysqldiff",
    "body": "2020/04/26 - 一、功能mysqldiff可以用来比较两个指定数据源中的结构差异，类似于Linux操作系统中的diff命令。 二、使用介绍对于工具的使用，直接使用–help进行查看，对其功能的介绍也及其详细： 1234567891011mysqldiff --helpMySQL Utilities mysqldiff version 1. 6. 5License type: GPLv2Usage: mysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1. object1:db2. object1 db3:db4mysqldiff - compare object definitions among objects where the difference ishow db1. obj1 differs from db2. obj2. . . 可以灵活选用提供的选项进行结构的比对，下文将选取常见的集中情况介绍。 2. 1 使用介绍: （1）不加上–force 说明：若不加上–force选项，则在第一个差异产生的时候，进程就会退出。这样的情况适用于只有少量差异，并逐一对比修改的情况，但是效率较低，通常，我们会把所有的差异查找出来，进行修改。 （2）加上–force进行完整对比 使用mysqldiff对比两个数据库的结构差异 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152mysqldiff --server1=root:root@172. 16. 3. 3:4407 --server2=root:root@172. 16. 3. 3:4408 wstestdb1:wstestdb2 --difftype=SQL --show-reverse -vvv --changes-for=server1 --force# WARNING: Using a password on the command line interface can be insecure. # server1 on 172. 16. 3. 3: . . . connected. # server2 on 172. 16. 3. 3: . . . connected. # Definition for object wstestdb1:CREATE DATABASE `wstestdb1` /*!40100 DEFAULT CHARACTER SET utf8 */# Definition for object wstestdb2:CREATE DATABASE `wstestdb2` /*!40100 DEFAULT CHARACTER SET utf8 */# Comparing `wstestdb1` to `wstestdb2`               [PASS]**###### 第一部分，对比数据库建库的属性是否一致 --【pass】**# Definition for object wstestdb1. wm_order:. . . . # Definition for object wstestdb2. wm_order:. . . . # Comparing `wstestdb1`. `wm_order` to `wstestdb2`. `wm_order`    [PASS]**###### 第二部分，对比wstestdb1. wm_order表结构是否一致 --【pass】**# Definition for object wstestdb1. ws_test_0:. . . . # Definition for object wstestdb2. ws_test_0:. . . . # Comparing `wstestdb1`. `ws_test_0` to `wstestdb2`. `ws_test_0`   [FAIL]**###### 第二部分，对比wstestdb1. ws_test_0表结构是否一致 --【fail】**###由于命令中指定--difftype=SQL --show-reverse --changes-for=server1，所以对比后会提示根据可以在server1上执行 ALTER TABLE `wstestdb1`. `ws_test_0` AUTO_INCREMENT=13, COMMENT='wstest';  即可使结构一致。# Transformation for --changes-for=server1:#ALTER TABLE `wstestdb1`. `ws_test_0`AUTO_INCREMENT=13, COMMENT='wstest';**######由于命令中有-vvv选项，所以会冗余的提示若需要修改server2，则可以执行：ALTER TABLE `wstestdb2`. `ws_test_0` AUTO_INCREMENT=11, COMMENT='wstest'; **# Transformation for reverse changes (--changes-for=server2):## ALTER TABLE `wstestdb2`. `ws_test_0`# AUTO_INCREMENT=11, COMMENT='wstest';## Definition for object wstestdb1. ws_test_1:. . . . . . . . . **######显示最终的结果：**# Compare failed. One or more differences found. （1）可以看出，mysqldiff的对比步骤为：– 对比数据库定义 —-下图part(1)– 对比表结构 —-下图part(2) —-表的定义、字段定义、字段的数量– 汇总结果： 并且在每个步骤结束后，提示reverse的信息 下图part(3) 并且会在每个步骤打印出是否一致（下图箭头指向的部分） （2）提示信息 可以查看上述的加粗部分，每个步骤的提示信息均与命令的选项有关： （3）其它选项 可以看出，两个库（wstestdb1和wstestdb2）中的主要的结构不同，在于对于表的定义，而我们在乎的更多的，可能是表字段的差异，所以，可以选择过滤掉表的定义信息的比较，使用选项： 12 --skip-table-options skip check of all table options (e. g. , AUTO_INCREMENT, ENGINE, CHARSET, etc. ). 示范不对比表的定义： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455mysqldiff --server1=root:root@172. 16. 3. 3:4407 --server2=root:root@172. 16. 3. 3:4408 wstestdb1:wstestdb2 --difftype=SQL --show-reverse -vvv --changes-for=server1 --skip-table-options --force# WARNING: Using a password on the command line interface can be insecure. # server1 on 172. 16. 3. 3: . . . connected. # server2 on 172. 16. 3. 3: . . . connected. # Definition for object wstestdb1:CREATE DATABASE `wstestdb1` /*!40100 DEFAULT CHARACTER SET utf8 */# Definition for object wstestdb2:CREATE DATABASE `wstestdb2` /*!40100 DEFAULT CHARACTER SET utf8 */# Comparing `wstestdb1` to `wstestdb2`               [PASS]# Definition for object wstestdb1. wm_order:. . . . # Definition for object wstestdb2. wm_order:. . . . # Comparing `wstestdb1`. `wm_order` to `wstestdb2`. `wm_order`    [PASS]# Definition for object wstestdb1. ws_test_0:. . . . # Definition for object wstestdb2. ws_test_0:. . . . # Comparing `wstestdb1`. `ws_test_0` to `wstestdb2`. `ws_test_0`   [PASS]# WARNING: Table options are ignored and differences were found:# --- `wstestdb1`. `ws_test_0`# +++ `wstestdb2`. `ws_test_0`# @@ -1,5 +1,5 @@# ENGINE=InnoDB# -AUTO_INCREMENT=11# +AUTO_INCREMENT=13# DEFAULT# CHARSET=utf8mb4# COMMENT='wstest'# Definition for object wstestdb1. ws_test_1:. . . . # Definition for object wstestdb2. ws_test_1:. . . . # Comparing `wstestdb1`. `ws_test_1` to `wstestdb2`. `ws_test_1`   [PASS]# WARNING: Table options are ignored and differences were found:# --- `wstestdb1`. `ws_test_1`# +++ `wstestdb2`. `ws_test_1`# @@ -1,4 +1,5 @@# ENGINE=InnoDB# +AUTO_INCREMENT=12# DEFAULT# CHARSET=utf8mb4# COMMENT='wstest'# Success. All objects are the same. 可以看到： 在出现定义不一致时候，会在注释中打上WARNING，并提示差异。 在忽略了表的定义后，两个库之间结构对比成功，提示：Success. All objects are the same. 三、小结mysqldiff可以方便的对比出两个数据源之间的结构差异，在生产环境中，往往用以比较新、老环境，或者是测试、开发环境之间的差异，非常方便的可以解决这个繁琐的表结构对比步骤，解放DBA的双手。 ps. 若想要对比数据差异，mysqldiff不能做到，此时，就需要另一个工具：mysqldbcompare将在后续介绍。 欢迎关注公众号：朔的话 "
    }, {
    "id": 27,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-9-percona-monitoring-management/",
    "title": "MySQL手记9 &#8212; Percona Monitoring Management（PMM监控）",
    "body": "2020/04/20 - 一、主要技术方案1. 1 PMM: Percona Monitoring Management，下称PMM，Percona的监控管理系统，详情：https://www. percona. com/doc/percona-monitoring-and-management/index. htmlPMM分为两个部分：Client和Server （1）Clinet端：: 由各种exporter（mysql_exporter、mongodb_exporter、node_exporter、redis_exporter…）外加queries工具、pmm-admin工具组成。 pmm-admin为管理工具，例如用以添加、删除所监控数据库实例 pmm-mysql-queries-0 pmm-mongodb-queries-0 这两者用以收集MySQL和MongoDB的query performance发送到QAN API(https://www. percona. com/doc/percona-monitoring-and-management/conf-mysql. html)（其中query的监控需要数据库按照文档进行配置，否则不能进行query监控） （2）Server端：: Query Analytics： QAN API：接收QAN agent传来的数据 QAN Web App：用来展示Query Analytics data的wen应用Metrics Monitor：展示监控数据metrics： Percona Dashboard：Percona一系列Grafana的dashboards Consul：为提供Prometheus hosts的操作（添加、删除）等 Prometheus：连接exporters并聚合其传入的metrics数据 Grafana：用以展示Prometheus的数据Orchestrator：MySQL复制拓扑结构的可视化工具（后续将单独介绍此工具） 虽然新版本的PMM默认为打开，最好在启动时候指定打开Orchestrator： 12docker . . . -e ORCHESTRATOR_ENABLED=true -e ORCHESTRATOR_USER=root -e ORCHESTRATOR_PASSWORD=root . . . Orchestrator地址：http://127. 0. 0. 1/orchestrator 通过如下页面进行添加： 添加后，可以看到添加的实例的拓扑关系： 此外，还可以修改MySQL复制的相关配置： 1. 2 监控实例: 监控实例的添加和删除使用pmm-admin工具进行管理。pmm-admin需要使用root用户运行：pmm-admin –help可以看到使用详情。 1. 3 PMM的安装: 可使用docker进行安装： 12 docker run -d -e METRICS_RETENTION=1440h --name pmm-server-1-2020-2 percona/pmm-server:112可以看到，使用dock er安装时，可以定制化一些需要的配置，例如：12-e METRICS_RETENTION=1440h：metrics保留1440小时还有其它的配置可供挑选：https://www. percona. com/doc/percona-monitoring-and-management/glossary. option. html 二、添加/删除实例2. 1 添加MySQL实例: 12pmm-admin add mysql --user testuser --password passwd --host 192. 168. 0. 1 --port 3306 testdb-master添加完成后，使用pmm-admin工具显示监控的实例列表信息： 2. 2 添加Mongodb实例: 12 pmm-admin add mongodb --uri mongodb://admin:password@172. 27. 2. 1:27017/admin mongodb-001[linux:metrics] OK, already monitoring this system. [mongodb:metrics] OK, now monitoring MongoDB metrics using URI admin:***@172. 27. 2. 1:27017/admin[mongodb:queries] OK, now monitoring MongoDB queries using URI admin:***@172. 27. 2. 1:27017/admin[mongodb:queries] It is required for correct operation that profiling of monitored MongoDB databases be enabled. [mongodb:queries] Note that profiling is not enabled by default because it may reduce the performance of your MongoDB server. [mongodb:queries] For more information read PMM documentation (https://www. percona. com/doc/percona-monitoring-and-management/conf-mongodb. html). 12​同理查看pmm-admin list： 2. 3 添加Redis实例: （1）redis_exporter: 由于PMM本身是不自带Redis监控的，但是其中的Prometheus可以收集到redis的数据，所以可以使用pmm-admin中的external:service来添加Redis实例（例如：https://github. com/oliver006/redis_exporter）: 使用redis_exporter收集metrics，并暴露端口给Prometheus： 12 . /redis_exporter -redis. addr 172. 27. 0. 1:7000 --redis. password redisPasswd -web. listen-address :9121 默认的端口为9121。 （2）PMM添加Redis实例: 12pmm-admin add external:service S-Redis-master-001 --service-port=9121其中–service-port=9121即为上步骤中redis_exporter暴露的端口号。 （3）查看redis实例添加情况: 三、 删除监控实例使用pmm-admin remove，即可方便地删除监控的节点： 1234 pmm-admin remove mysql:metrics tuya_testdb-ind-master OK, removed MySQL metrics mysql-3306-master from monitoring. 四、页面上进行添加/删除实例PMM的dashboards上提供了页面上的操作，详情如下： 点击对应的添加项，可以添加不同类型的实例： 至此，PMM基本介绍完毕，实际环境中，需要对于很多细节进行修改优化，以便更加适用，并降低监控对于​数据库实例的影响。 对于监控数据来说，收集得越仔细，就更容易排查问题，但是也对数据库实例的负载造成影响，所以需要进行权衡，选择更为适宜的比例进行监控​。 欢迎关注公众号：朔的话： "
    }, {
    "id": 28,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note8-comparing-adminmongo-and-mongo-express-data-format/",
    "title": "MySQL手记8 — adminMongo与Mongo-express对比（结果格式差异）",
    "body": "2020/04/15 - 一、adminMongo &amp; Mongo-express介绍：: 12  adminMongo（https://github. com/mrvautin/adminMongo）和Mongo-express（https://github. com/mongo-express/mongo-express）都是非常简单好用的MongoDB可视化展示的工具，在平常的调试或者排查问题中会使用到。1. 1 adminMongo安装: （1）使用git拷贝仓库: 12git clone https://github. com/mrvautin/adminMongo（2）安装: 123cd adminMongo/npm install （3）启动: 12 npm start可以看出，adminMongo的安装及启动都是非常的方便，启动后，直接访问http://localhost:1234 即可。 1. 2 Mongo-express安装: 12  可使用docker进行快速便捷的安装：（1）编辑docker启动mongo-express所需的配置文件: 123456789101112131415161718cat start. ymlversion: '3. 1'services: mongo-express:  image: mongo-express  restart: always  ports:   - 8081:8081  environment:   ME_CONFIG_BASICAUTH_USERNAME: admin   ME_CONFIG_BASICAUTH_PASSWORD: admin   ME_CONFIG_MONGODB_ADMINUSERNAME: mongoadmin   ME_CONFIG_MONGODB_ADMINPASSWORD: mongoroot   ME_CONFIG_MONGODB_ENABLE_ADMIN: 'true'   ME_CONFIG_MONGODB_PORT: 27017   ME_CONFIG_MONGODB_SERVER: 127. 0. 0. 1 （2）使用docker安装及启动: 12docker-compose -f start. yml up二、两者的差异12  近日在查看MongoDB的数据时，发现得到的结果格式不一致，猜想是MongoDB客户端展示的问题，显示如下：adminMongo：: Mongo-express:: 12插入的时候，插入的是一个kv键值对，其中value为json格式。可以看出，对于MongoDB中的document，adminMongo显示为一个包含“_id”的JSON串（并且把原来的JSON串的双引号进行了转义），mongo-express则是展示这个document中的键值对，并保留插入时候的JSON。 两者都可以显示数据，就是展示的格式不同，可以拿到json. cn进行查看： adminMongo：需要先转换一次，再把去除了双引号的value提出来（json串） mongo-express：删除key，直接使用value（json串）进行查看。 欢迎关注公众号：朔的话： "
    }, {
    "id": 29,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-0-mysql-installation/",
    "title": "MySQL手记0 — MySQL安装方式",
    "body": "2020/04/12 - 12  **MySQL的安装，是了解数据库的第一步，安装时的一些内容，可以让我们理解MySQL的文件基本结构。**https://dev. mysql. com/doc/refman/5. 7/en/installation-layouts. html 一、源码安装12  使用源码安装需要首先连接使用cmake安装MySQL所需要的依赖。例如：12345yum install ncurses-devel -yyum install libaio -yyum install glibc-devel. i686 glibc-devel -yyum install gcc gcc-c++ -y当然，对于其中的版本也有依赖，例如MySQL8. 0版本需要gcc版本为4. 8以上，但是CentOS6版本通过yum安装gcc，最高只能到4. 7，所以还需手动安装gcc4. 8。然后再进行cmake的安装： 12345678910cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql \-DMYSQL_DATADIR=/usr/local/mysql/data/ -DSYSCONFDIR=/etc/mysql \-DWITH_INNOBASE_STORAGE_ENGINE=1  \-DMYSQL_TCP_PORT=3306  \-DENABLED_LOCAL_INFILE=1  \-DEXTRA_CHARSETS=all  \-DDEFAULT_CHARSET=utf8  \-DDEFAULT_COLLATION=utf8_general_ci \-DWITH_BOOST=/tmp/boost_1_60_0/12make &amp;&amp; make install对于其中的选项，还需查阅MySQL的官方文档（https://dev. mysql. com/doc/refman/8. 0/en/source-configuration-options. html）。 二、yum安装12  默认Linux系统yum安装大多为MySQL5. 5的稳定版本，版本较老。通常在自己测试，为了方便部署时候，临时可以使用yum的方式进行安装。三、二进制包12  比较建议使用二进制包进行安装，二进制包里面的目录结构较为清晰。除了方便运维管理之外，还方便DBA做自动化部署的流程。二进制包直接展示了MySQL文件的基本结构。例如Percona公司，就提供了二进制包，方便用户的下载使用，用户只需要使用自己的数据库配置文件，就能启动MySQL实例。https://www. percona. com/doc/percona-server/LATEST/index. html 四、Docker安装123  Docker安装通常也是在自己测试的时候使用，并且与yum不同的是，Docker能够很方便的指定版本，譬如想要尝试下MySQL的最新版本，使用Docker可以快速的部署进行使用。通常不建议在生产环境使用Docker进行MySQL的部署，虽然其部署方便快捷，并且重启迁移也很便捷，但是考虑到数据库往往是业务敏感性的，稍微一点的波动或者延迟，可能就会影响到上层应用，所以数据库通常单独拎出来进行部署。  对于Docker部署MySQL，后续会进行介绍，方便各位快速上手使用MySQL。欢迎关注公众号：朔的话： "
    }, {
    "id": 30,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-3-about-mysql-version/",
    "title": "MySQL手记3 &#8212; 关注MySQL版本",
    "body": "2020/04/12 - 一、为什么要不断关注版本​从刚开始工作开始，接触得最多的数据库版本为：MySQL5. 6、MySQL5. 7，甚至有的项目由于时限太长，使用的还是5. 1或是5. 5，也有排查问题时候遇到的5. 1版本（老版本通常是直接通过yum安装的）。 ​对于DBA来说，有的时候在DBA群中讨论较多的话题：MySQL又出新版本了，当然还有官方的worklog里面的工作纪要。对于MySQL来说，由于本身的架构局限，较难满足所有的业务场景。而新的版本，很多时候，带来了很多特性，逐步地满足用户的需要。当然，也会修复部分已知bug，让MySQL更加稳定。 ​目前（2020年4月），MySQL最新的版本是MySQL8. 0，而现在，对于很多公司，生产上用得最多的，应该还是5. 7和5. 6版本，新的8. 0版本，往往是让有强大开发能力的大厂，或是在测试环境进行。目前很多的云厂商RDS，也提供了8. 0的版本。 二、版本的差异我们关注版本，主要就是关注其中的差异，还有对实际生产环境有极大促进作用的特性。考虑是否进行升级，升级又要注意什么？升级流程怎么样等等方面的内容，也将在后续篇章中进行介绍。在生产环境中，对于数据库的版本选择显得尤为重要，因为线上环境往往不能关机或者重启，而数据库的升级，则需要断开所有的连接，这势必会导致很多问题。而怎么选择数据库的版本呢？ 首先，DBA需要了解业务的变动情况: 业务变动对于数据库的影响。例如业务上经常添加列，那么是否可以考虑使用最新的MySQL8. 0版本，可以快速增加列（在8. 0版本之前，添加列需要消耗磁盘的IO去进行表数据的复制）； ​又或者是业务上需要优化很多的表结构，会有大量的添加索引的操作，那么最少使用5. 6的版本，因为5. 6以后，MySQL支持了OnlineDDL。MySQL Online DDL 再次，对于升级的操作难度的评估​: 对于有的业务，在做变动上，具有很大的难度（例如多应用方，或者是项目排期的问题）。这样的情况，DBA往往会采用一些额外的工具，去规避可能出现的问题：例如添加字段、索引、变更字段等等情况，DBA可采用例如pt-online-schema-change、gh-osc（后续会详细介绍）的工具进行，灵活控制数据库的负载，降低出现IO抖动的情况。 12 当然，MySQL的版本更新还在继续，而作为“一线”工作人员，需要不断刷新自己的知识库，任重道远。关于各个版本的对比，可以在官方文档中查看“What is new”的章节(https://dev. mysql. com/doc/refman/8. 0/en/mysql-nutshell. html)，会有详细的介绍，感兴趣的特性别忘了进行测试哟！欢迎关注公众号：朔的话： "
    }, {
    "id": 31,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-7-mysql-utilities-introduction/",
    "title": "MySQL手记7 &#8212; MySQL Utilities工具包",
    "body": "2020/04/12 - 一、MySQL Utilities简介MySQL Utilities是MySQL官方的数据库工具包，下载地址为：https://downloads. mysql. com/archives/utilities/。 该工具包主要是给DBA提供了在运维上可能需要的数据库工具。（官方文档：https://downloads. mysql. com/docs/mysql-utilities-1. 6-en. pdf） 下载后，解压得到如下目录： 12345678910111213build CHANGES. txt docs info. py info. pyc LICENSE. txt mysql PKG-INFO README. txt scripts setup. py unit_tests执行python setup. py install： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061. . . . . . running install_scriptscopying build/scripts-2. 7/mysqlfrm -&gt; /usr/bincopying build/scripts-2. 7/mysqlgrants -&gt; /usr/bincopying build/scripts-2. 7/mysqlbinlogmove -&gt; /usr/bincopying build/scripts-2. 7/mysqldbexport -&gt; /usr/bincopying build/scripts-2. 7/mysqluc -&gt; /usr/bincopying build/scripts-2. 7/mysqlrplshow -&gt; /usr/bincopying build/scripts-2. 7/mysqlrplsync -&gt; /usr/bincopying build/scripts-2. 7/mysqldbcopy -&gt; /usr/bincopying build/scripts-2. 7/mysqlindexcheck -&gt; /usr/bincopying build/scripts-2. 7/mysqlauditgrep -&gt; /usr/bincopying build/scripts-2. 7/mysqlbinlogpurge -&gt; /usr/bincopying build/scripts-2. 7/mysqldbimport -&gt; /usr/bincopying build/scripts-2. 7/mysqldiskusage -&gt; /usr/bincopying build/scripts-2. 7/mysqlfailover -&gt; /usr/bincopying build/scripts-2. 7/mysqlrplcheck -&gt; /usr/bincopying build/scripts-2. 7/mysqlreplicate -&gt; /usr/bincopying build/scripts-2. 7/mysqlmetagrep -&gt; /usr/bincopying build/scripts-2. 7/mysqlauditadmin -&gt; /usr/bincopying build/scripts-2. 7/mysqlslavetrx -&gt; /usr/bincopying build/scripts-2. 7/mysqlrplms -&gt; /usr/bincopying build/scripts-2. 7/mysqldbcompare -&gt; /usr/bincopying build/scripts-2. 7/mysqluserclone -&gt; /usr/bincopying build/scripts-2. 7/mysqlserverinfo -&gt; /usr/bincopying build/scripts-2. 7/mysqlserverclone -&gt; /usr/bincopying build/scripts-2. 7/mysqldiff -&gt; /usr/bincopying build/scripts-2. 7/mysqlbinlogrotate -&gt; /usr/bincopying build/scripts-2. 7/mysqlprocgrep -&gt; /usr/bincopying build/scripts-2. 7/mysqlrpladmin -&gt; /usr/binchanging mode of /usr/bin/mysqlfrm to 755changing mode of /usr/bin/mysqlgrants to 755changing mode of /usr/bin/mysqlbinlogmove to 755changing mode of /usr/bin/mysqldbexport to 755changing mode of /usr/bin/mysqluc to 755changing mode of /usr/bin/mysqlrplshow to 755changing mode of /usr/bin/mysqlrplsync to 755changing mode of /usr/bin/mysqldbcopy to 755changing mode of /usr/bin/mysqlindexcheck to 755changing mode of /usr/bin/mysqlauditgrep to 755changing mode of /usr/bin/mysqlbinlogpurge to 755changing mode of /usr/bin/mysqldbimport to 755changing mode of /usr/bin/mysqldiskusage to 755changing mode of /usr/bin/mysqlfailover to 755changing mode of /usr/bin/mysqlrplcheck to 755changing mode of /usr/bin/mysqlreplicate to 755changing mode of /usr/bin/mysqlmetagrep to 755changing mode of /usr/bin/mysqlauditadmin to 755changing mode of /usr/bin/mysqlslavetrx to 755changing mode of /usr/bin/mysqlrplms to 755changing mode of /usr/bin/mysqldbcompare to 755changing mode of /usr/bin/mysqluserclone to 755changing mode of /usr/bin/mysqlserverinfo to 755changing mode of /usr/bin/mysqlserverclone to 755changing mode of /usr/bin/mysqldiff to 755changing mode of /usr/bin/mysqlbinlogrotate to 755changing mode of /usr/bin/mysqlprocgrep to 755changing mode of /usr/bin/mysqlrpladmin to 755. . . . . . 从安装过程打印的信息来看，该工具包是使用Python进行开发的，并在安装过程把python脚本复制在/use/bin目录下，新增了多个mysql*开头的可执行文件，这些文件，就是Utilities中的工具。后续将逐步介绍常用的集中工具： 和pt工具相比，两个工具包相辅相成，虽说在实际工作中，pt工具用得更多，但是，在部分场景，MySQL Utilities也可以发挥其的作用，灵活运用好这两个工具包，可以让工作更加得心应手。 欢迎关注公众号：朔的话： "
    }, {
    "id": 32,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-6-percona-toolkit-introduction/",
    "title": "MySQL手记6 &#8212; percona-toolkit工具包",
    "body": "2020/04/12 - 一、percona-toolkit工具包介绍percona-toolkit（下称：pt工具），是Percona公司开发的用于数据库的工具包，品类很多，再次就不多做介绍，灵活的使用pt工具，可以极大的简化DBA日常的运维工作，提高工作效率。 （在日常工作中，其实常常用到pt的工具，公司对工具进行了封装，做成为直观的工具） 可在其网站上进行查看：https://www. percona. com/downloads/percona-toolkit/LATEST/pt工具包可大致分为以下几类：（1）开发类工具： pt-duplicate-key-checker pt-online-schema-change pt-query-advisor pt-show-grants pt-upgrade（2）性能类工具： pt-index-usage pt-pmp pt-visual-explain（3）配置类工具： pt-config-diff pt-mysql-summary pt-variable-advisor（4）监控类工具： pt-deadlock-logger pt-fk-error-logger pt-mext pt-query-digest pt-trend（5）复制类工具： pt-heartbeat pt-slave-delay pt-slave-find pt-slave-restart pt-table-checksum pt-table-sync（6）系统类工具： pt-diskstats pt-fifo-split pt-summary pt-stalk（7）实用类工具： pt-archiver pt-find pt-kill 二、安装在官网下载安装包后，解压，得到如下目录及文件： 123456789101112131415bin    CONTRIBUTE. md  COPYING       docs    Gopkg. toml lib     MANIFESTChangelog CONTRIBUTING. md docker-compose. yml Gopkg. lock INSTALL   Makefile. PL README. md其中bin目录下，即为我们所需要的可执行文件：                     pt-align   pt-fk-error-logger       pt-online-schema-change   pt-slave-restart       pt-archiver   pt-heartbeat       pt-pg-summary   pt-stalk       pt-config-diff   pt-index-usage       pt-pmp   pt-summary       pt-deadlock-logger   pt-ioprofile       pt-query-digest   pt-table-checksum       pt-diskstats   pt-kill       pt-secure-collect   pt-table-sync       pt-duplicate-key-checker   pt-mext       pt-show-grants   pt-table-usage       pt-fifo-split   pt-mongodb-query-digest       pt-sift   pt-upgrade       pt-find   pt-mongodb-summary       pt-slave-delay   pt-variable-advisor       pt-fingerprint   pt-mysql-summary       pt-slave-find   pt-visual-explain   对于经常用到的工具，例如使用pt-archiver进行数据的归档、使用pt-online-schema-change进行表结构的变更、使用pt-table-checksum对比两个表的checksum是否一致等等，都能灵活的进行，并且符合运维的思维，添加了很多选项，让我们能够精准的控制整个维护的过程。（后续将介绍常用的几种工具的使用场景）​欢迎关注公众号：朔的话： "
    }, {
    "id": 33,
    "url": "http://localhost:4000/index.php/2020/04/mysql-5-preparing-for-db-upgrade/",
    "title": "MySQL手记5 &#8212; 数据库升级准备",
    "body": "2020/04/09 - 一、升级前准备1. 1 备份数据库: 升级数据库的过程，每一步都需要严格把控，涉及到底层物理存储的变更，容易出现升级后数据库启动失败，或者是升级后数据错乱的风险。所以第一步要做的就是：备份！！ 说到备份，可以说是很多DBA的心声，也经常看到没有备份导致公司损失严重的情况。毕竟数据即财产，不完善的保管，丢失了，可就损失重大。 升级后，由于数据的存储结构可能会发生变化，所以除了基本的物理备份（简单理解为复制数据库的物理文件）外，必须要做逻辑备份。逻辑备份为SQL的形式，导出的数据更加的直观可控。并且，需要在测试环境验证备份文件的有效性（例如可尝试在测试环境进行恢复验证）。（备份的详细介绍会在后续篇章中介绍） 1. 2 流程: 在测试环境中，按照升级的流程老老实实走一遍。包括备份、升级、恢复、验证数据等。（1）在原实例升级 部分场景：例如成本控制，又或者是一些小的项目，没有条件部署新的数据库实例，则需要在原实例下进行升级。这个时候就一定要注意备份，防止进退两难！！ （2）在新实例升级 新建一个新版本的数据库实例，把备份文件还原到新的实例中。物理备份的还原很快，相当于是替换了新的数据库实例的数据文件，但是存在数据物理结构不兼容的风险。逻辑恢复很慢，需要把SQL文件一条条执行结束。而且MySQL的还原是单线程的，所以不支持原生的多线程还原。 当然，可以进行一些“类并发”。我们在备份的时候，将没有关联关系的库表按照大小，可以备份为多个文件进行备份，这样，在恢复的时候，我们就可以多个文件一起执行回放，以达到并发恢复的效果。 （3）新建从库 最常用的方式。生产环境的很多应用，都是不能停机的，没有对应的维护时间段给DBA。这个时候，我们需要采取更为平滑的升级方式。“创建从库”： 即在已有的实例上，新建一个从库，并且保持实时同步。待数据完成同步，延迟降到预测范围内时，应用可以选择在低峰的时段进行逐台切换，业务切换到新的实例上无误，即为升级成功。（由于此方法较为常用，对于此种方式进行升级的过程，会在后续篇章中介绍） 1. 3 测试: 不管是上部分说到的任何一个步骤，在升级之前都需要做好测试，考虑可能发生的情况，并且作出相应的解决方案。数据库在底层，很有可能牵一发而动全身，所以任何步骤的测试，都不能松懈。 二、验证2. 1 数据验证: 数据同步后，需要验证源端、目标端的数据是否一致。此时，可以自己通过脚本，或者工具（例如mysqldbcompare）进行。对于部分云厂商的工具，例如AWS的DMS（数据迁移服务），其提供了数据校验的功能，也可以作为迁移验证数据的参考。 2. 2 应用切换验证: **（1）审计日志: ** 对于是否切换成功，可以查看源端和目标端的审计日志。切换后：源端子啊一段时间内没有对应应用的审计日志，当然目标端会新增这个应用的审计日志。 （2）慢查询日志： 在没有开启审计日志的环境，可以使用慢查询日志进行判断，适当调低慢查询的阈值（ long_query_time， https://dev. mysql. com/doc/refman/8. 0/en/server-system-variables. html#sysvar_long_query_time），从而根据日志判断。（3）Processlist： 可以通过执行： show processlist;（或者查询information_schema. processlist， https://dev. mysql. com/doc/refman/8. 0/en/processlist-table. html）查看应用的连接情况。 12    总之，数据迁移是一个很重要的过程，需规划严格的流程，并制定回滚方案。对于数据库系统，若能够满足业务需求，都是尽量不动，我曾看到过uptime为10+年的数据库系统，不得不佩服开发人员和产品对于该产品的把控程度。欢迎关注公众号：朔的话： "
    }, {
    "id": 34,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-4-sysbench-qps-test/",
    "title": "MySQL手记4 &#8212; Sysbench进行QPS性能测试",
    "body": "2020/04/08 - 一、简介12Sysbench是业内较为常用的测试工具，常用以测试数据库QPS（Queries Per Second），还有系统IO等等。https://launchpad. net/sysbench/在《高性能MySQL》书中也有提到使用Sysbench来进行数据库的压测。 二、基准测试12在做压测之前，需要评估好数据库环境的情况，例如：需要多少数据进行测试，测试选用什么测试算法等等。2. 1 数据量评估: 123根据业务评估最大需要存放多少的数据量，并且做一定的冗余。例如：实际生产需存放50G的数据，最大有200个并发，那么，我们在测试的时候就可以选择30GB～100GB的范围区间进行“阶梯形”压测。为了防止出现内存很大会放下所有数据的情况，所以在压测时候，可使压测的数据量大于数据库（innodb_buffer_pool_size）的大小，这样能测试出更为确切的磁盘IO。2. 2 IO测试模式: 1234本系列主要是以数据库为中心进行介绍，所以本篇也是站在数据库的角度选择测试的模式。对于MySQL数据库，由于数据的存储在逻辑上是按照主键（聚集索引）顺序进行排列，但物理上，由于行信息，头信息（page-head），碎片等因素，真实在物理上则不是顺序的。所以在测试IO的时候，我们选择的test-mode为——“rndrw”（Random Read Write），这也就是为什么我们通常把数据放在SSD上，是因为SSD具有更高的随机读写性能。（PS:对于顺序读写，机械硬盘的性能和SSD相差不会很大，这点也是可以使用sysbench进行测试得到） 2. 2. 1 IO测试: 12由于数据库的性能瓶颈往往在于磁盘的IO，所以测试IO成为了第一个步骤。可参照：MySQL手记2 -- sysbench测试磁盘IO2. 2. 2 IO测试结果解读: 12执行sysbench进行测试后，我们主要关注几个方面：IOPS、吞吐量、延迟情况。（1）IOPS： 12在我们实际环境中，IOPS间接影响了应用的并发，IOPS越高，应用就能够在相同时间内执行更多的查询。而若IOPS较低，那么除了并发的QPS得不到提升之外，SQL可能会因此阻塞，导致大量的慢查，消耗数据库资源。（2）吞吐量： 12部分业务可能会较大的字符串，所以磁盘的吞吐量同样是一个重要的指标，吞吐量越大，能够瞬时IO（INPUT, OUTPUT）的数据也就越多。（3）延迟情况： 12很多对于延迟很敏感的应用，需要及时返回查询结果，读写都很频繁的场景，就会需要我们的磁盘延迟非常低。通常情况下，随着负载的升高，延迟可能会有一定的波动。在测试时，建议：a. 测试的时间需要至少测试1个小时b. 测试的数据量最好是在预估数据量附近的一个范围段，例如需要上线的最大数据量是100GB，则测试80～120GB区间（例如：80GB/90GB/100GB…）c. 相同条件测试3次，取平均值，防止出现偶然情况 2. 3 QPS测试: 12QPS(Queries Per Second)为衡量数据库性能的重要指标。数据库实例QPS越高，那么在生产环境中，就能满足更多的业务负载。对于QPS的测试，尤为重要。例如选择如下的条件： 12sysbench /usr/share/sysbench/oltp_read_write. lua --mysql-host=172. 16. 3. 3 --mysql-port=3306 --mysql-user=root --mysql-password=abcabc --mysql-db=sbtestdb --tables=3 --table-size=50000000 --threads=30 --max-time=90 --report-interval=10 run &amp;（1）sysbench –help 1234567891011121314151617181920212223242526272829303132333435363738sysbench --help​Usage:​ sysbench [options]. . . [testname] [command]​Commands implemented by most tests: prepare run cleanup help​General options: --threads=N           number of threads to use [1] --events=N           limit for total number of events [0] --time=N            limit for total execution time in seconds [10] --forced-shutdown=STRING    number of seconds to wait after the --time limit before forcing shutdown, or 'off' to disable [off] --thread-stack-size=SIZE    size of stack per thread [64K] --rate=N            average transactions rate. 0 for unlimited rate [0] --report-interval=N       periodically report intermediate statistics with a specified interval in seconds. 0 disables intermediate reports [0] --report-checkpoints=[LIST,. . . ] dump full statistics and reset all counters at specified points in time. The argument is a list of comma-separated values representing the amount of time in seconds elapsed from start of test when report checkpoint(s) must be performed. Report checkpoints are off by default. [] --debug[=on|off]        print more debugging info [off] --validate[=on|off]       perform validation checks where possible [off] --help[=on|off]         print help and exit [off] --version[=on|off]       print version and exit [off] --config-file=FILENAME     File containing command line options --tx-rate=N           deprecated alias for --rate [0] --max-requests=N        deprecated alias for --events [0] --max-time=N          deprecated alias for --time [0] --num-threads=N         deprecated alias for --threads [1]​Pseudo-Random Numbers Generator options: --rand-type=STRING random numbers distribution {uniform,gaussian,special,pareto} [special] --rand-spec-iter=N number of iterations used for numbers generation [12] --rand-spec-pct=N percentage of values to be treated as 'special' (for special distribution) [1] --rand-spec-res=N percentage of 'special' values to use (for special distribution) [75] --rand-seed=N   seed for random number generator. When 0, the current time is used as a RNG seed. [0] --rand-pareto-h=N parameter h for pareto distribution [0. 2]​. . . . See 'sysbench &lt;testname&gt; help' for a list of options for each test. （2）lua脚本： bulk_insert. lua oltp_insert. lua oltp_read_write. lua oltp_write_only. lua tests​oltp_common. lua oltp_point_select. lua oltp_update_index. lua select_random_points. lua​oltp_delete. lua oltp_read_only. lua oltp_update_non_index. lua select_random_ranges. lua lua脚本的选择： sysbench提供了多种不同的类型，其中较为常用的为：oltp_read_write. lua（即oltp场景的read&amp;write），当然，可以根据实际的需要，选择只读（oltp_read_only. lua ）、只写（oltp_write_only. lua ）、批量插入（bulk_insert. lua）等等。 （3）其它选项 –threads：并发执行的线程数 通常使用线上可能出现的并发数进行测试 –max-time：运行测试的最长时间，至少测试15分钟 –tables：表的数目，可根据应用情况而定，主要根据大表的数目进行判断 –table-size：表的大小，若为多个表，则每个表的大小均为table-size 2. 4 测试过程: （1）数据准备 123456789101112131415# sysbench /usr/share/sysbench/oltp_read_write. lua --mysql-host=172. 16. 3. 3 --mysql-port=3306 --mysql-user=root --mysql-password=abcabc --mysql-db=sbtestdb --tables=3 --table-size=50000 --threads=30 --max-time=90 --report-interval=10 prepare​sysbench 1. 0. 17 (using system LuaJIT 2. 0. 4)Initializing worker threads. . . ​Creating table 'sbtest2'. . . Creating table 'sbtest3'. . . Creating table 'sbtest1'. . . Inserting 50000 records into 'sbtest1'Inserting 50000 records into 'sbtest2'Inserting 50000 records into 'sbtest3'Creating a secondary index on 'sbtest1'. . . Creating a secondary index on 'sbtest3'. . . Creating a secondary index on 'sbtest2'. . . 12​生成3个表，每个表5​0000行数据。（2）oltp测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# sysbench /usr/share/sysbench/oltp_read_write. lua --mysql-host=172. 16. 3. 3 --mysql-port=3306 --mysql-user=root --mysql-password=abcabc --mysql-db=sbtestdb --tables=3 --table-size=50000 --threads=30 --max-time=90 --report-interval=10 run​sysbench 1. 0. 17 (using system LuaJIT 2. 0. 4)Running the test with following options:Number of threads: 30​Report intermediate results every 10 second(s)Initializing random number generator from current timeInitializing worker threads. . . ​Threads started!​[ 10s ] thds: 30 tps: 168. 27 qps: 3402. 24 (r/w/o: 2388. 13/674. 57/339. 53) lat (ms,95%): 634. 66 err/s: 0. 00 reconn/s: 0. 00[ 20s ] thds: 30 tps: 196. 39 qps: 3923. 33 (r/w/o: 2744. 41/786. 15/392. 77) lat (ms,95%): 196. 89 err/s: 0. 00 reconn/s: 0. 00[ 30s ] thds: 30 tps: 228. 62 qps: 4578. 77 (r/w/o: 3207. 96/913. 57/457. 24) lat (ms,95%): 207. 82 err/s: 0. 00 reconn/s: 0. 00[ 40s ] thds: 30 tps: 254. 63 qps: 5090. 31 (r/w/o: 3561. 16/1019. 90/509. 25) lat (ms,95%): 183. 21 err/s: 0. 00 reconn/s: 0. 00[ 50s ] thds: 30 tps: 217. 37 qps: 4348. 62 (r/w/o: 3045. 12/868. 86/434. 63) lat (ms,95%): 189. 93 err/s: 0. 00 reconn/s: 0. 00[ 60s ] thds: 30 tps: 246. 20 qps: 4922. 70 (r/w/o: 3445. 80/984. 40/492. 50) lat (ms,95%): 186. 54 err/s: 0. 00 reconn/s: 0. 00[ 70s ] thds: 30 tps: 210. 20 qps: 4207. 09 (r/w/o: 2943. 39/843. 30/420. 40) lat (ms,95%): 193. 38 err/s: 0. 00 reconn/s: 0. 00[ 80s ] thds: 30 tps: 216. 30 qps: 4324. 93 (r/w/o: 3030. 35/861. 99/432. 59) lat (ms,95%): 196. 89 err/s: 0. 00 reconn/s: 0. 00[ 90s ] thds: 30 tps: 198. 00 qps: 3963. 07 (r/w/o: 2774. 65/792. 51/395. 91) lat (ms,95%): 200. 47 err/s: 0. 00 reconn/s: 0. 00​SQL statistics:  queries performed:    read:              271460    write:              77560    other:              38780    total:              387800  transactions:            19390 (215. 21 per sec. )  queries:               387800 (4304. 16 per sec. )  ignored errors:           0   (0. 00 per sec. )  reconnects:             0   (0. 00 per sec. )​General statistics:  total time:             90. 0974s  total number of events:       19390Latency (ms):     min:                  8. 11     avg:                 139. 32     max:                 1757. 42     95th percentile:           196. 89     sum:               2701326. 42​Threads fairness:  events (avg/stddev):      646. 3333/6. 16  execution time (avg/stddev):  90. 0442/0. 02​命令指定为每10秒打印一次状态，一共执行90秒（由于此次为展示，所以执行的表数据、时间等都不符合规范）。可以看到平均的结果汇总为： 1234**TPS：215. 21          ## transactions:  19390 (215. 21 per sec. )QPS：4304. 16          ##queries:   387800 (4304. 16 per sec. ) 95%的延时为：196. 89ms  ##95th percentile:           196. 89**1234​通常，结合业务的情况，判读是否能够满足业务需求，例如：​  ​业务需要单实例的QPS在6000左右，那么这个测试的结果就不能够满足需求​  ​有的业务对于数据库响应的延时要求很高，若需要的延时不能超过50毫秒，那么该实例同样也不能满足需求此外，还有许多有趣的测试案例，之前看到的一个有趣的测试案例，测试MySQL的创建连接的性能：https://github. com/jeremycole/yesmark （3）清理 12​测试结束后，记得及时清理数据，防止占用磁盘空间，造成不必要的磁盘浪费：12sysbench /usr/share/sysbench/oltp_read_write. lua --mysql-host=172. 16. 3. 3 --mysql-port=3306 --mysql-user=root --mysql-password=abcabc --mysql-db=sbtestdb --tables=3 --table-size=50000 --threads=30 --max-time=90 --report-interval=10 cleanup2. 4 其它注意事项: 1234​每测试一次，停顿900秒：（1）用于预热数据，避免预热时的I/O影响测试结果；（2）CPU也需要进行“冷处理”，同样《高性能MySQL》一书中推荐两次测试中间间隔15分钟​sysbench所在的实例也需要预留足够的资源：因为sysbench运行的时候，会消耗CPU和内存，所以为了得到更准确的结果，sysbench所在的机器也需要预留足够的配置​ 12​至此，加上上篇的[MySQL手记2 -- sysbench测试磁盘IO](http://codercoder. cn/index. php/2020/04/mysql-note-2-sysbench-iotest/  MySQL手记2 -- sysbench测试磁盘IO )，已经可以使用sysbench测试得到IOPS和QPS/TPS的结果了，这对于业务上线，提供了参考​。压测这一步，也不能马虎​。欢迎关注公众号：朔的话： "
    }, {
    "id": 35,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-2-sysbench-iotest/",
    "title": "MySQL手记2 &#8212; sysbench测试磁盘IO",
    "body": "2020/04/06 - 一、磁盘性能测试对于基础硬件资源的性能测试，刚工作时，我也是人云亦云，不知道为什么要这么去做。在后面的工作中，逐渐意识到了性能压测，又或称其为基准测试的重要性。在MySQL数据库界的一个宝藏书籍：《高性能MySQL》中，就有详细的介绍。 二、Sysbench测试磁盘IO很多人性能压测，就是按照文档跑一遍，这种做法比较差强人意，在生产环境中，上线前对于机器的压测显得尤为重要。 1. 文件大小的选择: 光是这一点列出来，想必大部分人都有恍然大悟的感觉，对于测试IO时候，应当选取多大的数据文件，也是有讲究的：例如线上实际是500GB的数据文件，但是在测试时候只生成了10GB的文件进行IO测试，这样得到的结果，就与实际结果具有较大的误差。 2. 测试过程: Sysbench测试的过程为：（1）生成指定大小和数目的数据文件；（2）按照指定算法运行IO测试；（3）清除数据文件 2. 1 生成文件: 12sysbench --test=fileio --file-total-size=1GB --file-num=128 prepare123​显而易见，生成128个总大小为1GB的文件进行IO测试。​sysbench还有很多的指标，可供测试的时候选用，用以得到最为符合线上情况的效果。 ​在生成文件时，是顺序写入，可以看出该磁盘的顺序写入性能为：179 MiB/s。 2. 2 run: 12sysbench fileio --num-threads=32 --file-total-size=1GB --file-num=10 --file-test-mode=rndrw run主要关注： –file-test-mode，可选的算法有：seqwr, seqrewr, seqrd, rndrd, rndwr, rndrw，即顺序写、顺序读写、顺序读、随机读、随机写、随机读写 虽然MySQL的数据在逻辑上，是按照主键（聚集索引）进行排布的，但是实际在物理，为随机读写rndrw。这点也是在基准测试时，需要着重注意的，而不是当被问到：为什么使用随机读写的时候，自己也一脸懵 由于MySQL的这个属性，所以我们在测试IO的时候同样选择随机读写rndrw进行测试。 12​sysbench在运行时，会打印相关的信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[admin@ws_001 sysbench]$ sysbench fileio --num-threads=32 --file-total-size=1GB --file-num=128 --file-test-mode=rndrw runWARNING: --num-threads is deprecated, use --threads insteadsysbench 1. 0. 17 (using system LuaJIT 2. 0. 4)​Running the test with following options:Number of threads: 32Initializing random number generator from current time​​Extra file open flags: (none)128 files, 8MiB each1GiB total file sizeBlock size 16KiBNumber of IO requests: 0Read/Write ratio for combined random IO test: 1. 50Periodic FSYNC enabled, calling fsync() each 100 requests. Calling fsync() at the end of test, Enabled. Using synchronous I/O modeDoing random r/w testInitializing worker threads. . . ​​Threads started!​​File operations:  reads/s:           2070. 70  writes/s:           1379. 97  fsyncs/s:           4819. 37​​Throughput:  read, MiB/s:         32. 35  written, MiB/s:        21. 56​​General statistics:  total time:             10. 1124s  total number of events:       79547​​Latency (ms):     min:                  0. 00     avg:                  4. 03     max:                 263. 72     95th percentile:            23. 52     sum:                320278. 15​​Threads fairness:  events (avg/stddev):      2485. 8438/187. 43  execution time (avg/stddev):  10. 0087/0. 02​123456​Mbit/s：每秒传输10^6 bit的数据，也写成Mbps​MB/s：每秒传输10^6 byte的数据​MiB/s：每秒传输2^20 byte的数据​可以看到，读写速率为2070reads/s、1379writes/s，读写吞吐量为：32MiB/s、21MiB/s，并且读写的延迟为23. 52毫秒。对比在上个步骤中顺序写入的性能，可以大致猜测该磁盘为机械盘，而非SSD，因为SSD的随机读写的性能很高，并且SSD的随机读写和顺序读写不会相差那么高（这个结论也是多次在机房做基准测试得到的结论）。此次测试的误差其实较大，因为使用较小的文件进行测试，往往很容易受硬件资源抖动的影响。本案例只是用来说明测试需要关注的要点。参考：https://en. wikipedia. org/wiki/Data-rate_units 根据读写量、吞吐量、延迟的情况，可以初步得出结论：该磁盘是否能满足生产环境的要求？​ 此外，通过查看sysbench –help信息，sysbench还可以用来测试CPU、内存等的信息： 至此，sysbench测试磁盘IO的介绍到一段落。测试不是目的，而为什么测试、想要获得什么样的结果，才是我们应该着重关注的，只有测试多种场景，才能使我们的系统在生产环境中更加稳健。欢迎关注公众号：朔的话： "
    }, {
    "id": 36,
    "url": "http://localhost:4000/index.php/2020/04/mysql-note-1-database-system/",
    "title": "MySQL手记1 &#8212; 初识数据库系统",
    "body": "2020/04/06 - 很幸运，毕业的第一家公司，给应届生都安排了导师制，让应届生能够快速的成长起来。刚开始工作时，公司导师和我说：对于数据库来说，最重要的就是两个方面：安全与性能，后期你会发现，我们做的所有的工作，都是围绕着这两个方面进行展开。这句话后来，给了我很多的提示，告诉自己，怎么样才能把工作做好，而工作的重点又是什么。 公司的另一个导师告诉我：学习MySQL数据库，最准确的做法就是：阅读官方文档，然后去测试验证。所以，每每遇到一些疑问，我总是打开官方文档，查看相关的介绍，对于DBA来说，根据官方文档和测试结果，是一项基础的“素质”。测试和验证的过程很磨练人的耐心，但对于这个行业却重要，很多时候都是测试了很多种的场景，最后选出了其中的一个，做为最终上线的架构。 12就拿服务器的选型来说，磁盘这块的测试，为什么选择SSD？做RAID的目的是什么？都是前期测试的结果：一、RAID提到RAID，即磁盘阵列（Redundant Arrays of Independent Disks），往往与运维有关，DBA同样需要知道并了解其中的原理，特别是在自建数据库的环境，一个不小心，很容易造成数据的丢失。 对于RAID的具体介绍，网络上已经有非常详尽的资料，百度百科上也有详细的介绍：磁盘阵列。 1. 1 RAID的选型: RAID的选型，通常考虑两个方面：数据安全、成本。按照不同RAID选型的特性，可以得到： RAID0成本低、性能高，但安全性很低：若数据损坏，无法通过副本或者计算的形式恢复数据 RAID1的成本最高、最安全：RAID1是做数据的全量副本，当一个副本出现数据损坏的时候，可以通过另一个副本得到相同的数据，即损失一半的容量 RAID5的成本居中，但是其至少需要3块盘：总容量是（N－1）×单块硬盘容量（N是硬盘的个数）。比如3块1T的硬盘，组成raid5后就成了2T，还有1T是做校验的（所有校验信息分散放在所有磁盘上） 12更详细的信息可以查看附录分享的一篇文章：https://www. cnblogs. com/Q2881064156/p/7053203. html这也就是为什么在大多数的场景，我们会在数据库的系统中去选用较为安全的Raid10或是Raid5。 二、通用硬件选型2. 1 磁盘选型: 同样，DBA需要对硬件有基础了解，通常CPU和内存，各厂商的差异不会很大。上个部分所说的Raid，也是需要服务器支持Raid卡，这些信息的了解，可以多去几次机房装机测试，多装机几次，会有基本的概念。 12​对于性能差异较大的，主要是在于磁盘上，例如SSD，机械盘等的选型。当然，这些信息并非了解即可，而是需要针对IO，进行测试，包括：IOPS、吞吐量、延迟等等。对于不同的应用环境，同样对于磁盘的要求不同：通常相同容量的SSD的价格远大于机械盘的价格，而由于SSD在随机读写上的速度，远超过机械硬盘，通常我们在MySQL数据库服务器上使用SSD，以得到更高的IO性能。这并非猜测，而是因为对于MySQL的存储来说，物理上是随机读写的，并非顺序的，SSD具有更高的随机IO性能。（当然，若有顺序读写的环境，例如文件系统，使用SSD和机械硬盘的性能差异较小，会选用成本更低的机械硬盘） (​对于IO的测试方法，后续也将会分享) 2. 2 网络: （1）网络 既然说到硬件，还有一个需要着重关注的方面——网络 通常运营商网络有固定的带宽，可以根据需要进行选择。涉及到跨机房，专线等的内容，更是需要考虑到其中的网络延迟，适时调整应用或者数据库的相关配置，以充分利用现有资源。 （后续会详细介绍在跨机房、城市、国家等情况下，数据库应当注意哪些方面，对于数据的同步及一致性等的方面，作出介绍。） （2）网卡 市面上常见的服务器网卡主要是两种：千兆网卡、万兆网卡、光纤网卡 而对于网卡数目，又会有：单网卡、多网卡 通常对于一个数据库服务器来说，需要至少双千兆网卡，在生产环境，许多公司会绑定多个网卡，使得网络更加稳定。 当然，对于并发访问量或者数据传输要求高的场景，可选用万兆网卡甚至是光纤网卡，可以在购买服务器时，和厂家进行适配。 2. 3 附：网络小工具: （1）一个是很简单的ping工具，可以获得点到点的大致网络延迟情况。生产环境中，往往是禁止ping的，可以在测试时候打开，在ping完之后，应该及时禁止ping，防止服务器网络受到ping攻击。 （2）抓包工具。在windows上，用得比较多的是wireshark工具，在linux上，tcpdump也是常用的抓包工具。通过抓包，可以获取到客户端与服务端交互的数据信息。对于DBA来说，数据库环境中，会存在客户端和数据库server连接的问题，而这些问题，又可能与JDBC、线程池等有关系，所以在遇到问题时候，进行抓包，可以使问题的排查更加迅速、准确。 ​本篇主要是一个开篇概括，后续会结合DBA的日常工作，逐步介绍数据库相关的知识点​欢迎关注公众号：朔的话： "
    }, {
    "id": 37,
    "url": "http://localhost:4000/index.php/2019/11/tips-mysql8-default_generated/",
    "title": "Tips: MySQL8.0版本DEFAULT_GENERATED的问题",
    "body": "2019/11/28 - 背景最近使用mysqldiff工具进行多源数据表结构对比时（一个数据源为8. 0版本，另一个为5. 7版本），发现mysqldiff得到的结果中，出现了如下语句： 123ALTER TABLE tb1CHANGE COLUMN create_time create_time timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP DEFAULT_GENERATED COMMENT '创建时间';把mysqldiff生成的sql文件在5. 7版本中回放mysqldiff的结果时候，报错：**ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘DEFAULT_GENERATED COMMENT ‘创建时间’, **  所以推测为8. 0新增的表结构说明，而5. 7版本不兼容 解决8. 0文档对于DEFAULT_GENERATED的说明：DEFAULT_GENERATED for columns that have an expression default value. 即，在column上若有表达式类型的默认值时，会在该行的Extra列打上DEFAULT_GENERATED的tag The latest version of mysql is now adding a DEFAULT_GENERATED tag when a default is explicitly set https://dev. mysql. com/doc/refman/8. 0/en/show-columns. html 登录到数据库中，查看该表的columns信息： 其对于数据无影响，但是在使用mysqldiff工具时候，会把Extra列同样作为一个指标，出现不一致的情况。 解决可以编辑mysqldiff的结果，删除DEFAULT_GENERATED关键字即可。 附加：mysqldiff检查项说明： https://www. percona. com/blog/2015/04/15/checking-table-definition-consistency-mysqldiff/ "
    }, {
    "id": 38,
    "url": "http://localhost:4000/index.php/2019/11/tips-error-when-mysqldump8-dump-from-mysql57/",
    "title": "Tips: mysqldump8.0导出MySQL5.7版本的数据时报错",
    "body": "2019/11/28 - 现象今日在使用mysqldump导出MySQL5. 7版本的数据时，报错：mysqldump版本：8. 0. 17 12345mysqldump -h172. 16. 0. 100 -P3306 -B testdb --compact &gt; testdb_20191123. sql **Warning: A partial dump from a server that has GTIDs will by default include the GTIDs of all transactions, even those that changed suppressed parts of the database. If you don't want to restore GTIDs, pass --set-gtid-purged=OFF. To make a complete dump, pass --all-databases --triggers --routines --events. ****mysqldump: Couldn't execute 'SELECT COLUMN_NAME,            JSON_EXTRACT(HISTOGRAM, '$.  number-of-buckets-specified ')        FROM information_schema. COLUMN_STATISTICS        WHERE SCHEMA_NAME = 'testdb' AND TABLE_NAME = 'st_acc';': Unknown table 'column_statistics' in information_schema (1109)**备份失败，按照提示，是因为找不到information_schema. column_statistics这个元信息表。 解决按照8. 0版本的文档提示，mysqldump加入了该参数 –column-statistics，该参数默认为打开，在dump时，会在information_schema. column_statistics表中检查导出表的信息。 https://dev. mysql. com/doc/refman/8. 0/en/mysqldump. html#option_mysqldump_column-statistics 所以若需要dump出MySQL5. 7的数据，需要设置其为false 12mysqldump -h172. 16. 0. 100 -P3306 -B testdb --compact --column-statistics=0 &gt; testdb_20191123. sql 参考：https://serverfault. com/questions/912162/mysqldump-throws-unknown-table-column-statistics-in-information-schema-1109 "
    }, {
    "id": 39,
    "url": "http://localhost:4000/index.php/2019/11/tips-mysql-restore-error-while-constraint-exists/",
    "title": "Tips: MySQL导入备份sql文件时，外键约束报错",
    "body": "2019/11/28 - 现象最近在导入一个环境的数据的时候，出现了这个报错，备份为使用mysqldump进行的。在导入新环境时，提示：Fail to open the referenced table …. 原因根据报错是外键的问题，此时，由于sql文件中建表的先后顺序，导致打不开需要关联的其它表，会报错。但是由于此阶段还在初始化，所以可以暂时忽略。在导入结束后再去检查外键情况。 解决操作如下，首先创建一个文件，第一行为： 1234echo  set FOREIGN_KEY_CHECKS=0;   &gt; testdb_dump. sql mysqldump -B testdb --compact &gt;&gt; testdb_dump. sql echo  set FOREIGN_KEY_CHECKS=1;   &gt; testdb_dump. sql 注意不要直接vi编辑sql文件，因为如果备份文件过大，则可能会打不开文件，且消耗系统的IO资源。 "
    }, {
    "id": 40,
    "url": "http://localhost:4000/index.php/2019/11/mysql-flush-dirty-pages-causes-slow-queries/",
    "title": "MySQL刷脏让应用抖了一下？",
    "body": "2019/11/19 -  数据库突然出现大量慢查近期应用反馈出现连接被数据库断开的情况，查看应用日志，超过了jdbc的连接时间，没有返回结果，所以应该是慢查导致。但是为什么会突然出现耗时较长的慢查呢？ 问题追溯对照应用的报错时间点，看到在MySQL的错误日志中有如下：  InnoDB: page_cleaner: 1000ms intended loop took 27154ms. The settings might not be optimal. (flushed=27 and evicted=0, during the time. ) 所以是在那个时间的时候，数据库在进行刷脏操作，并且持续了27154ms，page_cleaner_thread接受脏页的数量远远大于它每秒能够处理脏页的能力，所以应用在这个期间内出现了慢查的情况。 How to fix?既然找到了原因，那么就想怎么去规避？ 首先想到的是对于刷脏的控制，查看相关的数据库配置： 12345678innodb_buffer_pool_instances 2innodb_lru_scan_depth 1024innodb_max_dirty_pages_pct 75innodb_max_dirty_pages_pct_lwm 0innodb_io_capacity 20000innodb_io_capacity_max 40000innodb_page_size 16384               优化刷新相关配置：: 1. innodb_buffer_pool_instances通常我们配置和innodb_buffer_pool_instances配置一样。但是在本环境中， 配置为一样的，所以排除这个因素。 2. innodb_lru_scan_depth由于此次刷脏，消耗了大量的io资源，导致大量慢查，所以需要进行优化，以缓解刷脏的消耗，用时间换资源：innodb_lru_scan_depth=1024，默认值较大，若配置较低，或者磁盘的性能不是很高，则可以设置为较小的值官方文档描述：A parameter that influences the algorithms and heuristics for the flush operation for the InnoDB buffer pool. Primarily of interest to performance experts tuning I/O-intensive workloads. It specifies, per buffer pool instance, how far down the buffer pool LRU page list the page cleaner thread scans looking for dirty pages to flush. This is a background operation performed once per second. 控制LRU列表中可用页的数量，从LRU上清理block并将其放到free list上的扫描深度。所以可以降低该值，设置innodb_lru_scan_depth=256； 3. innodb_max_dirty_pages_pct脏页比例，75%为默认值，由于此次刷脏的主要原因更多是在io上，所以暂时不变更这个参数 4. innodb_io_capacity官方：The innodb_io_capacity variable defines the number of I/O operations per second (IOPS) available to InnoDB background tasks, such as flushing pages from the buffer pool and merging data from the change buffer. 该值为InnoDB后台进程（例如从缓冲池刷脏、merge change buffer）能够使用的IOPS的大小。 该实例的配置为20000，根据现状来看，业务在刷脏期间出现大量慢查，所以判断SSD的IOPS不足以分配20000给InnoDB的后台刷脏线程。（由于使用的是tx云数据库，厂商未提供IOPS的监控，所以不能得到确切的值）调整innodb_io_capacity=2000 后记对于刷脏，应当调整数据库的相关配置，使该过程平滑进行，不要影响到业务。在本片文章中，介绍了排查的思路，若在日志中看到刷脏耗时较长，且导致了慢查，可参考本文的思路进行排查。 "
    }, {
    "id": 41,
    "url": "http://localhost:4000/index.php/2019/11/the-regexp-difference-between-mysql57-and-80/",
    "title": "MySQL8.0迁移到5.7中的正则表达REGEXP坑",
    "body": "2019/11/19 - 查不到数据？最近在迁移一个MySQL的环境，出了基本的默认字符集相关的一些差异可以人为预见，迁移过程未出现报错，迁移之后，业务同事反馈说部分应用查不到数据。 反查了一下数据库，数据都是一致的，所以让业务打印出相应的日志。查看里面有这么一条sql： 12select  c1, c2 from t1 where REGEXP '\\btest@111. com\\b'在日志中拎出sql，手动分别在5. 7和8. 0上执行： 12345675. 7：Empty set (0. 00 sec)8. 0:…1 row in set (0. 00 sec)所以猜想就是数据库版本不一致，导致的查询数据失败，查看8. 0版本的官方文档：https://dev. mysql. com/doc/refman/8. 0/en/regexp. html  MySQL implements regular expression support using International Components for Unicode (ICU), which provides full Unicode support and is multibyte safe. (Prior to MySQL 8. 0. 4, MySQL used Henry Spencer’s implementation of regular expressions, which operates in byte-wise fashion and is not multibyte safe. For information about ways in which applications that use regular expressions may be affected by the implementation change, see Regular Expression Compatibility Considerations. )  MySQL从8. 0. 4开始支持ICU包，在此版本之前，用的是Henry Spencer’s引擎，所以本次遇到的情况，恰还是由于两种正则表达式的规则不一致，所以在5. 7版本查询不到数据。 ICU相关正则说明：http://userguide. icu-project. org/strings/regexpSpencer’s引擎正则介绍：https://www. codeproject. com/Articles/4421/Henry-Spencer-s-Regexp-Engine-Revisited 问题fix:对于8. 0：\b为单词边界的标识对于5. 7：\b为空格的标识所以在5. 7中，原sql返回为空。 在原8. 0环境，由于sql语法为 \b ，即想要匹配 test@111. com 两边的单词边界，查阅表中的数据，数据之间是使用分号;进行分隔的，所以在5. 7版本中，换成： 12select  c1, c2 from t1 where REGEXP ';test@111. com;'也可以直接使用like语法： 12select c1, c2 from t1 where like '%test@111. com%'小感想MySQL8. 0支持了更为丰富，也更加规范的正则规则，更加便于开发人员。同样DBA在处理正则匹配的sql时候，应当考虑版本的问题，还有查询性能。 "
    }, {
    "id": 42,
    "url": "http://localhost:4000/index.php/2019/10/springbootapplication-exclude-inoperative/",
    "title": "SpringBootApplication启动排除DataSourceAutoConfiguration不生效???",
    "body": "2019/10/14 - 项目引用了新版本mybatis-spring-boot-starter之后启动不起来，报错Cannot determine embedded database driver class for database type NONE，在网上搜索是需要在排除掉spring自身的org. springframework. boot. autoconfigure. jdbc. DataSourceAutoConfiguration这个类就可以，不让其自动配置。 由于项目是采用spring boot框架，所以在@SpringBootApplication中exclude这个类即可：改之前代码： 12345678910@EnableAutoConfiguration@SpringBootApplication@EnableDubbo(multipleConfig = true)public class Application {  public static void main(String[] args) {    new SpringApplicationBuilder(Application. class). profiles( default ). build(args). run(args);  }}添加DataSourceAutoConfiguration排除之后： 12345678910@EnableAutoConfiguration@SpringBootApplication(exclude = {DataSourceAutoConfiguration. class})@EnableDubbo(multipleConfig = true)public class Application {  public static void main(String[] args) {    new SpringApplicationBuilder(Application. class). profiles( default ). build(args). run(args);  }}本以为这样就成功了，改之后发现重新启动项目还是报一样的错误，就比较奇怪，网上都是这样解决的，自己这里却不行。 现在只能猜测是不是我上面这样配置没生效，根本没有排除掉DataSourceAutoConfiguration呢，然后去debug了下spring这块源码，看spring是如何找到启动注解上要排除的类的。 最终找到了这个类AnnotatedElementUtils#searchWithGetSemanticsInAnnotations方法，该方法是查找该类上某个注解的定义配置的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * This method is invoked by {@link #searchWithGetSemantics} to perform * the actual search within the supplied list of annotations. * &lt;p&gt;This method should be invoked first with locally declared annotations * and then subsequently with inherited annotations, thereby allowing * local annotations to take precedence over inherited annotations. * &lt;p&gt;The {@code metaDepth} parameter is explained in the * {@link Processor#process process()} method of the {@link Processor} API. * @param element the element that is annotated with the supplied * annotations, used for contextual logging; may be {@code null} if unknown * @param annotations the annotations to search in * @param annotationType the annotation type to find * @param annotationName the fully qualified class name of the annotation * type to find (as an alternative to {@code annotationType}) * @param containerType the type of the container that holds repeatable * annotations, or {@code null} if the annotation is not repeatable * @param processor the processor to delegate to * @param visited the set of annotated elements that have already been visited * @param metaDepth the meta-depth of the annotation * @return the result of the processor (potentially {@code null}) * @since 4. 2 */  private static &lt;T&gt; T searchWithGetSemanticsInAnnotations(AnnotatedElement element,      List&lt;Annotation&gt; annotations, Class&lt;? extends Annotation&gt; annotationType,      String annotationName, Class&lt;? extends Annotation&gt; containerType,      Processor&lt;T&gt; processor, Set&lt;AnnotatedElement&gt; visited, int metaDepth) {    // Search in annotations    // 这个for循环是在类上直接定义的注解上进行查找指定的注解    for (Annotation annotation : annotations) {      Class&lt;? extends Annotation&gt; currentAnnotationType = annotation. annotationType();      if (!AnnotationUtils. isInJavaLangAnnotationPackage(currentAnnotationType)) {        if (currentAnnotationType == annotationType ||            currentAnnotationType. getName(). equals(annotationName) ||            processor. alwaysProcesses()) {          T result = processor. process(element, annotation, metaDepth);          if (result != null) {            if (processor. aggregates() &amp;&amp; metaDepth == 0) {              processor. getAggregatedResults(). add(result);            }            else {              return result;            }          }        }        // Repeatable annotations in container?        else if (currentAnnotationType == containerType) {          for (Annotation contained : getRawAnnotationsFromContainer(element, annotation)) {            T result = processor. process(element, contained, metaDepth);            if (result != null) {              // No need to post-process since repeatable annotations within a              // container cannot be composed annotations.               processor. getAggregatedResults(). add(result);            }          }        }      }    }    // Recursively search in meta-annotations    // 如果根据类上直接定义的注解去找不到话，然后在遍历每一个注解，找寻其通过继承关系得到的注解    for (Annotation annotation : annotations) {      Class&lt;? extends Annotation&gt; currentAnnotationType = annotation. annotationType();      if (!AnnotationUtils. isInJavaLangAnnotationPackage(currentAnnotationType)) {        T result = searchWithGetSemantics(currentAnnotationType, annotationType,            annotationName, containerType, processor, visited, metaDepth + 1);        if (result != null) {          processor. postProcess(element, annotation, result);          if (processor. aggregates() &amp;&amp; metaDepth == 0) {            processor. getAggregatedResults(). add(result);          }          else {            return result;          }        }      }    }    return null;  }拿我上面项目例子来说明，上面的代码我配置了@EnableAutoConfiguration和@SpringBootApplication两个注解，@SpringBootApplication里的exclude实际上使用的是@EnableAutoConfiguration里的exclude，所以当spring查找EnableAutoConfiguration这个注解的配置时候，根据上面spring代码可以知道，如果本地配置了，会优先取本地配置的，如果本地没有配置，才会通过第二个for循环，也就是从@SpringBootApplication里面去取，然后我项目代码也配置了@EnableAutoConfiguration，所以优先取本地配置，即在@SpringBootApplication配置的不会生效。 知道了这个结论之后，项目正常启动，改动就很简单了： 12345678910@EnableAutoConfiguration(exclude = {DataSourceAutoConfiguration. class})@SpringBootApplication@EnableDubbo(multipleConfig = true)public class Application {  public static void main(String[] args) {    new SpringApplicationBuilder(Application. class). profiles( default ). build(args). run(args);  }}或者：（推荐使用这种方式） 123456789@SpringBootApplication(exclude = {DataSourceAutoConfiguration. class})@EnableDubbo(multipleConfig = true)public class Application {  public static void main(String[] args) {    new SpringApplicationBuilder(Application. class). profiles( default ). build(args). run(args);  }}总结– 通过查看上面spring代码方法注释也能得到结论，这个方法应该首先调用本地声明的注释然后用继承的注释，从而允许本地注解优先于继承的注解。– @SpringBootApplication是多个注解的组合，其中就已经包含了@EnableAutoConfiguration注解，所以引用了@SpringBootApplication注解之后不需要在手动注解@EnableAutoConfiguration "
    }, {
    "id": 43,
    "url": "http://localhost:4000/index.php/2019/10/inputstream-readbyte/",
    "title": "踩坑之InputStream.read(byte[])方法",
    "body": "2019/10/13 - 项目之前都是好好的，最近现场那边出现一个问题，报错不是合法的json字符串，这个json字符串是通过http请求访问获得的。 通过直接在浏览器上直接访问http这个请求，发现返回的json也是完全正确的。后来排查代码才发现了原来错误出在从字节流中读取数据这里： 看下之前出错代码：这个方法是处理InputStream，然后返回成一个字符串。 12345678910111213public String process(InputStream in, String charset) {   byte[] buf = new byte[1024];   StringBuffer sb = new StringBuffer();   try {     while (in. read(buf) != -1) {       sb. append(new String(buf, charset));     }  } catch (IOException e) {     e. printStackTrace();  }   return sb. toString();}有问题的代码在第6行，发现之前项目没出错的原因是InputStream里面的数据少，还不够1024个字节，while那里循环一次就好了，得到一个正确格式的json串；后面出错了是因为InputStream里面数据比较多，while需要2次了，第一次读取之后buf里面满了，第二次读取发现read(byte[])方法不会去清空缓冲区数组，第二次实际上read字节只有100个，buf里面只替换前100个字节内容，然后通过第6行代码append到字符串里了，就造成了最后获得的字符串不是json格式，造成之后json解析出错。 知道问题后，将之前代码改为下，既然每次不会去清空缓冲区数组内容，那就通过读取长度来append字符串，问题解决： 1234567891011121314public String process(InputStream in, String charset) {  byte[] buf = new byte[1024];  StringBuffer sb = new StringBuffer();  int len = 0;  try {    while ((len=in. read(buf)) != -1) {      sb. append(new String(buf, 0, len, charset));    }  } catch (IOException e) {    e. printStackTrace();  }  return sb. toString();}后来查了下JDK API，发现API上也说明过了，只是以前没注意，关键在于加黑字体，不影响b[k]到b[b. length-1]的元素： 附上API： public int read(byte[] b) throws IOException 从输入流中读取一定数量的字节，并将其存储在缓冲区数组 b 中。以整数形式返回实际读取的字节数。 在输入数据可用、检测到文件末尾或者抛出异常前，此方法一直阻塞。 如果 b 的长度为 0，则不读取任何字节并返回 0；否则，尝试读取至少一个字节。如果因为流位于文件末尾而没有可用的字节，则返回值 -1；否则，至少读取一个字节并将其存储在 b 中。将读取的第一个字节存储在元素 b\[0\] 中，下一个存储在 b\[1\] 中，依次类推。读取的字节数最多等于 b 的长度。设 k 为实际读取的字节数；这些字节将存储在 b\[0\] 到 b\[k-1\] 的元素中，不影响 b\[k\] 到 b\[b. length-1\] 的元素。 "
    }, {
    "id": 44,
    "url": "http://localhost:4000/index.php/2019/10/nlpinpython/",
    "title": "利用python进行自然语言处理（spaCy模块的简单使用）",
    "body": "2019/10/11 - 前言：自然语言处理在数据科学领域中是一个大问题。在这篇文章中，我们来看一下对那些利用Python进行自然语言处理(NLP)的人可以使用的库。 正文：自然语言处理（NLP）是数据科学中最有趣的子领域之一，数据科学家越来越期望能够制定涉及利用非结构化文本数据的解决方案。尽管如此，许多应用数据科学家（来自STEM和社会科学背景）都缺乏NLP经验。在这篇文章中，我将探讨一些基本的NLP概念，并展示如何使用Python中日益流行的spaCy包来实现它们。这篇文章是针对绝对的NLP初学者，但是假设其具备Python的知识。 spaCy, You Say?: spaCy是由Matt Honnibal在Explosion AI开发用于“Python中的工业强度NLP”的相对较新的软件包。它的设计考虑了应用数据科学家，这意味着它不会影响用户决定使用什么深奥的算法来执行常见任务，而且速度快 – 速度极快(因为它在Cython中实现)。如果您熟悉Python数据科学堆栈，那么spaCy相当于用于NLP任务中的numpy – 尽管它相当低级但非常直观且高效。 So, What Can It Do?: 12345678910spaCy为任何NLP项目中常用的任务提供一站式服务，包括：  Tokenization（分词）  Lemmatization（词形还原）  Part-of-speech tagging（词性标注）  Entity recognition（实体识别）  Dependency parsing（依赖解析）  Sentence recognition（句子识别）  Word-to-vector transformations（词向量转换）  Many convenient methods for cleaning and normalizing text（许多方便的方法来清理和规范化文本）我将提供其中一些功能的高级概述，并展示如何使用spaCy访问它们。 Let’s Get Started!: 首先，我们加载spaCy的管道，按照惯例，它存储在一个名为nlp的变量中。声明此变量将需要几秒钟，因为spaCy需将其模型和数据提前加载以节省之后处理的时间。实际上，这会使得前期处理方式变得非常繁重以致于之后每次将nlp解析器应用到数据时都不会产生成本。请注意，在这里，我使用的是英语模型，但也有一个功能齐全的德语模型，在几种语言中实现分词（如下所述）。我们在示例文本上调用NLP来创建Doc对象。 Doc对象现在是用于NLP任务文本本身的容器，文本的切片（Span对象）和元素（Token对象）。值得注意的是，Token和Span对象实际上不包含任何数据。取而代之，它们包含指向Doc对象中包含的数据的指针，并且被懒惰地评估（即根据请求）。 spaCy的大部分核心功能是通过Doc（n = 33），Span（n = 29）和Token（n = 78）对象上的方法访问的。 Spacy安装： 12  pip install spacy下载数据模型： 12  python -m spacy download en_core_web_sm12345In[1]: import spacy. . . : nlp = spacy. load( en_core_web_sm ). . . : doc = nlp( The big grey dog ate all of the chocolate,        but fortunately he wasn't sick! )Tokenization: 分词是许多NLP任务的基础步骤。对文本分词是将一段文本拆分为单词，符号，标点符号，空格和其他元素的过程，从而创建标记。一种天真的方法是简单地以空格拆分字符串： 123456789101112131415161718In[2]: doc. text. split() . . . :Out[2]:['The', 'big', 'grey', 'dog', 'ate', 'all', 'of', 'the', 'chocolate,', 'but', 'fortunately', 'he',  wasn't , 'sick!']从表面上看，这看起来很好。但请注意，它忽略了标点符号，并且不会分割动词和副词（“是”，“不是”）。换句话说，它是天真的，它无法帮助我们（和机器）识别文本元素去理解其结构和意义。让我们看看spaCy如何处理这个问题： 123456789101112131415161718192021In[3]: [token. orth_ for token in doc] . . . :Out[3]:['The', 'big', 'grey', 'dog', 'ate', 'all', 'of', 'the', 'chocolate', ',', 'but', 'fortunately', 'he', 'was',  n't , 'sick', '!']在这里，我们访问每个词的. orth_方法，该方法返回词的字符串表示，而不是SpaCy词对象。这可能并不总是可取的，但值得注意。 SpaCy识别标点符号，并能够从单词标记中分割这些标点符号。许多SpaCy的词方法都提供了已处理文本的字符串和整数表示：带有下划线后缀的方法返回字符串和没有下划线后缀的方法返回整数。例如： 1234567891011121314151617181920In[4]: [(token, token. orth_, token. orth) for token in doc] . . . :Out[4]: [(The, 'The', 5059648917813135842), (big, 'big', 15511632813958231649), (grey, 'grey', 10475807793332549289), (dog, 'dog', 7562983679033046312), (ate, 'ate', 10806788082624814911), (all, 'all', 13409319323822384369), (of, 'of', 886050111519832510), (the, 'the', 7425985699627899538), (chocolate, 'chocolate', 10946593968795032542), (,, ',', 2593208677638477497), (but, 'but', 14560795576765492085), (fortunately, 'fortunately', 13851269277375979931), (he, 'he', 1655312771067108281), (was, 'was', 9921686513378912864), (n't,  n't , 2043519015752540944), (sick, 'sick', 14841597609857081305), (!, '!', 17494803046312582752)]去除所有标点符号和空格 12345678910111213141516171819In[5]: [token. orth_ for token in doc if not token. is_punct | token. is_space] . . . :Out[5]:['The', 'big', 'grey', 'dog', 'ate', 'all', 'of', 'the', 'chocolate', 'but', 'fortunately', 'he', 'was',  n't , 'sick']很酷，对吗？ Lemmatization: 分词的相关任务是词形还原。词形还原是将单词缩减为基本形式的过程 – 如果你愿意的话，它的母语单词。单词的不同用法通常具有相同的根含义。例如，practice，practiced和practising基本上都是指同一件事。通常希望标准化与其基本形式具有相似含义的单词。使用SpaCy，我们可以使用词的. lemma_方法访问每个单词的基本形式： 1234567In[6]: practice =  practice practiced practicing  . . . : nlp_practice = nlp(practice) . . . : [word. lemma_ for word in nlp_practice] . . . :Out[6]:['practice', 'practice', 'practice']为什么这有用？一个直接的用例是机器学习，特别是文本分类。例如，在创建“词袋”之前对文本进行词形还原可以避免单词重复，因此，允许模型在多个文档中构建更清晰的单词使用模式图像。 POS Tagging: 词性标注是将语法属性（即名词，动词，副词，形容词等）分配给单词的过程。共享相同POS标签的单词倾向于遵循类似的句法结构，并且在基于规则的处理中很有用。例如，在事件的给定描述中，我们可能希望确定谁拥有什么。通过利用所有格，我们可以做到这一点（提供文本在语法上是合理的！）。SpaCy使用流行的Penn Treebank POS标签（见这里，https://www. ling. upenn. edu/courses/Fall_2003/ling001/penn_treebank_pos. html）。使用SpaCy，您可以分别使用. pos_和. tag_方法访问粗粒度和细粒度POS标签。在这里，我访问细粒度的POS标签： 1234567891011121314151617181920212223In[7]: doc2 = nlp( Conor's dog's toy was hidden under the man's sofa in the woman's house ). . . : pos_tags = [(i, i. tag_) for i in doc2]. . . : pos_tags. . . :Out[7]:[(Conor, 'NNP'),('s, 'POS'),(dog, 'NN'),('s, 'POS'),(toy, 'NN'),(was, 'VBD'),(hidden, 'VBN'),(under, 'IN'),(the, 'DT'),(man, 'NN'),('s, 'POS'),(sofa, 'NN'),(in, 'IN'),(the, 'DT'),(woman, 'NN'),('s, 'POS'),(house, 'NN')]我们可以看到’s这些词被标记为POS。我们可以利用此标记来提取所有者及其拥有的东西： 123456789101112In[8]: owners_possessions = []. . . : for i in pos_tags:. . . :   if i[1] ==  POS :. . . :     owner = i[0]. nbor(-1). . . :     possession = i[0]. nbor(1). . . :     owners_possessions. append((owner, possession)). . . :. . . : owners_possessions. . . :Out[8]:[(Conor, dog), (dog, toy), (man, sofa), (woman, house)]这将返回所有者拥有元组的列表。如果你想成为关于它的超级Pythonic，你可以在列表理解（使用python的列表推导式）中做到这一点（我认为这是更好的！）： 12345In[9]: [(i[0]. nbor(-1), i[0]. nbor(+1)) for i in pos_tags if i[1] ==  POS ]. . . :Out[9]:[(Conor, dog), (dog, toy), (man, sofa), (woman, house)]在这里，我们使用每个词的. nbor方法，该方法返回词的相邻的词。 Entity Recognition: 实体识别是将文本中找到的命名实体分类为预定义类别（如人员，地点，组织，日期等）的过程. spaCy使用统计模型对广泛的实体进行分类，包括人员，事件，艺术作品和国籍/宗教（参见完整清单的文件, https://spacy. io/usage/entity-recognition%29. ）。例如，让我们从巴拉克奥巴马的维基百科条目中获取前两句话。我们将解析此文本，然后使用Doc对象的. ents方法访问已识别的实体。通过在Doc上调用此方法，我们可以访问其他词方法，特别是. label_和. label： 123456789101112131415161718192021In[10]: wiki_obama =    Barack Obama is an American politician who served as. . . : the 44th President of the United States from 2009 to 2017. He is the first. . . : African American to have served as president,. . . : as well as the first born outside the contiguous United States.    . . . :. . . : nlp_obama = nlp(wiki_obama). . . : [(i, i. label_, i. label) for i in nlp_obama. ents]. . . :Out[10]:[(Barack Obama, 'PERSON', 380), (American, 'NORP', 381), (44th, 'ORDINAL', 396), (the United States, 'GPE', 384), (2009, 'DATE', 391), (2017, 'DATE', 391), (first, 'ORDINAL', 396), (African, 'NORP', 381), (American, 'NORP', 381), (first, 'ORDINAL', 396), (United States, 'GPE', 384)]您可以看到模型已识别的实体以及它们的准确程度（在本例中）。 PERSON不用多说，指的是人名，NORP 是国籍或宗教团体，GPE识别位置（城市，国家等），DATE识别特定日期或日期范围，ORDINAL识别代表一些顺序类型的单词或数字。虽然我们讨论的是Doc方法的主题，但值得一提的是spaCy的句子识别器。 NLP任务想要将文档拆分成句子 并不罕见。通过访问Doc’s. sents方法，可以很容易地使用SpaCy执行此操作： 123456789In[11]: for ix, sent in enumerate(nlp_obama. sents, 1):. . . :    print( Sentence number {}: {} . format(ix, sent)). . . :Sentence number 1: Barack Obama is an American politician who served asthe 44th President of the United States from 2009 to 2017. Sentence number 2: He is the firstAfrican American to have served as president,as well as the first born outside the contiguous United States. 就这样。在后面的文章中，我将展示如何在复杂的数据挖掘和ML任务中使用spaCy。 译自：https://dzone. com/articles/nlp-in-python (by Jayesh Bapu Ahire Mar. 13. 18)翻译：by Janvn in Aug. 17. 2019 测试环境：win10Python环境：Python 3. 7. 3 | AnacondaspaCy使用方法：https://github. com/explosion/spaCy "
    }, {
    "id": 45,
    "url": "http://localhost:4000/index.php/2019/10/mysql-delete-deallock-1/",
    "title": "MySQL删除数据死锁案例分析",
    "body": "2019/10/09 -  表结构: 123456789101112131415CREATE TABLE if not exists `queue` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键ID', `unit_id` varchar(64) NOT NULL , `queue_id` varchar(32) NOT NULL , `mq_keys` varchar(64) NOT NULL , `mq_tags` varchar(64) NOT NULL , `mq_body` varchar(2048) DEFAULT NULL , `expect_tm` datetime NOT NULL , `ins_tm` datetime NOT NULL , `upd_tm` datetime NOT NULL , PRIMARY KEY (`id`), UNIQUE KEY `uniq_keys_tags` (`mq_keys`,`mq_tags`) USING BTREE, KEY `idx_queue_id_expect_tm` (`queue_id`,`expect_tm`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8死锁业务场景: 发生死锁场景是针对于同一条数据，并发情况下，一个请求根据唯一索引去删除该条数据；另一个请求是根据主键id去删除该条数据 死锁日志: 12345678910111213141516171819202122232425262728293031323334353637------------------------LATEST DETECTED DEADLOCK------------------------2018-10-21 16:36:11 7fe396bec700*** (1) TRANSACTION:TRANSACTION 6247680825, ACTIVE 0. 003 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 3 lock struct(s), heap size 1184, 2 row lock(s)LOCK BLOCKING MySQL thread id: 168275072 block 168314813MySQL thread id 168314813, OS thread handle 0x7fe394a79700, query id 11307015122 110. 24. 17. 162 queue updatingdelete from `queue`   WHERE ( mq_keys = '359843651133825024'         and mq_tags = 'test' )*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 28 page no 41578 n bits 160 index `PRIMARY` of table `db`. `queue` trx id 6247680825 lock_mode X locks rec but not gap waitingRecord lock, heap no 37 PHYSICAL RECORD: n_fields 11; compact format; info bits 32*** (2) TRANSACTION:TRANSACTION 6247680812, ACTIVE 0. 005 sec updating or deletingmysql tables in use 1, locked 13 lock struct(s), heap size 1184, 2 row lock(s), undo log entries 1MySQL thread id 168275072, OS thread handle 0x7fe396bec700, query id 11307015098 110. 24. 17. 162 queue updatingdelete from `queue`  where id = 359848240616589824*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 28 page no 41578 n bits 160 index `PRIMARY` of table `db`. `queue` trx id 6247680812 lock_mode X locks rec but not gapRecord lock, heap no 37 PHYSICAL RECORD: n_fields 11; compact format; info bits 32*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 28 page no 7583 n bits 344 index `uniq_keys_tags` of table `db`. `queue` trx id 6247680812 lock_mode X locks rec but not gap waitingRecord lock, heap no 275 PHYSICAL RECORD: n_fields 3; compact format; info bits 0*** WE ROLL BACK TRANSACTION (1)死锁日志分析:       步骤   事务1   事务2         1   begin:   begin:       2       delete from queue where id = ? （事务2获得锁：2 lock struct(s)：2种锁结构，分别为IX和主键的行锁）       3   delete from queue WHERE ( mq_keys = ? and mq_tags = ? ) (事务1此时需要获得锁：3 lock struct(s)：3种锁结构，分别为IX，uniq_keys_tags（该keys_tags唯一索引锁）和主键的行锁，此时由于事务2获得了主键的行锁，所以事务1在这里只能获取到：IX，uniq_keys_tags两个锁，等待事务2释放主键的行锁)           4       事务2继续获取锁：在找到id=x 的记录，对id=x 记录加上X锁之后，同时，会根据读取到的keys_tags列，然后将唯一索引上的keys_tags对应的索引项加X锁此时由于事务一已经拿到了该条记录唯一索引上的锁，需要等待事务1释放，于是死锁   总结: 项目中删除数据最少都是根据主键id去删除，减少死锁的可能 参考文档: https://blog. csdn. net/oyl822/article/details/42297773https://www. centos. bz/2017/09/mysql-delete-%e5%88%a0%e9%99%a4%e8%af%ad%e5%8f%a5%e5%8a%a0%e9%94%81%e5%88%86%e6%9e%90/ "
    }, {
    "id": 46,
    "url": "http://localhost:4000/index.php/2019/10/restore-oracle-datafile-with-linux-file-handle/",
    "title": "Linux下基于文件句柄的方式恢复oracle数据文件",
    "body": "2019/10/09 - 前言对于Linux下误删除Oracle数据文件，可以通过句柄方式来快速恢复数据文件，但是需要存在一定的前提，数据库与服务器均未发生重启，这样可以快速恢复。不然就需要通过RMAN进行restore/recover。*重启需谨慎，关库有风险！！！* 模拟删除数据文件123[oracle@dba1 ~]$ cd /home/oracle/app/oradata/orcl/ORCL/datafile/[oracle@dba1 datafile]$ rm -rf o1_mf_tbs_face_fnrowob1_. dbf查看数据库状态12345SQL&gt; select open_mode from v$database;OPEN_MODE------------------------------------------------------------READ WRITE获取DBW0进程号通过进程号来获取到各Oracle文件的句柄号 12345678910111213141516171819202122232425262728293031323334353637383940414243[oracle@dba1 ~]$ ps -ef|grep -v grep |grep dbw0oracle  16678   1 0 Jul16 ?    00:00:06 ora_dbw0_dssc[oracle@dba1 ~]$ cd /proc/16678/fd[oracle@dba1 fd]$ ls -ltotal 0lr-x------ 1 oracle oinstall 64 Jul 17 09:23 0 -&gt; /dev/nulll-wx------ 1 oracle oinstall 64 Jul 17 09:23 1 -&gt; /dev/nulllrwx------ 1 oracle oinstall 64 Jul 17 09:23 10 -&gt; /home/oracle/app/oracle/product/11. 2. 0/dbhome_1/dbs/lkDSSClr-x------ 1 oracle oinstall 64 Jul 17 09:23 11 -&gt; /home/oracle/app/oracle/product/11. 2. 0/dbhome_1/rdbms/mesg/oraus. msbl-wx------ 1 oracle oinstall 64 Jul 17 09:23 2 -&gt; /dev/nulllrwx------ 1 oracle oinstall 64 Jul 17 09:23 256 -&gt; /home/oracle/app/oradata/orcl/control01. ctllrwx------ 1 oracle oinstall 64 Jul 17 09:23 257 -&gt; /home/oracle/app/oradata/orcl/control02. ctllrwx------ 1 oracle oinstall 64 Jul 17 09:23 258 -&gt; /home/oracle/app/oradata/orcl/control03. ctllrwx------ 1 oracle oinstall 64 Jul 17 09:23 259 -&gt; /home/oracle/app/oradata/orcl/system01. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 260 -&gt; /home/oracle/app/oradata/orcl/sysaux01. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 261 -&gt; /home/oracle/app/oradata/orcl/undotbs01. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 262 -&gt; /home/oracle/app/oradata/orcl/users01. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 263 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_fmd5mfgl_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 264 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_idx_fmd5mhck_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 265 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_bigd_fmd5mjn8_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 266 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_bigd_fmd5mlhj_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 267 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_test_fmd5mmpc_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 268 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_test_fmd5mnr3_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 269 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_fmdsdobv_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 270 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_idx_fmdsj5dg_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 271 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_test_fmdsm22d_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 272 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_test_fmdsp0k8_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 273 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_bigd_fmdsryq1_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 274 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_bigd_fmdsxpv7_. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 275 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fmttspfy_. dbf&lt;u&gt;&lt;b&gt;&lt;i&gt;**lrwx------ 1 oracle oinstall 64 Jul 17 09:23 276 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fnrowob1_. dbf (deleted)**&lt;/i&gt;&lt;/b&gt;&lt;/u&gt;lrwx------ 1 oracle oinstall 64 Jul 17 09:23 277 -&gt; /home/oracle/app/oradata/orcl/undotbs03. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 278 -&gt; /home/oracle/app/oradata/orcl/temp01. dbflrwx------ 1 oracle oinstall 64 Jul 17 09:23 279 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_temp_fmc6m2q4_. tmplrwx------ 1 oracle oinstall 64 Jul 17 09:23 280 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_temp_fmc6m2ts_. tmplrwx------ 1 oracle oinstall 64 Jul 17 09:23 281 -&gt; /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_temp_fmc6m2vz_. tmplr-x------ 1 oracle oinstall 64 Jul 17 09:23 3 -&gt; /dev/nulllr-x------ 1 oracle oinstall 64 Jul 17 09:23 4 -&gt; /dev/nulllr-x------ 1 oracle oinstall 64 Jul 17 09:23 5 -&gt; /dev/nulllr-x------ 1 oracle oinstall 64 Jul 17 09:23 6 -&gt; /home/oracle/app/oracle/product/11. 2. 0/dbhome_1/rdbms/mesg/oraus. msblr-x------ 1 oracle oinstall 64 Jul 17 09:23 7 -&gt; /proc/16678/fdlr-x------ 1 oracle oinstall 64 Jul 17 09:23 8 -&gt; /dev/zero数据文件已提示删除Oracle数据文件/home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fnrowob1_. dbf已提示被删除，物理文件已不存在 123[oracle@dba1 fd]$ ls -l /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fnrowob1_. dbfls: cannot access /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fnrowob1_. dbf: No such file or directory还原数据文件通过句柄号276，进行复制 1234[oracle@dba1 fd]$ cp /proc/16678/fd/276 /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fnrowob1_. dbf[oracle@dba1 fd]$ ls -l /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fnrowob1_. dbf-rw-r----- 1 oracle oinstall 10737426432 Jul 17 09:37 /home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fnrowob1_. dbf数据文件的offline与online确认复制完成后在去offline操作，修复好之后再去online操作 1234567SQL&gt; alter database datafile '/home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fnrowob1_. dbf' offline;数据库已更改。SQL&gt; recover datafile '/home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fnrowob1_. dbf';完成介质恢复。SQL&gt; alter database datafile '/home/oracle/app/oradata/orcl/ORCL/datafile/o1_mf_tbs_face_fnrowob1_. dbf' online;数据库已更改。检查数据库告警日志12[oracle@dba1 fd]$tail -f /home/oracle/alert_orcl. log后续其实通过句柄方式恢复过程中最重要的是数据文件的offline与online的顺序，一定先offline数据文件后执行recover在去online，如果顺序发生错误，那么这种方式基本就行不通了。需要考虑rman方式进行restore与recover。任何时候重启数据库与服务器都需要谨慎，避免带来更为严重的故障。 "
    }, {
    "id": 47,
    "url": "http://localhost:4000/index.php/2019/10/sql-execution-plan/",
    "title": "oracle获取SQL执行计划常用方法",
    "body": "2019/10/09 -  前言oracle执行计划其实就是oracle内部的机器级代码，决定如何访问存储器来得到想要的结果，主要内容有：访问方式与访问顺序。 基于Centos6. 7下的单机Oracle11. 2. 0. 4数据库环境 示例SQL为SELECT EMPNO, ENAME, JOB FROM SCOTT. EMP WHERE EMPNO &gt; 7800; 使用explain plan for1234567891011121314151617SQL&gt; SET LINESIZE 999 PAGESIZE 999 LONG 999SQL&gt; EXPLAIN PLAN FOR SELECT EMPNO, ENAME, JOB FROM SCOTT. EMP WHERE EMPNO &gt; 7800;SQL&gt; select * from table(dbms_xplan. display());PLAN_TABLE_OUTPUT---------------------------------------------------------------------------------------Plan hash value: 169057108--------------------------------------------------------------------------------------| Id | Operation          | Name  | Rows | Bytes | Cost (%CPU)| Time   |--------------------------------------------------------------------------------------|  0 | SELECT STATEMENT      |    |   3 |  54 |   2  (0)| 00:00:01 ||  1 | TABLE ACCESS BY INDEX ROWID| EMP  |   3 |  54 |   2  (0)| 00:00:01 ||* 2 |  INDEX RANGE SCAN     | PK_EMP |   3 |    |   1  (0)| 00:00:01 |--------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------  2 - access( EMPNO &gt;7800)优点: 不需要真实执行业务SQL，可快速获取SQL执行计划。 缺点: 无法判断表被访问多少次、处理多少行、逻辑读、物理读情况 使用set autotrace on1234567891011121314151617181920212223242526272829303132333435363738SQL&gt; SET LINESIZE 999 PAGESIZE 999 LONG 999SQL&gt; SET AUTOTRACE ONSQL&gt; SELECT EMPNO, ENAME, JOB FROM SCOTT. EMP WHERE EMPNO &gt; 7800;   EMPNO ENAME             JOB---------- ------------------------------ ---------------------------   7839 KING              PRESIDENT   7844 TURNER             SALESMAN   7876 ADAMS             CLERK   7900 JAMES             CLERK   7902 FORD              ANALYST   7934 MILLER             CLERK执行计划----------------------------------------------------------Plan hash value: 169057108--------------------------------------------------------------------------------------| Id | Operation          | Name  | Rows | Bytes | Cost (%CPU)| Time   |--------------------------------------------------------------------------------------|  0 | SELECT STATEMENT      |    |   3 |  54 |   2  (0)| 00:00:01 ||  1 | TABLE ACCESS BY INDEX ROWID| EMP  |   3 |  54 |   2  (0)| 00:00:01 ||* 2 |  INDEX RANGE SCAN     | PK_EMP |   3 |    |   1  (0)| 00:00:01 |--------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------  2 - access( EMPNO &gt;7800)统计信息----------------------------------------------------------     0 recursive calls     0 db block gets     4 consistent gets     0 physical reads     0 redo size    829 bytes sent via SQL*Net to client    524 bytes received via SQL*Net from client     2 SQL*Net roundtrips to/from client     0 sorts (memory)     0 sorts (disk)     6 rows processed优点: 可以体现大致的逻辑读、物理读、递归调用情况 缺点: 必须等业务SQL执行完毕后才能获取到执行计划；无法判断表被访问多少次 使用statistics_level1234567891011121314151617181920212223242526272829SQL&gt; alter session set statistics_level=all;SQL&gt; SET LINESIZE 999 PAGESIZE 999 LONG 999SQL&gt; SELECT EMPNO, ENAME, JOB FROM SCOTT. EMP WHERE EMPNO &gt; 7800;   EMPNO ENAME             JOB---------- ------------------------------ ---------------------------   7839 KING              PRESIDENT   7844 TURNER             SALESMAN   7876 ADAMS             CLERK   7900 JAMES             CLERK   7902 FORD              ANALYST   7934 MILLER             CLERKSQL&gt; select * from table(dbms_xplan. display_cursor(null, null, 'allstats last'));PLAN_TABLE_OUTPUT-----------------------------------------------------------------------------------------------SQL_ID 7zhmdhvvn4wu2, child number 1-------------------------------------SELECT EMPNO, ENAME, JOB FROM SCOTT. EMP WHERE EMPNO &gt; 7800Plan hash value: 169057108------------------------------------------------------------------------------------------------| Id | Operation          | Name  | Starts | E-Rows | A-Rows |  A-Time  | Buffers |------------------------------------------------------------------------------------------------|  0 | SELECT STATEMENT      |    |   1 |    |   6 |00:00:00. 01 |    4 ||  1 | TABLE ACCESS BY INDEX ROWID| EMP  |   1 |   3 |   6 |00:00:00. 01 |    4 ||* 2 |  INDEX RANGE SCAN     | PK_EMP |   1 |   3 |   6 |00:00:00. 01 |    2 |------------------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------  2 - access( EMPNO &gt;7800)优点: 从Starts分析可以明确知道表被访问多少次；从E-ROWS和A-ROWS对比获取到预估的行数和实际的行数，某些特定业务可以通过此种方式数据总数； 缺点: 必须等业务SQL执行完毕后才能获取到执行计划；无法获取递归调用的次数与物理读的数值； 使用10046事件1234567891011121314151617181920SQL&gt; ALTER SESSION SET TRACEFILE_IDENTIFIER='dba';SQL&gt; ALTER SESSION SET EVENTS '10046 trace name context forever ,level 12';SQL&gt; ALTER SESSION SET MAX_DUMP_FILE_SIZE='UNLIMITED';SQL&gt; SELECT EMPNO, ENAME, JOB FROM SCOTT. EMP WHERE EMPNO &gt; 7800;   EMPNO ENAME             JOB---------- ------------------------------ ---------------------------   7839 KING              PRESIDENT   7844 TURNER             SALESMAN   7876 ADAMS             CLERK   7900 JAMES             CLERK   7902 FORD              ANALYST   7934 MILLER             CLERKSQL&gt; ALTER SESSION SET EVENTS '10046 trace name context off';SQL&gt; SELECT DISTINCT(M. SID) ,P. PID,P. TRACEFILE FROM V$MYSTAT M,V$SESSION S ,V$PROCESS P WHERE M. SID=S. SID AND S. PADDR = P. ADDR;    SID    PID TRACEFILE---------- ---------- ---------------------------------------------------------   1012     28 /u01/app/diag/rdbms/orcl/orcl/trace/orcl_ora_8820_dba. trc[oracle@dba1 ~]$ tkprof /u01/app/diag/rdbms/orcl/orcl/trace/orcl_ora_8820_dba. trc output=/home/oracle/dba_10046[oracle@dba1 ~]$ ls -l /home/oracle/dba_10046. prf优点: 可以获取到SQL解析事件、执行时间、等待事件、产生行数、物理读；可以跟踪整个SQL执行 缺点: 操作步骤多;无法获取表被访问次数;执行计划中的谓语部分不能清晰显示 使用awrsqrpt. sql12SQL&gt; @?/rdbms/admin/awrsqrpt. sql依次输入report_type、num_days、begin_snap、end_snap、sql_id就会生成一份html报告。 优点: 可以获取到总的消耗CPU事件、执行次数、逻辑读、物理读等. 缺点: 操作步骤多，必须知道SQL的SQL_ID与两个快点间隔是否存在此SQL运行. 总结不同的应用场景下选择不同的方法，可快速获取到SQL执行计划。当然也可以使用PL/SQL工具选中SQL语句后按下F5就可以大致观察执行计划了。这种方式是最为简单的。如果SQL执行耗时很长才会返回结果，这时候看执行计划考虑用方法explain plan for。如果想看SQL多条执行计划情况，可以考虑使用awrsqrpt. sql的方式。如果想获取到表的访问次数，只能使用statistics_level，如果SQL中含有多函数，函数中套有SQL等多层递归调用，想获得准确结果，只能使用方法10046跟踪事件。 "
    }, {
    "id": 48,
    "url": "http://localhost:4000/index.php/2019/09/longadder/",
    "title": "高并发下比AtomicLong性能更好的LongAdder",
    "body": "2019/09/23 - 前言JDK1. 8相对之前版本做了很多多线程性能方面的优化，今天来看看AtomicLong和LongAdder（1. 8新增），这两个类都是可以对一个Long数值进行原子类的操作增加或减少，用于计数。 AtomicLong原理AtomicLong修改值最终是通过cas操作来修改的，如果没有更新成功，会在循环重新尝试更新。 LongAdder原理有了AtomicLong之后，为什么还需要有LongAdder呢？LongAdder主要是为了在多线程并发高场景下使用，性能比AtomicLong更好。 AtomicLong在多线程下一直都是在更新一个热点数据value值，而LongAdder就通过将单个节点的并发修改分散到多个节点上，就相当于是在更新不同的value值，冲突少。 这个类里最主要的两个方法，add和sum。先看下add方法实现：1. 如果cell为空，没有冲突的情况下，都是通过更新base值就成功，这个是为了在低并发的情况下性能也能和AtomicLong差不多。2. 如果cell不为空，则会根据当前线程的threadLocalRandomProbe值取模计算在cell数组中的位置，如果数组所在位置cell不为空，则cas方式更新相应的value值。3. 如果为空则会最后执行longAccumulate方法。 longAccumulate逻辑（代码比较长，考虑扩容等并发情况，大概说下逻辑）：1. 如果当前线程定位到cell数组的位置为null，则会创建一个新的cell并将本次值赋值给cell的value值2. 如果不为空，则尝试通过定位到的cell去cas更新 sum方法实现：这里就会遍历Cell数组里的所有值，加上base全部加一起返回。 性能测试网上别人这个测试已经说的比较详细了http://blog. palominolabs. com/2014/02/10/java-8-performance-improvements-longadder-vs-atomiclong/但是这里并不要看到里面第一张图，就以为是在一个线程的时候AtomicLong性能高，而二个线程的时候AtomicLong就比LongAdder差很多了，并不是的。关键这里还是得看他的测试代码，他测试代码里面主要是每个线程会for循环加1000000次，所以跟一个线程加一次还是有区别的。 是不是可以废弃掉AtomicLong，全使用LongAdder呢答案并不是的：– 首先，AtomicLong API比较丰富，提供了incrementAndGet\getAndAdd等很方便的操作，而LongAdder主要是add\sum（用于取值）方法– 由于LongAdder的取值sum方法是遍历了所有的cell，然后值相加得到，所以可能存在在获取值的时候cell的值有并发更新，统计的值有误差 总结线程冲突不高情况下，使用AtomicLong是比较好，冲突高情况下使用LongAdder性能更好。相应的还有AtomicDouble vs DoubleAdder "
    }, {
    "id": 49,
    "url": "http://localhost:4000/index.php/2019/09/mybatis-nosuchpropertyexception/",
    "title": "项目重启后, Mybatis报错org.apache.ibatis.ognl.NoSuchPropertyException分析",
    "body": "2019/09/20 - Mybatis报错org. apache. ibatis. ognl. NoSuchPropertyException分析日志报错信息org. apache. ibatis. ognl. NoSuchPropertyException: XxxExample&amp;Criterion. condition或者org. apache. ibatis. ognl. NoSuchPropertyException: XxxExample&amp;Criterion. value或者org. apache. ibatis. ognl. NoSuchPropertyException: XxxExample&amp;Criterion. noValue等这些错误都是项目发布重启之后可能会出现。 问题分析查看报错信息+debug调试一. 获取某个对象的某个字段值流程如下 从图中可以看出，getProperty方法只有在获取不到值的情况下才会抛出上面的异常，也就是说只有存在OgnlRuntime#getMethodValue为空的时候发生（OgnlRuntime#getFieldValue方法在上面的举例中是肯定获取不到的，因为condition是类的私有变量，这个方法只能获取到非私有变量的值） 二. 现在就来看什么情况下会导致OgnlRuntime#getMethodValue返回null 在这里同一同样有两种情况，getGetMethod返回为null，并且getReadMethod返回也为null的时候才会返回null。由于在这里传入给getReadMethod的numParms参数是0，导致getReadMethod里面根本也获取不到任何值（方法实现里只判断了大于小于0，没有等于0场景），所以问题只能出现在getGetMethod返回null时候 三. 继续查看OgnlRuntime#getGetMethod什么情况下会返回null 跟到这个方法可以看出，这个方法是存在并发问题的，线程非安全。项目重启后第一次查询当两个线程同时值了行了A处从缓存里面获取字段对应的method都为null，然后另一个线程去执行了C处将method放到了缓存，另一个线程此时去执行B处代码时候，判断了如果包含了这个key就返回null了。 总结mybatis在版本&gt;=3. 4. 1之后修复了这个问题，主要修改是改动了上面提到的OgnlRuntime#getReadMethod这个方法的实现，即使第三段中提到的并发下依旧会返回null，但是之后可以通过这个方法重新能得到。 "
    }, {
    "id": 50,
    "url": "http://localhost:4000/index.php/2019/09/mysql-attention-default-value-when-adding-column/",
    "title": "MySQL中加字段设置默认值的问题",
    "body": "2019/09/18 - 背景在一个MySQL数据库多活的场景里，执行DDL新增字段需要进行更加准确的控制：1. 在alter语句中，不能指定默认值，因为这回导致先加上默认值的一端同步到另一端的数据中心含有默认值，导致同步报错。（不指定默认值时即为default NULL）2. 若先加上default NULL的字段，那么数据库中该字段则全为NULL，往往业务需要新增字段的值为非NULL，此时，就需要对该字段批量更新 若需要变更的表为大表，那么进行批量的更新就会非常消耗资源，产生大量binlog，还会导致同步延迟升高。 Repeat &amp; Fix环境：: MySQL version: 5. 7. 22sql_mode=”” 1234567891011121314CREATE TABLE if not exists `test1` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(10) DEFAULT NULL COMMENT 'name', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=20250319 DEFAULT CHARSET=utf8mysql&amp;gt; select count(1) from test1;+----------+| count(1) |+----------+| 16777219 |+----------+需求： 对这样的一个表进行添加字段，并且设置新加字段的默认值为1。 情况一：: ALTER语句中直接设置默认值： 1234567891011121314151617181920212223242526272829303132333435363738mysql&amp;gt; **alter table test1 add column status tinyint default 1;**mysql&amp;gt; select * from test1 order by id desc limit 10;+----------+---------+--------+| id    | name  | status |+----------+---------+--------+| 20250318 | aaqqwww |   1 || 20250317 | aaqq  |   1 || 20250316 | aaqq  |   1 || 20184908 | qq   |   1 || 20184907 | qq   |   1 || 20184906 | qq   |   1 || 20184905 | qq   |   1 || 20184904 | qq   |   1 || 20184903 | qq   |   1 || 20184902 | qq   |   1 |+----------+---------+--------+mysql&amp;gt; insert into test1(id,name) values (null,'qwe');Query OK, 1 row affected (0. 00 sec)mysql&amp;gt; select * from test1 order by id desc limit 10;+----------+---------+--------+| id    | name  | status |+----------+---------+--------+| 20250319 | qwe   |   1 || 20250318 | aaqqwww |   1 || 20250317 | aaqq  |   1 || 20250316 | aaqq  |   1 || 20184908 | qq   |   1 || 20184907 | qq   |   1 || 20184906 | qq   |   1 || 20184905 | qq   |   1 || 20184904 | qq   |   1 || 20184903 | qq   |   1 |+----------+---------+--------+可见：在ALTER语句中直接设置默认值，则表中的历史数据对应的字段也会被更新为默认值1。 情况二：: 先加字段，再设置默认值： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162mysql&amp;gt; **alter table test1 add column addr tinyint ;**mysql&amp;gt; select * from test1 order by id desc limit 10;+----------+---------+--------+------+| id    | name  | status | addr |+----------+---------+--------+------+| 20250319 | qwe   |   1 | NULL || 20250318 | aaqqwww |   1 | NULL || 20250317 | aaqq  |   1 | NULL || 20250316 | aaqq  |   1 | NULL || 20184908 | qq   |   1 | NULL || 20184907 | qq   |   1 | NULL || 20184906 | qq   |   1 | NULL || 20184905 | qq   |   1 | NULL || 20184904 | qq   |   1 | NULL || 20184903 | qq   |   1 | NULL |+----------+---------+--------+------+----设置新增字段addr的默认值为1：mysql&amp;gt; **alter table test1 alter addr set default 1;**Query OK, 0 rows affected (0. 00 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&amp;gt; select * from test1 order by id desc limit 10;+----------+---------+--------+------+| id    | name  | status | addr |+----------+---------+--------+------+| 20250319 | qwe   |   1 | NULL || 20250318 | aaqqwww |   1 | NULL || 20250317 | aaqq  |   1 | NULL || 20250316 | aaqq  |   1 | NULL || 20184908 | qq   |   1 | NULL || 20184907 | qq   |   1 | NULL || 20184906 | qq   |   1 | NULL || 20184905 | qq   |   1 | NULL || 20184904 | qq   |   1 | NULL || 20184903 | qq   |   1 | NULL |+----------+---------+--------+------+10 rows in set (0. 00 sec)mysql&amp;gt; insert into test1(id,name) values (null,'qweasd');Query OK, 1 row affected (0. 00 sec)mysql&amp;gt; select * from test1 order by id desc limit 10;+----------+---------+--------+------+| id    | name  | status | addr |+----------+---------+--------+------+| 20250320 | qweasd |   1 |  1 || 20250319 | qwe   |   1 | NULL || 20250318 | aaqqwww |   1 | NULL || 20250317 | aaqq  |   1 | NULL || 20250316 | aaqq  |   1 | NULL || 20184908 | qq   |   1 | NULL || 20184907 | qq   |   1 | NULL || 20184906 | qq   |   1 | NULL || 20184905 | qq   |   1 | NULL || 20184904 | qq   |   1 | NULL |+----------+---------+--------+------+10 rows in set (0. 00 sec)现象： 新增的列的历史数据值全为NULL，只有新增的row才能有默认值1，若业务需要该字段历史数据为默认值1，则需要进行批量更新（更新注意事项见附录）。原因： 根据MySQL OnlineDDL，对于列设置默认值，只会更改元信息，不在原表中进行更改，所以历史数据为NULL1。 情况二（补充）: 在情况二的基础上，若需要设置历史数据为非NULL，需要再进行一次结构变更： 1234567891011121314151617181920212223242526272829303132333435mysql&amp;gt; select * from test1 order by id desc limit 10;+----------+---------+--------+------+| id    | name  | status | addr |+----------+---------+--------+------+| 20250320 | qweasd |   1 |  1 || 20250319 | qwe   |   1 | NULL || 20250318 | aaqqwww |   1 | NULL || 20250317 | aaqq  |   1 | NULL || 20250316 | aaqq  |   1 | NULL || 20184908 | qq   |   1 | NULL || 20184907 | qq   |   1 | NULL || 20184906 | qq   |   1 | NULL || 20184905 | qq   |   1 | NULL || 20184904 | qq   |   1 | NULL |+----------+---------+--------+------+mysql&amp;gt; **alter table test1 modify addr int not null default 1;**mysql&amp;gt; select * from test1 order by id desc limit 10;+----------+---------+--------+------+| id    | name  | status | addr |+----------+---------+--------+------+| 20250320 | qweasd |   1 |  1 || 20250319 | qwe   |   1 |  0 || 20250318 | aaqqwww |   1 |  0 || 20250317 | aaqq  |   1 |  0 || 20250316 | aaqq  |   1 |  0 || 20184908 | qq   |   1 |  0 || 20184907 | qq   |   1 |  0 || 20184906 | qq   |   1 |  0 || 20184905 | qq   |   1 |  0 || 20184904 | qq   |   1 |  0 |+----------+---------+--------+------+10 rows in set (0. 00 sec)现象：. . 若使用ALTER命令修改该列为非NULL，则会将该列全部更新为02。 . . . 附：若采取批量更新的方式刷新老数据：1. 需要放在业务低峰进行执行2. 分批次进行update，例如一次更新1000条，每次停顿1秒（按照后端binlog消费能力和数据库负载进行调整） - - - - - -1. [Online DDL Operations](https://dev. mysql. com/doc/refman/5. 7/en/innodb-online-ddl-operations. html) [↩︎](#fnref-662-1)2. [Data Type Default Values](https://dev. mysql. com/doc/refman/5. 7/en/data-type-defaults. html) [↩︎](#fnref-662-2)"
    }, {
    "id": 51,
    "url": "http://localhost:4000/index.php/2019/09/tokudb-bug-of-alibaba-mysql-rds/",
    "title": "阿里云RDS中MySQL实例TokuDB的BUG",
    "body": "2019/09/18 -  背景：近日在进行表结构变更时，发现一个存储引擎为TokuDB的表变更字段花费了10个小时。但是对于TokuDB，字段变更应该是秒级完成的。至此向阿里云提交了bug。 环境：阿里云RDS for MySQL 5. 6版本表的存储引擎：TokuDB 回复：阿里云目前不再进行TokuDB的更新和维护，所以建议不再使用该存储引擎。 相似bug：tokudb-hot-column-expansion[bugfix] Issue: #62 alter TokuDB table comment rebuild whole engine data 规避措施：（1）不使用TokuDB存储引擎（2）监控结构变更的状态，控制执行时间，若某个时间内没有执行成功，则kill变更线程（3）使用pt-online-schema-change进行结构变更 "
    }, {
    "id": 52,
    "url": "http://localhost:4000/index.php/2019/09/innodb-lock-and-mysql-transaction-isolation/",
    "title": "InnoDB锁及MySQL事务隔离级别",
    "body": "2019/09/18 - Innodb锁机制参看文档:1 共享锁和排它锁: Share-lock：简单理解为读取某些行Exclusive-lock：操作某些行 意向锁: InnoDB提供了多个粒度的锁，允许行锁和表锁的共同存在。例如在lock table . . write 时，允许其他事务加上意向锁。意向锁为在需要加上读锁或者写锁之前，需要首先申请意向锁，意向锁的分类：1. 意向共享锁intention shared lock (IS)：2. 意向排它锁intention exclusive lock (IX)：例如：select … lock in share mode为IS，select … for update为IX。           X   IX   S   IS         X   Conflict   Conflict   Conflict   Conflict       IX   Conflict   Compatible   Conflict   Compatible       S   Conflict   Conflict   Compatible   Compatible       IS   Conflict   Compatible   Compatible   Compatible   意向锁不会和任何类型的锁冲突，除了LOCK TABLES … WRITE 行锁: 锁在索引列， 123456789SHOW ENGINE INNODB STATUS：RECORD LOCKS space id 58 page no 3 n bits 72 index `PRIMARY` of table `test`. `t` trx id 10078 lock_mode X locks rec but not gapRecord lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 4; hex 8000000a; asc   ;; 1: len 6; hex 00000000274f; asc   'O;; 2: len 7; hex b60000019d0110; asc    ;;Gap锁: 锁在两个索引行之间，或者无穷小到最小索引值，最大索引值到无穷大。例如： 12SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE; 对于使用唯一索引锁定行以搜索唯一行的语句，不需要gap锁，（搜索条件只包含多列惟一索引的某些列，还是可能发生gap）****READ COMMITTED隔离级别下，gap锁仅用作外键检查和冲突检查**  It is also worth noting here that conflicting locks can be held on a gap by different transactions. For example, transaction A can hold a shared gap lock (gap S-lock) on a gap while transaction B holds an exclusive gap lock (gap X-lock) on the same gap. The reason conflicting gap locks are allowed is that if a record is purged from an index, the gap locks held on the record by different transactions must be merged.  Gap locks in InnoDB are “purely inhibitive”, which means that their only purpose is to prevent other transactions from inserting to the gap. Gap locks can co-exist. A gap lock taken by one transaction does not prevent another transaction from taking a gap lock on the same gap. There is no difference between shared and exclusive gap locks. They do not conflict with each other, and they perform the same function. Next-Key Locks: 索引值及其前面的gap，假设一个索引列包好以下值：10, 11, 13, and 20 123456(negative infinity, 10](10, 11](11, 13](13, 20](20, positive infinity)在RR隔离级别下，MySQL使用Next-Key Locks防止幻读2。幻读： 同一个查询在不同的时间得到不同的结果集。例如一个表的索引字段有90,102两个值，当执行： 12SELECT * FROM child WHERE id &amp;gt; 100 FOR UPDATE;另一个会话此时插入value=101，则再次查询时，出现value=101的值，违背了事务的ACID规则。 插入意向锁Insert Intention Locks: 插入意向锁为在插入之前需要加上的gap锁，作用：在多个事务需要插入的在时候，如果需要插入的gap位置不一样，则不用进行等待。例如两个索引值为4和7，现有两个事务需要分别插入5和6的值，则在获取到对应行的排它锁之前，会加上插入意向锁，但由于是插入不同的值，索引事务不会相互阻塞。 12345678910mysql&amp;gt; CREATE TABLE if not exists child (id int(11) NOT NULL, PRIMARY KEY(id)) ENGINE=InnoDB;mysql&amp;gt; INSERT INTO child (id) values (90),(102);mysql&amp;gt; START TRANSACTION;mysql&amp;gt; SELECT * FROM child WHERE id &amp;gt; 100 FOR UPDATE;B：mysql&amp;gt; START TRANSACTION;mysql&amp;gt; INSERT INTO child (id) VALUES (101);此时查看锁的状态： 12345678show engine innodb status:RECORD LOCKS space id 31 page no 3 n bits 72 index `PRIMARY` of table `test`. `child`trx id 8731 lock_mode X locks gap before rec insert intention waitingRecord lock, heap no 3 PHYSICAL RECORD: n_fields 3; compact format; info bits 0 0: len 4; hex 80000066; asc  f;; 1: len 6; hex 000000002215; asc     ;; 2: len 7; hex 9000000172011c; asc   r ;;. . . AUTO-INC Locks自增锁: 自增锁是一种表级锁，在insert一条自增字段的值时，需要加上自增锁。简单来说，当一个事务插入自增列值时，另外一个需要插入该列的insert事务需要等待，以得到连续递增的值。当然，我们可以通过控制innodb_autoinc_lock_mode参数进行自增的控制3。 在MySQL 5. 1. 22之前，innodb使用一个表锁解决自增字段的一致性问题，但是如果大量的并发插入就会引起SQL堵塞，不但影响效率，而且可能会瞬间达到max_connections而崩溃。 在 5. 1. 22之后，innodb使用新的方式解决自增字段一致性问题，对于可以预判行数的insert语句，innodb使用一个轻量级的互斥量。如：某一insert语句1执行前，表的AUTO_INCREMENT=1，语句A的插入行数已知为3，innodb在语句1的实际插入操作执行前就预分配给该语句三个自增值，当有一个新的insert语句2要执行时，读取的AUTO_INCREMENT=4，这样虽然语句1可能还没有执行完，语句2就可直接执行无需等待语句2。 这种方式对于可预判插入行数的插入语句有效，如：insert和replace。对于无法提前获知插入行数的语句，如：insert…select…、replace…select…和load data则innodb还是使用表锁。 1234 innodb_autoinc_lock_mode = 0 (“traditional” lock mode：全部使用表锁)  innodb_autoinc_lock_mode = 1 (默认)(“consecutive” lock mode：可预判行数时使用新方式，不可时使用表锁)  innodb_autoinc_lock_mode = 2 (“interleaved” lock mode：全部使用新方式，不安全，不适合replication) MySQL事务隔离级别事务隔离级别简介: 事务隔离级别（Transaction Isolation Levels）是数据库的基础，ISOLATION即为ACID属性中的I项。隔离级别用以控制在多个事务同时进行更改和执行查询时，对性能和结果的可靠性、一致性和重现性之间的平衡进行设置。 一致性非锁定读（Consistent Nonlocking Reads）: InnoDB使用多版本控制，以显示数据库在某一时刻的快照数据。查询查看在此时间点之前提交的事务所做的更改，而稍后或未提交的事务则不做任何更改4。 REPEATABLE READ: 是InnoDB默认的隔离级别，可以做到一致非锁定读 4。在RR( REPEATABLE READ)级别下，事务中的读取总是读的是第一次读取时创建的快照数据，若需要获取最新的状态，需要提交事务。       Session A   Session B         SET autocommit=0;   SET autocommit=0;       SELECT * FROM t; —-empty set               INSERT INTO t VALUES (1, 2);       SELECT * FROM t; —-empty set               COMMIT;       SELECT * FROM t; —-empty set           COMMIT;           SELECT * FROM t; —–(1,2)       READ COMMITTED: 对于RC(READ COMMITTED)级别，一致性读每次读到的都是最新的快照，即每次读取到的数据均为最新版本。RC级别由于没有了gap锁，所以会出现幻读。binlog_format必须为ROW。RC级别事务的影响：1. 对于UPDATE或DELETE语句，InnoDB只对它更新或删除的行持有锁。非匹配行的记录锁在MySQL评估WHERE条件之后立即释放。这大大降低了死锁的可能性，但它们仍然可能发生。2. 对于UPDATE语句，如果一行已经被锁定，InnoDB执行“semi-consistent”读取，将最新提交的版本返回给MySQL，以便MySQL可以确定该行是否匹配更新的WHERE条件。如果行匹配(必须更新)，MySQL将再次读取该行，这次InnoDB要么锁定该行，要么等待锁。 举例： 1234567891011CREATE TABLE if not exists t (a INT NOT NULL, b INT) ENGINE = InnoDB;INSERT INTO t VALUES (1,2),(2,3),(3,2),(4,3),(5,2);COMMIT;--Session ASTART TRANSACTION;UPDATE t SET b = 5 WHERE b = 3;--Session BUPDATE t SET b = 4 WHERE b = 2;如果事务中不修改该行，则马上会释放锁，如果修改该行，则会在事务结束后进行释放。 对于RR级别： 1234567事务Ax-lock(1,2); retain x-lockx-lock(2,3); update(2,3) to (2,5); retain x-lockx-lock(3,2); retain x-lockx-lock(4,3); update(4,3) to (4,5); retain x-lockx-lock(5,2); retain x-lock在符合条件的行接上X锁，并且不进行释放，所以事务B在更新时候，需要等待事务A的提交或者释放： 12x-lock(1,2); block and wait for first UPDATE to commit or roll back对于RC级别： 1234567事务A：x-lock(1,2); unlock(1,2)x-lock(2,3); update(2,3) to (2,5); retain x-lockx-lock(3,2); unlock(3,2)x-lock(4,3); update(4,3) to (4,5); retain x-lockx-lock(5,2); unlock(5,2)事务B： 123456x-lock(1,2); update(1,2) to (1,4); retain x-lockx-lock(2,3); unlock(2,3)x-lock(3,2); update(3,2) to (3,4); retain x-lockx-lock(4,3); unlock(4,3)x-lock(5,2); update(5,2) to (5,4); retain x-lock**但是，如果WHERE条件包含索引列，并且InnoDB使用索引，那么在获取和保留记录锁时只考虑索引列。(( 1234567891011CREATE TABLE if not exists t (a INT NOT NULL, b INT, c INT, INDEX (b)) ENGINE = InnoDB;INSERT INTO t VALUES (1,2,3),(2,2,4);COMMIT;--Session ASTART TRANSACTION;UPDATE t SET b = 3 WHERE b = 2 AND c = 3;--Session BUPDATE t SET b = 4 WHERE b = 2 AND c = 4;- - - - - -1. [InnoDB locking](https://dev. mysql. com/doc/refman/8. 0/en/innodb-locking. html) [↩︎](#fnref-656-1)2. [Phantom Rows](https://dev. mysql. com/doc/refman/8. 0/en/innodb-next-key-locking. html) [↩︎](#fnref-656-2)3. [AUTO\_INCREMENT Handling in InnoDB](https://dev. mysql. com/doc/refman/8. 0/en/innodb-auto-increment-handling. html) [↩︎](#fnref-656-3)4. [Consistent Nonlocking Reads](https://dev. mysql. com/doc/refman/8. 0/en/innodb-consistent-read. html) [↩︎](#fnref-656-4) [↩︎](656-4)"
    }, {
    "id": 53,
    "url": "http://localhost:4000/index.php/2019/09/mysql-drop-index-safely/",
    "title": "怎么查找MySQL中的重复索引和无用索引，并且安全地drop index删除索引？",
    "body": "2019/09/18 - 好文分享Dropping useless MySQL indexes 总结重复索引查找方法：: 可以使用pt-duplicate-key-checker查找出MySQL数据库中的重复索引。注意事项：1. 重复索引有部分是业务需要的，用以做冗余，或者是完成覆盖索引的sql，不能简单的找到重复索引后进行删除 无用索引查找方法：:  对于MariaDB或者Percona Server for MySQL，可以使用user_statistics，查询information_schema. INDEX_STATISTICS，可以找到未被使用的索引（ps. 可以查看我之前的文章MySQL索引统计信息information_schema. INDEX_STATISTICS） 对于官方版MySQL，可以使用Performance_schema中的table_io_waits_summary_by_index_usage表进行查找：12345SELECT object_schema, object_name, index_name  FROM performance_schema. table_io_waits_summary_by_index_usage  WHERE index_name IS NOT NULL AND count_star = 0  ORDER BY object_schema, object_name, index_name;注：需启动实例前设置performance_schema = on。  注意事项：    打开performance_schema统计对系统性能有一定影响  MariaDB10默认为关闭performance_schema  此种统计方法是不准确的，因为其是把未产生IO等待的索引，看作为未被使用的索引。 删除索引: 由于对于索引的下线具有业务风险，所以，MySQL8开始，支持索引不可见，语法为： 12ALTER TABLE t ALTER INDEX idx_a INVISIBLE[VISIBLE];并且该语句可以瞬间完成，以此降低drop index的风险。 "
    }, {
    "id": 54,
    "url": "http://localhost:4000/index.php/2019/09/tips-when-using-mysqldump/",
    "title": "Tips: MySQL数据库使用mysqldump备份恢复时的注意事项",
    "body": "2019/09/18 - 背景 mysqldump作为MySQL数据库逻辑备份的常用工具，对于其备份出来的文件，应该进行确认，防止在恢复时误删数据。 mysqldump提供了很多选项，使用时候需确认默认选项及所需选项配置。 MySQL主从和双机为MySQL复制的常见架构，在此类集群中，对于数据的恢复，更需要小心，确认无误后再进行操作。mysqldump采坑点1. -E, -R, –triggers: 常用的mysqldump的格式为（例如备份wstest. t1）： 12mysqldump -uroot -p -P 8001 -h 192. 168. 101. 185 -E -R --triggers wstest t1 &gt; wstest_t1. sql这样既可备份wstest. t1及表上的EVENTS，ROUTINES，TRIGGERS，下文默认加上三者，但是在备份时需要注意，因为若未备份，则在恢复时候虽然数据正确，但是实例运行起来后，会出现问题。 2. drop table: 默认情况下，mysqldump备份出来的文件中，在恢复表时候，会先drop table。按照第一点的命令，备份得到的文件内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071-- MySQL dump 10. 13 Distrib 8. 0. 12, for linux-glibc2. 12 (x86_64)---- Host: 192. 168. 101. 185  Database: wstest-- -------------------------------------------------------- Server version    8. 0. 12/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */; SET NAMES utf8mb4 ;/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;/*!40103 SET TIME_ZONE='+00:00' */;/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;SET @MYSQLDUMP_TEMP_LOG_BIN = @@SESSION. SQL_LOG_BIN;SET @@SESSION. SQL_LOG_BIN= 0;---- GTID state at the beginning of the backup --SET @@GLOBAL. GTID_PURGED=/*!80000 '+'*/ 'b3e550a7-b009-11e8-aca0-000c299263cc:1-284814';---- Table structure for table `t1`--------注意在create表之前，先进行了drop--------**DROP TABLE IF EXISTS `t1`;**/*!40101 SET @saved_cs_client   = @@character_set_client */; SET character_set_client = utf8mb4 ;CREATE TABLE if not exists `t1` ( `a` int(11) NOT NULL AUTO_INCREMENT, `b` int(11) DEFAULT NULL, `c` int(11) DEFAULT NULL, PRIMARY KEY (`a`), UNIQUE KEY `uniq_b` (`b`)) ENGINE=InnoDB AUTO_INCREMENT=111112 DEFAULT CHARSET=utf8;/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `t1`--LOCK TABLES `t1` WRITE;/*!40000 ALTER TABLE `t1` DISABLE KEYS */;INSERT INTO `t1` VALUES (3,10004,100),(11,10016,30000),(431,12,99),(436,18,33),(111111,23231313,12313131);/*!40000 ALTER TABLE `t1` ENABLE KEYS */;UNLOCK TABLES;---- Dumping events for database 'wstest'------ Dumping routines for database 'wstest'--SET @@SESSION. SQL_LOG_BIN = @MYSQLDUMP_TEMP_LOG_BIN;/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;-- Dump completed on 2019-06-11 10:23:09若环境中已经存在新的数据，则这种方式将会删除表后重建，导致数据丢失。所以，可以在命令中加上 –skip-add-drop-table： 12mysqldump --skip-add-drop-table wstest t1 &amp;gt; wstest_t1. sql 从备份文件可以看出，在新建表之后，会使用insert into语句进行数据的插入。为了防止有重复数据中断恢复（恢复大表的时候，花费时间比较长，若中断后排错，又需要重新恢复，耗时较长），还可以使用 –replace： 12mysqldump --skip-add-drop-table --replace wstest t1 &amp;gt; wstest_t1. sql 得到的备份文件的插入数据部分为： 123456LOCK TABLES `t1` WRITE;/*!40000 ALTER TABLE `t1` DISABLE KEYS */;REPLACE INTO `t1` VALUES (3,10004,100),(11,10016,30000),(431,12,99),(436,18,33),(111111,23231313,12313131);/*!40000 ALTER TABLE `t1` ENABLE KEYS */;UNLOCK TABLES;3. –set-gtid-purged: 执行第一点的mysqldump命令时，会有一个warning：  Warning: A partial dump from a server that has GTIDs will by default include the GTIDs of all transactions, even those that changed suppressed parts of the database. If you don’t want to restore GTIDs, pass –set-gtid-purged=OFF. To make a complete dump, pass –all-databases –triggers –routines –events. 需要关注–set-gtid-purged选项，在上文中备份出来的文件中，有如下两行：  SET @MYSQLDUMP_TEMP_LOG_BIN = @@SESSION. SQL_LOG_BIN; SET @@SESSION. SQL_LOG_BIN= 0; 这两行的意思是：不把恢复产生的sql记录在binlog中。这点尤其重要，因为在MySQL主从，或者MySQL双机的环境，若进行恢复，则会同步到对端，这样就存在一个问题：若一端正常在数据写入，需要回复另一端的时候，此时，有这两行的话，相对来说就会使恢复过程更安全。 否则，在另一端也会执行备份文件中的内容（若备份文件中有类似drop table的选项，那将是一个删库的结果~）。  若是在一个全新的一个集群环境做恢复，那么可以加上–set-gtid-purged=OFF，这样，可在在从库中也收到binlog信息，得到一个数据一致的集群。 4. –single-transaction: 备份时创建一致的快照，在单个事务中转储所有表。强烈建议开启，并配合–master-data使用由于备份是一个阶段式的dump，所以可能出现：A表已经备份，B表关联了A的数据，那么再备份B表时，A表没有相关的记录。就会造成恢复的时候，出现数据逻辑不完整的情况。 5. –master-data: –master-data 决定是否将 binary log position和filename 信息记录在备份文件中。  =1：直接记录在文件中，恢复时会执行change master to…. :123456---- Position to start replication or point-in-time recovery from--CHANGE MASTER TO MASTER_LOG_FILE='mysql8001. 000025', MASTER_LOG_POS=159500640; =2：以注释的方式记录在备份文件：123456---- Position to start replication or point-in-time recovery from---- CHANGE MASTER TO MASTER_LOG_FILE='mysql8001. 000025', MASTER_LOG_POS=159500640;6. -e, –extended-insert, –skip-extended-insert: 加上 -e 或者 –extended-insert，可以使insert语句为一个insert插入多条数据，如上文所示。加上–skip-extended-insert， 则为一条insert插入一条数据： 12345678910LOCK TABLES `t1` WRITE;/*!40000 ALTER TABLE `t1` DISABLE KEYS */;INSERT INTO `t1` VALUES (3,10004,100);INSERT INTO `t1` VALUES (11,10016,30000);INSERT INTO `t1` VALUES (431,12,99);INSERT INTO `t1` VALUES (436,18,33);INSERT INTO `t1` VALUES (111111,23231313,12313131);/*!40000 ALTER TABLE `t1` ENABLE KEYS */;UNLOCK TABLES;7. -F, –flush-logs: 在进行逻辑备份的全量+增量的恢复时，往往需要找到对应的binlog的position信息，所以在备份时，建议加上-F，这样，在dump之前会先flush logs，产生新的binlog文件，便于恢复。建议和–master-data一起使用  Note that if you dump many databases at once (using the option –databases= or –all-databases), the logs will be flushed for each database dumped. The exception is when using –lock-all-tables or –master-data: in this case the logs will be flushed only once, corresponding to the moment all tables are locked. So if you want your dump and the log flush to happen at the same exact moment you should use –lock-all-tables or –master-data with –flush-logs. 8. 字符集: 可以看到备份出的文件中有SET NAMES utf8mb4 ; 等关于字符集的字样，同样在辈分时候应该注意，防止字符集不一致出现的数据不可用。 9. 注释: 对于mysqldump中的注释部分，同样需要进行确认，例如上文中的SQL_MODE，TIME_ZONE等等。 10. 其它: (1) LOCK TABLE对于表的回复操作，会有LOCK TABLE …. WRITE操作，这个在使用时一定要注意，必要时（前提是已经重复确认数据不会产生加锁等相互影响），可以加上**–skip-add-locks ** 选项取消加表锁。 (2) — Dump completed on备份结束后，可以查看最后一行是否为：— Dump completed on …. . "
    }, {
    "id": 55,
    "url": "http://localhost:4000/index.php/2019/09/mysql-statistic-tables/",
    "title": "MySQL数据库信息统计表",
    "body": "2019/09/18 - 前言聊聊MySQL数据库中的统计信息，众所周知，MySQL在执行sql时，会使用统计信息进行判断，采用最优（cost花费最低）的执行计划，而这些统计信息是怎么进行的，在用户角度如何去调整或者理解统计信息呢？  本次演示使用的MySQL版本：8. 0. 12 innodb_table_stats 和 innodb_index_statsinnodb_table_stats和innodb_index_stats都是在MySQL实例中的mysql数据库下的表，分别存储表和索引级别的统计信息。innodb_table_stats的字段说明：       Column name   Description   说明         database_name   Database name   数据库名       table_name   Table name, partition name, or subpartition name   表名       last_update   A timestamp indicating the last time that InnoDB updated this row   最后更新时间       n_rows   The number of rows in the table   表的行数(估值)       clustered_index_size   The size of the primary index, in pages   聚集索引页数       sum_of_other_index_sizes   The total size of other (non-primary) indexes, in pages   二级索引页数   参考MySQL官方文档 innodb_table_stats示例：: 1234567891011121314151617mysql&gt; select * from mysql. innodb_table_stats where database_name='wstest';+---------------+-------------+---------------------+----------+----------------------+--------------------------+| database_name | table_name | last_update     | n_rows  | clustered_index_size | sum_of_other_index_sizes |+---------------+-------------+---------------------+----------+----------------------+--------------------------+| wstest    | mul_replace | 2018-11-13 22:01:58 |    2 |          1 |            1 || wstest    | rdslist   | 2018-11-16 10:30:52 |   324 |          5 |            0 || wstest    | t1     | 2019-03-12 14:13:33 |    8 |          1 |            1 || wstest    | t2     | 2018-11-27 11:39:08 |    10 |          1 |            1 || wstest    | t3     | 2018-12-12 14:52:23 |  302472 |         865 |            0 || wstest    | t4     | 2018-12-12 15:07:34 | 4155228 |        21043 |            0 || wstest    | t5     | 2019-03-05 19:15:28 | 11301308 |        58688 |            0 || wstest    | test    | 2018-10-30 16:29:22 |    6 |          1 |            0 || wstest    | testgroupby | 2019-01-02 16:36:04 |    6 |          1 |            0 || wstest    | tmstamp   | 2019-01-07 17:02:43 |    2 |          1 |            0 |+---------------+-------------+---------------------+----------+----------------------+--------------------------+10 rows in set (0. 00 sec)从上述内容可以看出表的基本状态，包括表名，聚集索引和非聚集索引（二级索引）大小等等，此外，还能看出部分表在一段时间内没有更新，或者更新的行数没有超过recalculate的阈值（10% rows） 而想要获取到更为详细的信息，需要查看innodb_index_stats：       Column name   Description   说明         database_name   Database name   数据库名       table_name   Table name, partition name, or subpartition name   表名       index_name   Index name   索引名       last_update   A timestamp indicating the last time that InnoDB updated this row   最后更新时间       stat_name   The name of the statistic, whose value is reported in the stat_value column   统计线程的名称       stat_value   The value of the statistic that is named in stat_name column   统计线程的值       sample_size   The number of pages sampled for the estimate provided in the stat_value column   采样页数       stat_description   Description of the statistic that is named in the stat_name column   统计的说明   innodb_index_stats示例：: 1234567891011121314&lt;br&gt;&lt;/br&gt;mysql&gt; select * from mysql. innodb_index_stats where database_name='wstest' and table_name='t4';+---------------+------------+------------+---------------------+--------------+------------+-------------+-----------------------------------+| database_name | table_name | index_name | last_update     | stat_name  | stat_value | sample_size | stat_description         |+---------------+------------+------------+---------------------+--------------+------------+-------------+-----------------------------------+| wstest    | t4     | PRIMARY  | 2019-03-21 18:57:41 | n_diff_pfx01 |  4155228 |     20 | id                || wstest    | t4     | PRIMARY  | 2019-03-21 18:57:41 | n_leaf_pages |   20988 |    NULL | Number of leaf pages in the index || wstest    | t4     | PRIMARY  | 2019-03-21 18:57:41 | size     |   21043 |    NULL | Number of pages in the index   || wstest    | t4     | idx_name  | 2019-03-21 18:57:41 | n_diff_pfx01 |     1 |      2 | name               || wstest    | t4     | idx_name  | 2019-03-21 18:57:41 | n_diff_pfx02 |  4189010 |     20 | name,id              || wstest    | t4     | idx_name  | 2019-03-21 18:57:41 | n_leaf_pages |    5810 |    NULL | Number of leaf pages in the index || wstest    | t4     | idx_name  | 2019-03-21 18:57:41 | size     |    6699 |    NULL | Number of pages in the index   |+---------------+------------+------------+---------------------+--------------+------------+-------------+-----------------------------------+7 rows in set (0. 00 sec)首先，对于stat_name这列的解释：– size：该索引总的页数– n_leaf_pages：索引中叶子节点的页数– n_diff_pfx01：前01个字段在索引中的唯一值数目（估值）– n_diff_pfx02：前02个字段在索引中的唯一值数目（估值） 1234567891011121314151617mysql&gt; select count(distinct name) from wstest. t4; ----n_diff_pfx01对应的value+----------------------+| count(distinct name) |+----------------------+|          2 |+----------------------+1 row in set (0. 00 sec)mysql&gt; select count(distinct name,id) from wstest. t4; ----n_diff_pfx02对应的value+-------------------------+| count(distinct name,id) |+-------------------------+|         4194304 |+-------------------------+1 row in set (2. 99 sec)其他信息：: 使用information_schema. tables查看统计信息： 12345678mysql&gt; select table_name,table_rows,data_length,index_length from information_schema. tables where table_name='t4';+------------+------------+-------------+--------------+| TABLE_NAME | TABLE_ROWS | DATA_LENGTH | INDEX_LENGTH |+------------+------------+-------------+--------------+| t4     |  4155228 |  344768512 |      0 |+------------+------------+-------------+--------------+1 row in set (0. 07 sec)发现INDEX_LENGTH 列为0，这是由于idx_name这列，是我为了展示二级索引时加上的，还没有能刷新在information_schema. tables里。此时，使用analyze table t4;进行统计信息的重新收集（注：若是必须analyze，一定要放在低峰进行操作”） 12345678mysql&gt; analyze table wstest. t4;+-----------+---------+----------+----------+| Table   | Op   | Msg_type | Msg_text |+-----------+---------+----------+----------+| wstest. t4 | analyze | status  | OK    |+-----------+---------+----------+----------+1 row in set (0. 11 sec)重新收集统计信息后，查看information_schema. tables中的信息，与mysql. innodb_index_stats中的结果进行对比： 1234567891011121314151617mysql&gt; SELECT SUM(stat_value) pages, index_name, SUM(stat_value)*@@innodb_page_size size FROM mysql. innodb_index_stats WHERE table_name='t4' AND stat_name = 'size' GROUP BY index_name; +-------+------------+-----------+| pages | index_name | size   |+-------+------------+-----------+| 21108 | PRIMARY  | 345833472 || 6699 | idx_name  | 109756416 |+-------+------------+-----------+2 rows in set (0. 00 sec)mysql&gt; select table_name,table_rows,data_length,index_length from information_schema. tables where table_name='t4';                           +------------+------------+-------------+--------------+| TABLE_NAME | TABLE_ROWS | DATA_LENGTH | INDEX_LENGTH |+------------+------------+-------------+--------------+| t4     |  4173444 |  345833472 |  109756416 |+------------+------------+-------------+--------------+1 row in set (0. 00 sec)可以看出：1. information_schema. tables中的DATA_LENGTH 值 = PRIMARY页数 * 页的大小，即对于InnoDB，聚集索引的大小即为数据大小。  information_schema. tables中的INDEX_LENGTH值 = 二级索引页数 * 页的大小再在t4上添加一个索引： 12345678910111213141516171819202122232425mysql&gt; analyze table wstest. t4;                                                                    +-----------+---------+----------+----------+| Table   | Op   | Msg_type | Msg_text |+-----------+---------+----------+----------+| wstest. t4 | analyze | status  | OK    |+-----------+---------+----------+----------+1 row in set (0. 06 sec)mysql&gt; select table_name,table_rows,data_length,index_length from information_schema. tables where table_name='t4';+------------+------------+-------------+--------------+| TABLE_NAME | TABLE_ROWS | DATA_LENGTH | INDEX_LENGTH |+------------+------------+-------------+--------------+| t4     |  4173444 |  345833472 |  356155392 |+------------+------------+-------------+--------------+1 row in set (0. 00 sec)mysql&gt; SELECT SUM(stat_value) pages, index_name, SUM(stat_value)*@@innodb_page_size size FROM mysql. innodb_index_stats WHERE table_name='t4' AND stat_name = 'size' GROUP BY index_name;+-------+------------+-----------+| pages | index_name | size   |+-------+------------+-----------+| 21108 | PRIMARY  | 345833472 || 15039 | idx_addr  | 246398976 || 6699 | idx_name  | 109756416 |+-------+------------+-----------+3 rows in set (0. 01 sec)可以看出：INDEX_LENGTH = size( idx_addr + idx_name ) 相关配置信息为了使统计信息更加准确，需要关注：innodb_stats_transient_sample_pages（innodb_stats_persistent=OFF时）：在收集统计信息时的采样索引pages页数，默认为8。 innodb_stats_persistent_sample_pages（innodb_stats_persistent=ON时）：在收集统计信息时的采样索引pages页数，默认为20。 innodb_stats_persistent：是否将InnoDB的索引统计信息同步到磁盘，若设置为0，则在产生变更时，会自动重新收集信息，得到不同的执行计划，默认为ON。innodb_stats_auto_recalc（innodb_stats_persistent=ON时）：在表的数据被更改后（阈值：10%），自动地重新估算统计信息 "
    }, {
    "id": 56,
    "url": "http://localhost:4000/index.php/2019/09/tips-mysql-spatial-data-types/",
    "title": "MySQL中使用空间位置需注意的问题",
    "body": "2019/09/18 - 空间位置数据类型MySQL支持的空间数据类型[1](#fn-641-1)：**GEOMETRY****POINT****LINESTRING****POLYGON**最常用的为GEOMETRY，POLYGON，POINT。因为目前很多应用都是判断是否某个点在所画范围内，或者是两个多边形范围的交叉情况。 GEOMETRY: GEOMETRY是一种强大的空间数据类型，可以用来表示POINT, LINESTRING, and POLYGON，即另外的三种空间数据类型均可以使用GEOMETRY来表示（线上也推荐使用此种模式，避免出现兼容性问题 ） . . 常见问题空间索引: 所有的空间字段不能为NULL，不然在创建空间索引的时候会报错： 123mysql&amp;gt; create table spatest(id int auto_increment primary key, userspace geometry default null, SPATIAL KEY `idx_userspace` (`userspace`));ERROR 1252 (42000): All parts of a SPATIAL index must be NOT NULL关于使用polygon数据类型: polygon中的打点，必须为首尾相连，形成闭合图形（在应用中容易打点时忽略最后一个点） 1234567891011121314mysql&amp;gt; select st_astext(ST_geomfromtext('POLYGON(( 119. 41667 24. 078513,115. 416761 26. 078578,115. 41725 24. 078327,113. 4177 24. 078027,115. 418154 25. 077749, 119. 41667 26. 078513))')); ERROR 3037 (22023): Invalid GIS data provided to function st_geomfromtext. mysql&amp;gt; select st_astext(ST_geomfromtext('POLYGON(( 119. 41667 24. 078513,115. 416761 26. 078578,115. 41725 24. 078327,113. 4177 24. 078027,115. 418154 25. 077749, 119. 41667 24. 078513))')); +---------------------------------------------------------------------------------------------------------------------------------------------------------------------+| st_astext(ST_geomfromtext('POLYGON(( 119. 41667 24. 078513,115. 416761 26. 078578,115. 41725 24. 078327,113. 4177 24. 078027,115. 418154 25. 077749, 119. 41667 24. 078513))')) |+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+| POLYGON((119. 41667 24. 078513,115. 416761 26. 078578,115. 41725 24. 078327,113. 4177 24. 078027,115. 418154 25. 077749,119. 41667 24. 078513))                 |+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0. 00 sec)注意  MySQL8. 0将astext函数转换为st_astext。 空间相关函数常用的空间相关函数2：ST_Intersects(g1, g2):Returns 1 or 0 to indicate whether g1 spatially intersects g2. ST_Contains(g1, g2):Returns 1 or 0 to indicate whether g1 completely contains g2. This tests the opposite relationship as ST_Within(). - - - - - -1. [MySQL空间数据类型](https://dev. mysql. com/doc/refman/5. 6/en/spatial-type-overview. html) [↩︎](#fnref-641-1)2. [MySQL支持的空间函数](https://dev. mysql. com/doc/refman/5. 6/en/spatial-relation-functions-object-shapes. html#function_st-intersects) [↩︎](#fnref-641-2)"
    }, {
    "id": 57,
    "url": "http://localhost:4000/index.php/2019/09/otter-one-way-loopback/",
    "title": "Otter的单向回环补救（使用Otter遇到的问题一）",
    "body": "2019/09/18 - 背景Otter是阿里巴巴公司的开源项目，用以进行多机房数据库同步。对于其数据一致性，开源版解决方案为：单向回环补救。1 单向回环补救概况: 在双向同步时，例如AB双向同步，在Otter中设置A为主站点，B为非主站点，则： A产生的数据，只会从A—-&gt;B，回环终止，保证不进入死循环 B产生的数据，从B—-&gt;A，会再次进入到A—-&gt;B的回路，形成一次单向的回环 存在的问题：存在同步延迟时，会出现版本丢失高 / 数据交替性变化1. 对于B同步到A，先从B—-&gt;A，变更很快完成，但是此时在A中产生了很大的数据变更，则A—-&gt;B的链路又会回放一次，导致出现数据交替2. A同一条数据进行了十次变更（即产生10个版本），A很快同步到B，但是B对该行的操作需要进行回环，所以B在该行的数据—-&gt;A—-&gt;B时，会覆盖之前的10个版本 对于以上的两种问题，Otter官方给出了相应的解决方案：  反查数据库同步 (以数据库最新版本同步，解决交替性，比如设置一致性反查数据库延迟阀值为60秒，即当同步过程中发现数据延迟超过了60秒，就会基于PK反查一次数据库，拿到当前最新值进行同步，减少交替性的问题) 字段同步 (降低冲突概率) 同步效率 (同步越快越好，降低双写导致版本丢失概率，不需要构建冲突数据KV表) 同步全局控制 (比如HZ-&gt;US和US-&gt;HZ一定要一起启动，一起关闭，保证不会出现一边数据一直覆盖另一边，造成比较多的版本丢失)1遇到的问题在测试阶段，应用出现的问题（双向同步，A为主站点）：1. 在B端对某行进行了多次变更（即产生了多个版本），则数据会同步到A，继而再同步回到B2. 业务在update后，马上进行查询，但是在查询时（同步会由A再回到B），查询到了一个中间状态的版本，此时应用报错 How to repeat?首先看一下环境：MySQL版本：5. 7. 22A和B为两个机房的MySQL数据库，并且使用Otter进行双A同步，即两边均可写 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950mysql&amp;gt; show create table test2 \G*************************** 1. row ***************************    Table: test2Create Table: CREATE TABLE if not exists `test2` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(30) DEFAULT NULL, `status` tinyint(4) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mysql&amp;gt; select * from test2;+----+------+--------+| id | name | status |+----+------+--------+| 1 | aaa |   0 || 2 | aaa |   0 |+----+------+--------+2 rows in set (0. 00 sec)mysql&amp;gt; **update test2 set name=concat(name,'x'),status=5 where status=0;select sleep(0. 038); update test2 set name=concat(name,'y'),status=99 where status=5;update test2 set name=concat(name,'z'),status=100 where status=99;**Query OK, 2 rows affected (0. 01 sec)Rows matched: 2 Changed: 2 Warnings: 0+--------------+| sleep(0. 038) |+--------------+|      0 |+--------------+1 row in set (0. 04 sec)Query OK, 2 rows affected (0. 00 sec)Rows matched: 2 Changed: 2 Warnings: 0Query OK, 0 rows affected (0. 01 sec)Rows matched: 0 Changed: 0 Warnings: 0mysql&amp;gt; select * from test2;+----+-------+--------+| id | name | status |+----+-------+--------+| 1 | aaaxy |   99 || 2 | aaaxy |   99 |+----+-------+--------+2 rows in set (0. 00 sec) **此时出现数据版本丢失的情况**  **此时出现数据版本丢失的情况**   **此时出现数据版本丢失的情况**由于中间版本的不稳定性，测试多遍，还有可能出现不同的结果： 1234567891011&lt;br&gt;&lt;/br&gt;. . . . . . mysql&amp;gt; select * from test2;+----+------+--------+| id | name | status |+----+------+--------+| 1 | aaax |   5 || 2 | aaax |   5 |+----+------+--------+2 rows in set (0. 00 sec)解决思路1. 数据合并概念: 需要说明Otter的一个核心算法：数据合并2 数据合并算法  入库算法采取了按pk hash并行载入+batch合并的优化  a. 打散原始数据库事务，预处理数据，合并insert/update/delete数据(参见合并算法)，然后按照table + pk进行并行(相同table的数据，先执行delete,后执行insert/update，串行保证，解决唯一性约束数据变更问题)，相同table的sql会进行batch合并处理 . b. 提供table权重定义，根据权重定义不同支持”业务上类事务功能”，并行中同时有串行权重控制    业务类事务描述：比如用户的一次交易付款的流程，先产生一笔交易记录，然后修改订单状态为已付款。用户对这事件的感知，是通过订单状态的已付款，然后进行查询交易记录。 .   所以，可以对同步进行一次编排： 先同步完交易记录，再同步订单状态。(给同步表定义权重，权重越高的表相对重要，放在后面同步，最后达到的效果可以保证业务事务可见性的功能，快的等慢的. ) 2. 添加表权重: 从某种程度上说，可以通过设置不同表的权重，从而使相同表的变更合并在一起，可以降低风险。但是，表的权重算法仅在入库时进行，而不是在拉取数据时，而若update是被分库在多个batch中，则权重并不能生效。 3. 关闭主站点: 关闭主站点会导致并发时，两边数据不一致的情况，不能关闭主站点。  目前的思路并没有能解决问题，所以想要继续挖究，后续若有解决方案，再进行更新~ . 数据一致性检验批量检验: MySQL Ultility中的mysqldbcompare 工具 增量对比：: 由于主键是单调递增的，所以可以在同步的过程中，进行校验，例如A和B双向同步，在某端产生了id &gt; 0 and id 0 and id &lt; 100的数据，进行比对 - - - - - -1. [Otter数据一致性算法](https://github. com/alibaba/otter/wiki/Otter%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7) [↩︎](#fnref-637-1) [↩︎](637-1)2. [Otter数据合并算法](https://github. com/alibaba/otter/wiki/Otter%E6%95%B0%E6%8D%AE%E5%85%A5%E5%BA%93%E7%AE%97%E6%B3%95) [↩︎](#fnref-637-2)"
    }, {
    "id": 58,
    "url": "http://localhost:4000/index.php/2019/09/innodb-cluster-mgr-group_replication_consistency/",
    "title": "InnoDB Cluster(MGR)中的事务一致性等级配置",
    "body": "2019/09/18 - 简介InnoDB cluster是基于MySQL Group Replication（MGR）搭建的，本文主要介绍在MySQL-8. 0. 14中新增的一致性配置参数：group_replication_consistency1，用以控制在InnoDB cluster中的事务一致性等级，其有5种可选配置项：EVENTUAL(默认)、BEFORE_ON_PRIMARY_FAILOVER、BEFORE、AFTER、BEFORE_AND_AFTER。此外，对于不同的事务（只读，或者读写），进行不同的一致性控制。本文的例子均基于“单写”（Single-primary mode）cluster环境。 group_replication_consistency配置有如下几种可配选项，根据一致性等级程度增大顺序进行介绍： EVENTUAL: 在执行”读”或者”写”事务之前，不用等待之前的事务完成。在group_replication_consistency参数出现之前，默认是使用此种方法。例如： 1234567Secondary master上：  lock table t1 read;Primary 上：      insert into t1 values (***);  ----执行成功，不会产生等待Secondary master上：  select * from t1;  ----执行成功，返回结果为插入前的状态Secondary master上：  unlock tables; Secondary master上：  select * from t1;  ----执行成功，返回结果为插入后的状态BEFORE_ON_PRIMARY_FAILOVER: 新primary上的RO或RW事务，在恢复老的primary的待办事务之前，将会被阻塞。 这可确保在primary发生故障转移发生时，客户端始终会在primary服务器上看到最新值。 这保证了一致性，但意味着客户端必须能够在应用积压的情况下处理延迟。 通常这种延迟应该是最小的，但取决于积压的任务大小。 BEFORE: RW事务在执行之前等待所有先前的事务完成；RO事务在返回结果前需要等待所有先前的事务完成(Apply Queue为空才能返回结果)。这样可以确保RO返回的结果，为最新的状态。例如： 123456789Secondary master上：  lock table t1 read;Primary 上：      insert into t1 values (***);  ----执行成功，不会产生等待Secondary master上：    set @@session. group_replication_consistency='BEFORE' ;   select * from t1;  ----等待，若超过“wait_timeout”的阈值，则报错：ERROR: 3797: Error while waiting for group transactions commit on group_replication_consistency= 'BEFORE'Secondary master上：  unlock tables;  ----执行成功。此时Secondary master上的select线程返回插入后的结果Secondary master上：  select * from t1;  ----执行成功，返回结果为插入后的状态AFTER: RW事务需要等待其在所有节点上的变更结束，才能执行成功。“AFTER”不影响只读事务。例如： 12345678910Secondary master上：  lock table t1 read;Primary 上：     set @@session. group_replication_consistency='AFTER' ;      insert into t1 values (***);  ----等待，测试发现即使等待时间超过“wait_timeout”的阈值，也不会报错Secondary master上：    select * from t1;  ----等待，若超过“wait_timeout”的阈值，则报错：ERROR: 3797: Error while waiting for group transactions commit on group_replication_consistency= 'BEFORE'Secondary master上：  unlock tables;  ----执行成功。此时Primary 上的insert 执行成功Secondary master上：  select * from t1;  ----执行成功，返回结果为插入后的状态BEFORE_AND_AFTER: RW事务等待之前所有的事务完成，并且等待其在所有节点上的变更结束；RO事务需要等待之前所有的事务完成。如上文“AFTER”部分的测试结果。（本文测试参考MySQL InnoDB Cluster – consistency levels2） 总结由此可见，在8. 0. 14后，提供了更为准确的数据一致性控制：1. 相比之前默认的EVENTUAL，即保持最终的一致性，配置不同的选项，可以更好的控制在primary宕机时，能保证RO和RW事务的准确性。 12**EVENTUAL**在Primary宕机后，在新的Primary重放完老primary的事务之前，若此时有RO事务，则会导致RO事务读取到老的数据；而RW事务则可能由于冲突被rollback，导致数据不一致。2. 当然，很多小伙伴会想，那么把所有节点都配置为“AFTER”不就好了吗？ 12事实并非如此，因为“AFTER”很有可能导致：当Primary上有大量的变更、DDL、备份等操作时，commit被延迟，并且延迟可能会导致独有的业务全部需要连接到Primary。- - - - - -1. [官方文档：group\_replication\_consistency](https://dev. mysql. com/doc/refman/8. 0/en/group-replication-options. html#sysvar_group_replication_consistency) [↩︎](#fnref-633-1)2. [MySQL InnoDB Cluster – consistency levels](https://lefred. be/content/mysql-innodb-cluster-consistency-levels/) [↩︎](#fnref-633-2)"
    }, {
    "id": 59,
    "url": "http://localhost:4000/index.php/2019/09/mysql-innodb_cached_indexes/",
    "title": "InnoDB索引在缓存中的情况",
    "body": "2019/09/17 - innodb的缓存情况从MySQL8. 0开始，可以通过information_schema中的INNODB_CACHED_INDEXES表，查看索引在缓存中的情况。 所需权限需要有对于该表的PROCESS权限，否则会报错： 12You must have the PROCESS privilege to query this table. 查看索引缓存状态: （1）查询INNODB_CACHED_INDEXES表 123456789101112131415161718192021root:information_schema&gt; select * from INNODB_CACHED_INDEXES ;+------------+----------+----------------+| SPACE_ID  | INDEX_ID | N_CACHED_PAGES |+------------+----------+----------------+| 4294967294 |    1 |       1 || 4294967294 |    2 |       1 || 4294967294 |    3 |       1 || 4294967294 |    4 |       1 || 4294967294 |    5 |       1 || 4294967294 |    7 |       1 || 4294967294 |    8 |       1 || 4294967294 |    9 |       1 || 4294967294 |    10 |       1 || 4294967294 |    11 |       1 || 4294967294 |    12 |       1 || 4294967294 |    13 |       1 || 4294967294 |    14 |       1 || 4294967294 |    15 |       2 |. . . （2）获取表名对应关系可以根据tables和columns表获取表名： 12345678910111213141516171819202122root:information_schema&gt; SELECT tables. NAME AS table_name, indexes. NAME AS index_name, cached. N_CACHED_PAGES AS n_cached_pagesFROM INFORMATION_SCHEMA. INNODB_CACHED_INDEXES AS cached, INFORMATION_SCHEMA. INNODB_INDEXES AS indexes, INFORMATION_SCHEMA. INNODB_TABLES AS tablesWHERE cached. INDEX_ID = indexes. INDEX_ID AND indexes. TABLE_ID = tables. TABLE_ID;+------------------+------------+----------------+| table_name    | index_name | n_cached_pages |+------------------+------------+----------------+| wstestdb/sbtest2 | PRIMARY  |      273 || wstestdb/sbtest2 | k_2    |      166 || wstestdb/sbtest1 | PRIMARY  |      287 || wstestdb/sbtest1 | k_1    |      165 |+------------------+------------+----------------+4 rows in set (0. 01 sec)（3）多次查询，观察变化再次查询： 1234567891011root:information_schema&gt; SELECT  tables. NAME AS table_name,  indexes. NAME AS index_name,  cached. N_CACHED_PAGES AS n_cached_pages FROM  INFORMATION_SCHEMA. INNODB_CACHED_INDEXES AS cached,  INFORMATION_SCHEMA. INNODB_INDEXES AS indexes,  INFORMATION_SCHEMA. INNODB_TABLES AS tables WHERE  cached. INDEX_ID = indexes. INDEX_ID  AND indexes. TABLE_ID = tables. TABLE_ID;+------------------+------------+----------------+| table_name    | index_name | n_cached_pages |+------------------+------------+----------------+| wstestdb/sbtest2 | PRIMARY  |      1764 || wstestdb/sbtest2 | k_2    |      166 || wstestdb/sbtest1 | PRIMARY  |      831 || wstestdb/sbtest1 | k_1    |      165 |+------------------+------------+----------------+4 rows in set (0. 01 sec)（4）表的大小环境介绍： 12345678910111213141516171819root:information_schema&amp;gt; select count(*) from wstestdb. sbtest2;+----------+| count(*) |+----------+|  116716 |+----------+root:information_schema&amp;gt; show create table wstestdb. sbtest2 \G *************************** 1. row ***************************    Table: sbtest2Create Table: CREATE TABLE if not exists `sbtest2` ( `id` int(11) NOT NULL AUTO_INCREMENT, `k` int(11) NOT NULL DEFAULT '0', `c` char(120) NOT NULL DEFAULT '', `pad` char(60) NOT NULL DEFAULT '', PRIMARY KEY (`id`), KEY `k_2` (`k`)) ENGINE=InnoDB AUTO_INCREMENT=700001 DEFAULT CHARSET=utf8结果缓存情况: 可以看出，大约有 5. 89%的数据和索引页被缓存在缓冲池中 ： 12345678910111213141516root:information_schema&amp;gt; SELECT COUNT(*) AS total_pages FROM information_schema. INNODB_BUFFER_PAGE;+----------+| total_pages |+----------+|  32768 |+----------+1 row in set (0. 15 sec)root:information_schema&amp;gt; select (1764+166)/32768;+------------------+| (1764+166)/32768 |+------------------+|      0. 0589 |+------------------+1 row in set (0. 00 sec)缓冲池中的信息: 可以根据之前的文章InnoDB缓冲池中的内容，查看缓冲池中的情况。 附加信息对于索引缓存情况，pmm已经支持对其进行监控：使用pmm监控索引缓存情况：Which Indexes are Cached? Discover with PMM "
    }, {
    "id": 60,
    "url": "http://localhost:4000/index.php/2019/09/whats-in-innodb-buffer-pool/",
    "title": "InnoDB缓冲池中的内容",
    "body": "2019/09/17 - 缓冲池信息相关的表查看缓冲池中的信息，主要是通过information_schema库下的三张表进行查看：+ INNODB_BUFFER_PAGE：INNODB缓冲池中page的情况+ INNODB_BUFFER_PAGE_LRU：INNODB缓冲池中page的LRU(Least Recently Used)情况+ INNODB_BUFFER_POOL_STATS：INNODB缓冲池状态总览 123456789root:information_schema&gt; SHOW TABLES FROM INFORMATION_SCHEMA LIKE 'INNODB_BUFFER%';+-----------------------------------------------+| Tables_in_information_schema (INNODB_BUFFER%) |+-----------------------------------------------+| INNODB_BUFFER_PAGE              || INNODB_BUFFER_PAGE_LRU            || INNODB_BUFFER_POOL_STATS           |+-----------------------------------------------+详情查看：[InnoDB INFORMATION_SCHEMA Buffer Pool Tables]注意事项：  查询 INNODB_BUFFER_PAGE 或者 INNODB_BUFFER_PAGE_LRU 会影响数据库的性能！ (https://dev. mysql. com/doc/refman/8. 0/en/innodb-information-schema-buffer-pool-tables. html) 从INNODB_BUFFER_PAGE表查询系统数据系统数据记为MySQL用以存储数据库实例相关状态或者配置的数据，这部分数据同样会部分缓存在缓冲池中。 12345678root:information_schema&gt; SELECT COUNT(*) FROM INFORMATION_SCHEMA. INNODB_BUFFER_PAGE    WHERE TABLE_NAME IS NULL OR (INSTR(TABLE_NAME, '/') = 0 AND INSTR(TABLE_NAME, '. ') = 0);+----------+| COUNT(*) |+----------+|  29573 |+----------+1 row in set (0. 25 sec)系统数据在缓冲池中的分布: 查看系统数据在整个缓冲池中的分布情况： 1234567891011121314151617mysql&gt; SELECT    (SELECT COUNT(*) FROM INFORMATION_SCHEMA. INNODB_BUFFER_PAGE    WHERE TABLE_NAME IS NULL OR (INSTR(TABLE_NAME, '/') = 0 AND INSTR(TABLE_NAME, '. ') = 0)    ) AS system_pages,    (    SELECT COUNT(*)    FROM INFORMATION_SCHEMA. INNODB_BUFFER_PAGE    ) AS total_pages,    (    SELECT ROUND((system_pages/total_pages) * 100)    ) AS system_page_percentage;+--------------+-------------+------------------------+| system_pages | total_pages | system_page_percentage |+--------------+-------------+------------------------+|    29573 |    32768 |           90 |+--------------+-------------+------------------------+缓存中系统数据的属性: PAGE_TYPE字段可以查看系统数据的属性： 123456789101112131415161718192021mysql&gt; SELECT DISTINCT PAGE_TYPE FROM INFORMATION_SCHEMA. INNODB_BUFFER_PAGE    WHERE TABLE_NAME IS NULL OR (INSTR(TABLE_NAME, '/') = 0 AND INSTR(TABLE_NAME, '. ') = 0);+-------------------+| PAGE_TYPE     |+-------------------+| SYSTEM      || INODE       || IBUF_INDEX    || TRX_SYSTEM    || RSEG_ARRAY    || UNDO_LOG     || FILE_SPACE_HEADER || IBUF_BITMAP    || LOB_FIRST     || LOB_DATA     || LOB_INDEX     || UNKNOWN      || INDEX       |+-------------------+13 rows in set (0. 37 sec)从INNODB_BUFFER_PAGE表查询用户数据12345678mysql&gt; SELECT COUNT(*) FROM INFORMATION_SCHEMA. INNODB_BUFFER_PAGE    WHERE TABLE_NAME IS NOT NULL AND TABLE_NAME NOT LIKE '%INNODB_TABLES%';+----------+| COUNT(*) |+----------+|   3195 |+----------+用户数据在缓冲池中的分布情况: 同理，查看用户数据在缓冲池中的分布情况： 1234567891011121314151617mysql&gt; SELECT    (SELECT COUNT(*) FROM INFORMATION_SCHEMA. INNODB_BUFFER_PAGE    WHERE TABLE_NAME IS NOT NULL AND (INSTR(TABLE_NAME, '/') &gt; 0 OR INSTR(TABLE_NAME, '. ') &gt; 0)    ) AS user_pages,    (    SELECT COUNT(*)    FROM information_schema. INNODB_BUFFER_PAGE    ) AS total_pages,    (    SELECT ROUND((user_pages/total_pages) * 100)    ) AS user_page_percentage;+------------+-------------+----------------------+| user_pages | total_pages | user_page_percentage |+------------+-------------+----------------------+|    3195 |    32768 |          10 |+------------+-------------+----------------------+查看用户数据对应的表 1234567891011mysql&amp;gt; SELECT DISTINCT TABLE_NAME FROM INFORMATION_SCHEMA. INNODB_BUFFER_PAGE    WHERE TABLE_NAME IS NOT NULL AND (INSTR(TABLE_NAME, '/') &amp;gt; 0 OR INSTR(TABLE_NAME, '. ') &amp;gt; 0)    AND TABLE_NAME NOT LIKE '`mysql`. `innodb_%';+----------------------+| TABLE_NAME      |+----------------------+| `wstestdb`. `sbtest2` || `wstestdb`. `sbtest1` |+----------------------+2 rows in set (0. 15 sec)从INNODB_BUFFER_PAGE表查看索引数据: 当然，也可以使用该表查看索引被缓存的情况情况。索引缓存情况可以对比另一篇文章查看InnoDB索引在缓存中的情况。 123456789101112mysql&amp;gt; SELECT INDEX_NAME, COUNT(*) AS Pages,ROUND(SUM(IF(COMPRESSED_SIZE = 0, @@GLOBAL. innodb_page_size, COMPRESSED_SIZE))/1024/1024)AS 'Total Data (MB)'FROM INFORMATION_SCHEMA. INNODB_BUFFER_PAGEWHERE INDEX_NAME='k_2' AND TABLE_NAME = '`wstestdb`. `sbtest2`';+------------+-------+-----------------+| INDEX_NAME | Pages | Total Data (MB) |+------------+-------+-----------------+| k_2    |  167 |        3 |+------------+-------+-----------------+1 row in set (0. 19 sec)查看某个表的所有索引缓存情况： 1234567891011121314mysql&amp;gt; SELECT INDEX_NAME, COUNT(*) AS Pages,    ROUND(SUM(IF(COMPRESSED_SIZE = 0, @@GLOBAL. innodb_page_size, COMPRESSED_SIZE))/1024/1024)    AS 'Total Data (MB)'    FROM INFORMATION_SCHEMA. INNODB_BUFFER_PAGE    WHERE TABLE_NAME = '`wstestdb`. `sbtest2`'    GROUP BY INDEX_NAME;+------------+-------+-----------------+| INDEX_NAME | Pages | Total Data (MB) |+------------+-------+-----------------+| PRIMARY  | 1767 |       28 || k_2    |  167 |        3 |+------------+-------+-----------------+2 rows in set (0. 21 sec)查询LRU_POSITION信息LRU可以反映表中热数据的情况，可以参考这个状态，判断是否会影响sql的查询，或者是否需要刷数据，使数据变“热”。 123456789root:information_schema&amp;gt; select table_name,INDEX_NAME,min(LRU_POSITION),max(LRU_POSITION) from  INFORMATION_SCHEMA. INNODB_BUFFER_PAGE_LRU where table_name='`wstestdb`. `sbtest2`' group by INDEX_NAME;+----------------------+------------+-------------------+-------------------+| table_name      | INDEX_NAME | min(LRU_POSITION) | max(LRU_POSITION) |+----------------------+------------+-------------------+-------------------+| `wstestdb`. `sbtest2` | PRIMARY  |        485 |       4273 || `wstestdb`. `sbtest2` | k_2    |        527 |       2910 |+----------------------+------------+-------------------+-------------------+2 rows in set (0. 03 sec)查询INNODB_BUFFER_POOL_STATS表查询INNODB_BUFFER_POOL_STATS表和直接执行show engine innodb status \G 和 查看Innodb_buffer的状态的结果相似： 123456789101112131415161718192021222324252627282930313233343536root:information_schema&amp;gt; SELECT * FROM information_schema. INNODB_BUFFER_POOL_STATS \G*************************** 1. row ***************************             POOL_ID: 0            POOL_SIZE: 32768          FREE_BUFFERS: 27417         DATABASE_PAGES: 5169       OLD_DATABASE_PAGES: 1888     MODIFIED_DATABASE_PAGES: 0       PENDING_DECOMPRESS: 0          PENDING_READS: 0        PENDING_FLUSH_LRU: 0       PENDING_FLUSH_LIST: 0        PAGES_MADE_YOUNG: 0      PAGES_NOT_MADE_YOUNG: 0      PAGES_MADE_YOUNG_RATE: 0    PAGES_MADE_NOT_YOUNG_RATE: 0        NUMBER_PAGES_READ: 3590      NUMBER_PAGES_CREATED: 1579      NUMBER_PAGES_WRITTEN: 68456         PAGES_READ_RATE: 0        PAGES_CREATE_RATE: 0       PAGES_WRITTEN_RATE: 8. 973448067156127        NUMBER_PAGES_GET: 25963207            HIT_RATE: 1000  YOUNG_MAKE_PER_THOUSAND_GETS: 0NOT_YOUNG_MAKE_PER_THOUSAND_GETS: 0     NUMBER_PAGES_READ_AHEAD: 0    NUMBER_READ_AHEAD_EVICTED: 0         READ_AHEAD_RATE: 0     READ_AHEAD_EVICTED_RATE: 0          LRU_IO_TOTAL: 0         LRU_IO_CURRENT: 0        UNCOMPRESS_TOTAL: 0       UNCOMPRESS_CURRENT: 01 row in set (0. 00 sec)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647mysql&amp;gt; SHOW ENGINE INNODB STATUS \G. . . ----------------------BUFFER POOL AND MEMORY----------------------Total large memory allocated 549453824Dictionary memory allocated 494195Buffer pool size  32768Free buffers    27417Database pages   5169Old database pages 1888Modified db pages 0Pending reads   0Pending writes: LRU 0, flush list 0, single page 0Pages made young 0, not young 00. 00 youngs/s, 0. 00 non-youngs/sPages read 3590, created 1579, written 684560. 00 reads/s, 0. 00 creates/s, 0. 00 writes/sNo buffer pool page gets since the last printoutPages read ahead 0. 00/s, evicted without access 0. 00/s, Random read ahead 0. 00/sLRU len: 5169, unzip_LRU len: 0I/O sum[0]:cur[0], unzip sum[0]:cur[0]root:information_schema&amp;gt; SHOW STATUS LIKE 'Innodb_buffer%';+---------------------------------------+--------------------------------------------------+| Variable_name             | Value                      |+---------------------------------------+--------------------------------------------------+| Innodb_buffer_pool_dump_status    | Dumping of buffer pool not started        || Innodb_buffer_pool_load_status    | Buffer pool(s) load completed at 190911 6:50:47 || Innodb_buffer_pool_resize_status   |                         || Innodb_buffer_pool_pages_data     | 5169                       || Innodb_buffer_pool_bytes_data     | 84688896                     || Innodb_buffer_pool_pages_dirty    | 0                        || Innodb_buffer_pool_bytes_dirty    | 0                        || Innodb_buffer_pool_pages_flushed   | 68446                      || Innodb_buffer_pool_pages_free     | 27417                 -      || Innodb_buffer_pool_pages_misc     | 182                       || Innodb_buffer_pool_pages_total    | 32768                      || Innodb_buffer_pool_read_ahead_rnd   | 0                        || Innodb_buffer_pool_read_ahead     | 0                        || Innodb_buffer_pool_read_ahead_evicted | 0                        || Innodb_buffer_pool_read_requests   | 25963233                     || Innodb_buffer_pool_reads       | 3384                       || Innodb_buffer_pool_wait_free     | 0                        || Innodb_buffer_pool_write_requests   | 4119405                     |+---------------------------------------+--------------------------------------------------+18 rows in set (0. 01 sec)"
    }, {
    "id": 61,
    "url": "http://localhost:4000/index.php/2019/09/mysql-drop-large-table/",
    "title": "MySQL安全删除大表drop table",
    "body": "2019/09/16 - 情况描述背景: 在删除过大的表时，除了会导致DML和DDL阻塞之外，还会产生大量的IO，造成资源占用严重，影响正常的业务。 前提: linux操作系统，MySQL数据库为独立表空间 思路: 在独立表空间环境中，删除一个表体现在OS上则为删除一个表空间文件。所以在OS上使用硬链接，在删除表时，实际是删除硬链接，该操作能迅速完成，然后再在系统上进行文件的逐步删除 删除大表步骤建立硬链接: 在OS上建立硬链接，例如表testbigfile，则在datadir下对应位置： 12ln testbigfile. ibd testbigfile. ibd. rm通过 ll 显示的第二列可以看到有两个文件使用了这个链接，所以删除其中一个时，删除的只是链接（会使得MySQL删表时速度更快），只有在只有一个文件使用链接时，才是真正的删除。 linux命令行 ll -a 显示的内容： 在MySQL中进行表的删除12mysql&gt; drop table bigtbdrop;该步操作非常快，是因为删除的是硬链接，而不是真正的文件。 在操作系统删除硬链接文件由于突然删除上百GB的文件，同样会导致IO的占用，所以在Linux环境可以使用truncate工具进行递进删除，一次删除1GB；更好的做法是统计当前的IO使用资源，在空闲IO资源较多时，触发truncate的操作： 12truncate -s -1GB regtime. ibd -s -1GB: 一次删除1GB，直到删完为止 同样可以通过truncate –help查看命令的帮助。 至此，则可安全地删除大表，妈妈再也不用担心我的drop table啦~ "
    }, {
    "id": 62,
    "url": "http://localhost:4000/index.php/2019/09/attention-when-using-aliyun-rds/",
    "title": "使用阿里云RDS的注意事项",
    "body": "2019/09/11 - 背景云上的RDS，给DBA带来了很多方便，但是也存在由于其自身的bug问题，导致影响到业务对于数据库的使用。本篇文章主要是分享一些采坑的过程，还有避免的方法。 一、升降级维护时间随着业务的拓展，当使用的RDS实例出现资源不够时，需要对RDS实例进行升降级操作，此时，可以选择两种切换方式（切换过程均会有30秒内的闪断，需要进行重连）：1. 在数据迁移结束之后进行切换2. 在维护时间进行切换（维护时间可以由用户自己设定） 注意事项: 若选择“在维护时间切换”，则可以选择应用低峰期，进行切换。1. 偶然情况： 数据迁移结束后，若新的RDS实例或者当前实例有报错（报错信息为阿里云内部信息，不会展示给用户），那么需要阿里云运维人员进行干预。 此种情况下，切换会顺延至下一个运维时间 . . 2. 联想 –选择“在数据迁移结束之后进行切换”通过1中的偶然情况，即存在需要人为干预的报错。那么切换方式选择“ 在数据迁移结束之后进行切换 ”的时候，可能会出现很严重的情况：1. 人为干预的时间不确定2. 数据完全同步的时间不确定由于可能会出现的以上的情况，均会导致在业务高峰期切换，后果可想而知。 所以，请选择“在维护时间进行切换！！！” 二、半同步复制阿里云RDS的高可用版本，主库对应着一个备库（备库的日志、监控、报警等信息不会展示给客户），并且默认使用的是半同步复制，rpl_semi_sync_master_timeout默认为10秒，并且rpl_semi_sync_master_timeout不能直接修改（需要联系阿里云技术支持进行修改）。 业务影响: 由于使用的是半同步复制，所以当出现 备库不可用 或者 主备间网络异常 的时候：（此时半同步复制链路报错：Waiting for semi-sync ACK from slave）1. 会出现业务的变更sql不能提交的情况！2. 由于主备间的网络等监控和报错信息，不提供给用户，所以不能及时预警3. 业务在sql执行超时时，通常会进行重试，会导致连接突增4. 业务突增，全都在等待rpl_semi_sync_master_timeout超时，导致资源消耗增大，CPU使用率升高 紧急处理: 在主库的连接数上涨时，收到报警。此时：1. 查看连接情况，都在等待从库相应2. 切换同步方式为：异步复制处理结束后，正常，查看从库（从库为业务使用的只读实例，备库为HA使用）正常，所以排查为备库的原因。反馈给阿里云的技术支持人员，得到回复为：  日志上面的确记录了退化，但是当前记录的日志没有完整的记录这个退化的原因。能看到的是备库没有给返回ACK，所以物理机间的内网质量波动可能性更大。这里我也让研发团队尝试加下这里的关于退化的日志，后续能够更准确的判断 问题规避: 对于出现的问题，阿里云表示没有打印出现问题的原因，只是给出了规避方案。 方案一：使用异步复制: 根据异步复制的流程，主库上的提交不用等待备库的ACK，所以可以进行规避。弊端：1. 异步复制不等待从库响应即可提交，所以当主库宕机时，可能出现提交的事务未在备库上执行，切换后会出现数据不一致的情况 由于有时候会需要进行主备切换，并且不排除主库可能会宕机的情况，所以不予采用！！！ 方案二：减小rpl_semi_sync_master_timeout: 默认rpl_semi_sync_master_timeout=10秒，所以等待超时时间较长，若此时并发很高，可能会导致等待时间延长。所以缩短超时时间，这样可以在更短的时间内超时，自动使用异步复制进行同步。 "
    }, {
    "id": 63,
    "url": "http://localhost:4000/index.php/2019/09/glance-show-linux-status/",
    "title": "安装及使用glance &#8211;查看Linux性能命令",
    "body": "2019/09/11 - 环境准备python3: 更新yum源: 12345678910备份：mv /etc/yum. repos. d/CentOS-Base. repo /etc/yum. repos. d/CentOS-Base. repo. backupmv epel. repo epel. repo. backupyum clean all  ##清理缓存wget -O /etc/yum. repos. d/CentOS-Base. repo http://mirrors. aliyun. com/repo/Centos-6. repowget -O /etc/yum. repos. d/epel. repo http://mirrors. aliyun. com/repo/epel-6. repoyum makecache安装python3: 12yum list python3*找到相关的包后，进行安装： 12yum install python3*在/usr/bin目录下，更换默认的python文件 123mv /usr/bin/python /usr/bin/python2. 6. bakcp -rf /usr/bin/python3 /use/bin/python安装glance 使用curl安装                    curl -L https://bit. ly/glances      /bin/bash                使用wget安装                    wget -O- http://bit. ly/glances      /bin/bash               报错及修复: yum配置报错: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@localhost ~]# sh install. shDetected system: CentOSLoaded plugins: fastestmirror, securitySetting up Install ProcessLoading mirror speeds from cached hostfile * base: mirrors. aliyun. com * extras: mirrors. aliyun. com * updates: mirrors. aliyun. com * webtatic: uk. repo. webtatic. comPackage python-pip-7. 1. 0-1. el6. noarch already installed and latest versionPackage python-devel-2. 6. 6-66. el6_8. x86_64 already installed and latest versionPackage gcc-4. 4. 7-23. el6. x86_64 already installed and latest versionPackage lm_sensors-3. 1. 1-17. el6. x86_64 already installed and latest versionPackage 1:wireless-tools-29-6. el6. x86_64 already installed and latest versionNothing to doInstall dependanciesTraceback (most recent call last): File  /usr/bin/pip , line 7, in   from pip. _internal import main File  /usr/lib/python2. 6/site-packages/pip/_internal/__init__. py , line 19, in   from pip. _vendor. urllib3. exceptions import DependencyWarning File  /usr/lib/python2. 6/site-packages/pip/_vendor/urllib3/__init__. py , line 8, in   from . connectionpool import ( File  /usr/lib/python2. 6/site-packages/pip/_vendor/urllib3/connectionpool. py , line 92  _blocking_errnos = {errno. EAGAIN, errno. EWOULDBLOCK}                  ^SyntaxError: invalid syntaxTraceback (most recent call last): File  /usr/bin/pip , line 7, in   from pip. _internal import main File  /usr/lib/python2. 6/site-packages/pip/_internal/__init__. py , line 19, in   from pip. _vendor. urllib3. exceptions import DependencyWarning File  /usr/lib/python2. 6/site-packages/pip/_vendor/urllib3/__init__. py , line 8, in   from . connectionpool import ( File  /usr/lib/python2. 6/site-packages/pip/_vendor/urllib3/connectionpool. py , line 92  _blocking_errnos = {errno. EAGAIN, errno. EWOULDBLOCK}                  ^SyntaxError: invalid syntaxInstall GlancesTraceback (most recent call last): File  /usr/bin/pip , line 7, in   from pip. _internal import main File  /usr/lib/python2. 6/site-packages/pip/_internal/__init__. py , line 19, in   from pip. _vendor. urllib3. exceptions import DependencyWarning File  /usr/lib/python2. 6/site-packages/pip/_vendor/urllib3/__init__. py , line 8, in   from . connectionpool import ( File  /usr/lib/python2. 6/site-packages/pip/_vendor/urllib3/connectionpool. py , line 92  _blocking_errnos = {errno. EAGAIN, errno. EWOULDBLOCK}                  ^SyntaxError: invalid syntax修复可以看出报错是在yum时候，由于yum配置为python2版本，现在的默认python为python3，所以解析报错。修复： 123vim /usr/bin/yum#把  #!/usr/bin/python 改为 #!/usr/bin/python2. 6pip版本问题: 123456789101112131415161718192021222324252627282930[root@localhost ~]# . /install. sh    Detected system: CentOSLoaded plugins: fastestmirror, securitySetting up Install ProcessLoading mirror speeds from cached hostfile * base: mirrors. aliyun. com * extras: mirrors. aliyun. com * updates: mirrors. aliyun. com * webtatic: uk. repo. webtatic. comPackage python-pip-7. 1. 0-1. el6. noarch already installed and latest versionPackage python-devel-2. 6. 6-66. el6_8. x86_64 already installed and latest versionPackage gcc-4. 4. 7-23. el6. x86_64 already installed and latest versionPackage lm_sensors-3. 1. 1-17. el6. x86_64 already installed and latest versionPackage 1:wireless-tools-29-6. el6. x86_64 already installed and latest versionNothing to doInstall dependanciesTraceback (most recent call last): File  /usr/bin/pip , line 7, in   from pip. _internal import mainImportError: No module named 'pip'Traceback (most recent call last): File  /usr/bin/pip , line 7, in   from pip. _internal import mainImportError: No module named 'pip'Install GlancesTraceback (most recent call last): File  /usr/bin/pip , line 7, in   from pip. _internal import mainImportError: No module named 'pip'修复可以看出是因为pip版本较低的原因，所以升级pip： 123456789101112wget https://bootstrap. pypa. io/get-pip. py -o get-pip. py python get-pip. py --force-reinstall[root@localhost ~]# python get-pip. py --force-reinstallDEPRECATION: Python 3. 4 support has been deprecated. pip 19. 1 will be the last one supporting it. Please upgrade your Python as Python 3. 4 won't be maintained after March 2019 (cf PEP 429). Collecting pip Using cached https://files. pythonhosted. org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19. 1. 1-py2. py3-none-any. whlCollecting wheel Downloading https://files. pythonhosted. org/packages/bb/10/44230dd6bf3563b8f227dbf344c908d412ad2ff48066476672f3a72e174e/wheel-0. 33. 4-py2. py3-none-any. whlInstalling collected packages: pip, wheelSuccessfully installed pip-19. 1. 1 wheel-0. 33. 4安装glance时的日志: 安装文档1 12345678910111213141516171819202122232425262728[root@localhost ~]# . /install. sh Detected system: CentOSLoaded plugins: fastestmirror, securitySetting up Install ProcessLoading mirror speeds from cached hostfile * base: mirrors. aliyun. com * extras: mirrors. aliyun. com * updates: mirrors. aliyun. com * webtatic: us-east. repo. webtatic. comPackage python-pip-7. 1. 0-1. el6. noarch already installed and latest versionPackage python-devel-2. 6. 6-66. el6_8. x86_64 already installed and latest versionPackage gcc-4. 4. 7-23. el6. x86_64 already installed and latest versionPackage lm_sensors-3. 1. 1-17. el6. x86_64 already installed and latest versionPackage 1:wireless-tools-29-6. el6. x86_64 already installed and latest versionNothing to doInstall dependanciesDEPRECATION: Python 3. 4 support has been deprecated. pip 19. 1 will be the last one supporting it. Please upgrade your Python as Python 3. 4 won't be maintained after March 2019 (cf PEP 429). Requirement already up-to-date: pip in /usr/lib/python3. 4/site-packages (19. 1. 1)DEPRECATION: Python 3. 4 support has been deprecated. pip 19. 1 will be the last one supporting it. Please upgrade your Python as Python 3. 4 won't be maintained after March 2019 (cf PEP 429). Requirement already satisfied: setuptools in /usr/lib/python3. 4/site-packages (19. 6. 2)Collecting glances[action,batinfo,browser,cpuinfo,docker,export,folders,gpu,graph,ip,raid,snmp,web,wifi] Downloading https://files. pythonhosted. org/packages/32/34/72f9202ad5b7ada314507a50b9ab1fb604d2f468b138679e0a4fedeb91fa/Glances-3. 1. 0. tar. gz (6. 7MB)   |██████████████████████████████▋ | 6. 4MB 22kB/s eta 0:00:13   . . . . . Successfully built glances psutilInstalling collected packages: psutil, glancesSuccessfully installed glances-3. 1. 0 psutil-5. 6. 2观察到Successfully installed glances-3. 1. 0 psutil-5. 6. 2，即为安装成功。 使用glance在命令行直接输入： 12  glances显示如下： 可以看出，得到了系统的多方面指标。对于各个指标的情况，还可以加上对应参数，例如CPU各个核的情况： 12glances --percpu 则会显示所有CPU分别的状态： 查看帮助： 12 glances --help glance其它功能: web: 还可以使用web查看状态： 123[root@localhost ~]# glances -wGlances Web User Interface started on http://0. 0. 0. 0:61208/然后用浏览器即可看到监控的状态。. influxdb: 将监控数据输出到influxdb2：首先安装influxdb module： 12pip install influxdb12glances -t 5 --export influxdb安装grafana：https://grafana. com/grafana/download?platform=linux - - - - - -1. [Glances](https://pypi. org/project/Glances/) [↩︎](#fnref-588-1)2. [InfluxDB &amp; Glances](https://glances. readthedocs. io/en/stable/gw/influxdb. html) [↩︎](#fnref-588-2)"
    }, {
    "id": 64,
    "url": "http://localhost:4000/index.php/2019/09/mysql-index-statistic-info/",
    "title": "MySQL索引统计信息",
    "body": "2019/09/11 -  背景上一篇文章中(MySQL索引统计信息information_schema. INDEX_STATISTICS)提到了在MySQL的社区版本中，都提供了对于索引统计信息的表，但是，在官方的MySQL版本中，是怎么维护索引（或表）的统计信息的呢？ 官方MySQL中，有performance_schema数据库，主要功能即为监控MySQL server的性能指标，不同的指标对应不同表（表的存储引擎为PERFORMANCE_SCHEMA），在MySQL5. 7开始，有sys数据库，其中包含了多个视图，展示了PERFORMANCE_SCHEMA中的数据集合，使其更具可读性。 本片文章主要阐述使用索引统计信息的过程，对于performance_schema的说明，可以查阅官方文档，有更详细的说明：Chapter 26 MySQL Performance Schema 在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择： 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。 . 在performance_schema中查看统计信息使用performance_schema进行统计信息的手机，需要在数据库启动时加入参数：performance_schema=ON，不可以在运行时进行更改。 123mysql&gt; set global performance_schema=on;ERROR 1238 (HY000): Variable 'performance_schema' is a read only variable打开之后，可以查看统计信息表： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647mysql&amp;gt; show create table performance_schema. table_io_waits_summary_by_index_usage \G*************************** 1. row ***************************    Table: table_io_waits_summary_by_index_usageCreate Table: CREATE TABLE if not exists `table_io_waits_summary_by_index_usage` ( `OBJECT_TYPE` varchar(64) DEFAULT NULL, `OBJECT_SCHEMA` varchar(64) DEFAULT NULL, `OBJECT_NAME` varchar(64) DEFAULT NULL, `INDEX_NAME` varchar(64) DEFAULT NULL, `COUNT_STAR` bigint(20) unsigned NOT NULL, `SUM_TIMER_WAIT` bigint(20) unsigned NOT NULL, `MIN_TIMER_WAIT` bigint(20) unsigned NOT NULL, `AVG_TIMER_WAIT` bigint(20) unsigned NOT NULL, `MAX_TIMER_WAIT` bigint(20) unsigned NOT NULL, `COUNT_READ` bigint(20) unsigned NOT NULL, `SUM_TIMER_READ` bigint(20) unsigned NOT NULL, `MIN_TIMER_READ` bigint(20) unsigned NOT NULL, `AVG_TIMER_READ` bigint(20) unsigned NOT NULL, `MAX_TIMER_READ` bigint(20) unsigned NOT NULL, `COUNT_WRITE` bigint(20) unsigned NOT NULL, `SUM_TIMER_WRITE` bigint(20) unsigned NOT NULL, `MIN_TIMER_WRITE` bigint(20) unsigned NOT NULL, `AVG_TIMER_WRITE` bigint(20) unsigned NOT NULL, `MAX_TIMER_WRITE` bigint(20) unsigned NOT NULL, `COUNT_FETCH` bigint(20) unsigned NOT NULL, `SUM_TIMER_FETCH` bigint(20) unsigned NOT NULL, `MIN_TIMER_FETCH` bigint(20) unsigned NOT NULL, `AVG_TIMER_FETCH` bigint(20) unsigned NOT NULL, `MAX_TIMER_FETCH` bigint(20) unsigned NOT NULL, `COUNT_INSERT` bigint(20) unsigned NOT NULL, `SUM_TIMER_INSERT` bigint(20) unsigned NOT NULL, `MIN_TIMER_INSERT` bigint(20) unsigned NOT NULL, `AVG_TIMER_INSERT` bigint(20) unsigned NOT NULL, `MAX_TIMER_INSERT` bigint(20) unsigned NOT NULL, `COUNT_UPDATE` bigint(20) unsigned NOT NULL, `SUM_TIMER_UPDATE` bigint(20) unsigned NOT NULL, `MIN_TIMER_UPDATE` bigint(20) unsigned NOT NULL, `AVG_TIMER_UPDATE` bigint(20) unsigned NOT NULL, `MAX_TIMER_UPDATE` bigint(20) unsigned NOT NULL, `COUNT_DELETE` bigint(20) unsigned NOT NULL, `SUM_TIMER_DELETE` bigint(20) unsigned NOT NULL, `MIN_TIMER_DELETE` bigint(20) unsigned NOT NULL, `AVG_TIMER_DELETE` bigint(20) unsigned NOT NULL, `MAX_TIMER_DELETE` bigint(20) unsigned NOT NULL, UNIQUE KEY `OBJECT` (`OBJECT_TYPE`,`OBJECT_SCHEMA`,`OBJECT_NAME`,`INDEX_NAME`)) ENGINE=PERFORMANCE_SCHEMA DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci1 row in set (0. 00 sec)查看文档中对于该表的介绍：26. 12. 16. 8. 2 The table_io_waits_summary_by_index_usage Table table_io_waits_summary_by_index_usage表整合了所有索引的I/O操作信息该表的列分类（同table_io_waits_summary_by_table 相同），按照(OBJECT_TYPE, OBJECT_SCHEMA, OBJECT_NAME)这三个字段进行group。 指标分类：: COUNT_STAR, SUM_TIMER_WAIT, MIN_TIMER_WAIT, AVG_TIMER_WAIT, MAX_TIMER_WAITThese columns aggregate all I/O operations. They are the same as the sum of the corresponding xxx_READ and xxx_WRITE columns. 对应xxx_READ 和 xxx_WRITE 列的和 COUNT_READ, SUM_TIMER_READ, MIN_TIMER_READ, AVG_TIMER_READ, MAX_TIMER_READThese columns aggregate all read operations. They are the same as the sum of the corresponding xxx_FETCH columns. 对应xxx_FETCH 列的和 COUNT_WRITE, SUM_TIMER_WRITE, MIN_TIMER_WRITE, AVG_TIMER_WRITE, MAX_TIMER_WRITEThese columns aggregate all write operations. They are the same as the sum of the corresponding xxx_INSERT, xxx_UPDATE, and xxx_DELETE columns. 对应 xxx_INSERT，xxx_UPDATE，xxx_DELETE三个值的和 COUNT_FETCH, SUM_TIMER_FETCH, MIN_TIMER_FETCH, AVG_TIMER_FETCH, MAX_TIMER_FETCHThese columns aggregate all fetch operations. 所有的select操作次数 COUNT_INSERT, SUM_TIMER_INSERT, MIN_TIMER_INSERT, AVG_TIMER_INSERT, MAX_TIMER_INSERTThese columns aggregate all insert operations. 所有的insert操作次数 COUNT_UPDATE, SUM_TIMER_UPDATE, MIN_TIMER_UPDATE, AVG_TIMER_UPDATE, MAX_TIMER_UPDATEThese columns aggregate all update operations. 所有的update 操作次数 COUNT_DELETE, SUM_TIMER_DELETE, MIN_TIMER_DELETE, AVG_TIMER_DELETE, MAX_TIMER_DELETEThese columns aggregate all delete operations. 所有的delete 操作次数. 对于INDEX_NAME列：1. A value of PRIMARY indicates that table I/O used the primary index. 2. A value of NULL means that table I/O used no index. 3. Inserts are counted against INDEX_NAME = NULL 举例: 12345678910&lt;br&gt;&lt;/br&gt;mysql&amp;gt; select * from performance_schema. table_io_waits_summary_by_index_usage where object_schema='wstest' and object_name='test2' limit 10 ;+-------------+---------------+-------------+------------+------------+----------------+----------------+----------------+----------------+------------+----------------+----------------+----------------+----------------+-------------+-----------------+-----------------+-----------------+-----------------+-------------+-----------------+-----------------+-----------------+-----------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+| OBJECT_TYPE | OBJECT_SCHEMA | OBJECT_NAME | INDEX_NAME | COUNT_STAR | SUM_TIMER_WAIT | MIN_TIMER_WAIT | AVG_TIMER_WAIT | MAX_TIMER_WAIT | COUNT_READ | SUM_TIMER_READ | MIN_TIMER_READ | AVG_TIMER_READ | MAX_TIMER_READ | COUNT_WRITE | SUM_TIMER_WRITE | MIN_TIMER_WRITE | AVG_TIMER_WRITE | MAX_TIMER_WRITE | COUNT_FETCH | SUM_TIMER_FETCH | MIN_TIMER_FETCH | AVG_TIMER_FETCH | MAX_TIMER_FETCH | COUNT_INSERT | SUM_TIMER_INSERT | MIN_TIMER_INSERT | AVG_TIMER_INSERT | MAX_TIMER_INSERT | COUNT_UPDATE | SUM_TIMER_UPDATE | MIN_TIMER_UPDATE | AVG_TIMER_UPDATE | MAX_TIMER_UPDATE | COUNT_DELETE | SUM_TIMER_DELETE | MIN_TIMER_DELETE | AVG_TIMER_DELETE | MAX_TIMER_DELETE |+-------------+---------------+-------------+------------+------------+----------------+----------------+----------------+----------------+------------+----------------+----------------+----------------+----------------+-------------+-----------------+-----------------+-----------------+-----------------+-------------+-----------------+-----------------+-----------------+-----------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+| TABLE    | wstest    | test2    | PRIMARY  |     6 |   139617054 |    8265600 |    23269509 |    42271164 |     0 |       0 |       0 |       0 |       0 |      6 |    139617054 |     8265600 |    23269509 |    42271164 |      0 |        0 |        0 |        0 |        0 |      0 |        0 |        0 |        0 |        0 |      6 |    139617054 |     8265600 |     23269509 |     42271164 |      0 |        0 |        0 |        0 |        0 || TABLE    | wstest    | test2    | idx_name  |     7 |    69869781 |    6575211 |    9981081 |    23699394 |     7 |    69869781 |    6575211 |    9981081 |    23699394 |      0 |        0 |        0 |        0 |        0 |      7 |    69869781 |     6575211 |     9981081 |    23699394 |      0 |        0 |        0 |        0 |        0 |      0 |        0 |        0 |        0 |        0 |      0 |        0 |        0 |        0 |        0 || TABLE    | wstest    | test2    | NULL    |     25 |   249500088 |     836154 |    9979974 |    72511083 |     19 |    76699233 |     836154 |    4036491 |    28997865 |      6 |    172800855 |    10806903 |    28800081 |    72511083 |     19 |    76699233 |     836154 |     4036491 |    28997865 |      6 |    172800855 |     10806903 |     28800081 |     72511083 |      0 |        0 |        0 |        0 |        0 |      0 |        0 |        0 |        0 |        0 |+-------------+---------------+-------------+------------+------------+----------------+----------------+----------------+----------------+------------+----------------+----------------+----------------+----------------+-------------+-----------------+-----------------+-----------------+-----------------+-------------+-----------------+-----------------+-----------------+-----------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+3 rows in set (0. 00 sec)可以看出，对于test2表，PRIMARY主键共使用了6次（COUNT_WRITE=6，即按照主键顺序写入了6行数据），idx_name供使用了7次（COUNT_READ=7，读了7行），再次读取后查看状态： 123456789101112131415161718192021222324252627282930313233mysql&amp;gt; explain select * from wstest. test2 where name='111xyz';+----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key   | key_len | ref  | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------+| 1 | SIMPLE   | test2 | NULL    | ref | idx_name   | idx_name | 93   | const |  6 |  100. 00 | NULL |+----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------+1 row in set, 1 warning (0. 00 sec)mysql&amp;gt; select * from wstest. test2 where name='111xyz';  +----+--------+--------+------+-------+| id | name  | status | addr | addr2 |+----+--------+--------+------+-------+| 1 | 111xyz |  110 |   |   0 || 2 | 111xyz |  110 |   |   0 || 3 | 111xyz |  110 |   |   0 || 4 | 111xyz |  110 |   |   0 || 5 | 111xyz |   5 |   |   0 || 6 | 111xyz |  110 |   |   0 |+----+--------+--------+------+-------+6 rows in set (0. 00 sec)mysql&amp;gt; select * from performance_schema. table_io_waits_summary_by_index_usage where object_schema='wstest' and object_name='test2' limit 10 ;+-------------+---------------+-------------+------------+------------+----------------+----------------+----------------+----------------+------------+----------------+----------------+----------------+----------------+-------------+-----------------+-----------------+-----------------+-----------------+-------------+-----------------+-----------------+-----------------+-----------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+| OBJECT_TYPE | OBJECT_SCHEMA | OBJECT_NAME | INDEX_NAME | COUNT_STAR | SUM_TIMER_WAIT | MIN_TIMER_WAIT | AVG_TIMER_WAIT | MAX_TIMER_WAIT | COUNT_READ | SUM_TIMER_READ | MIN_TIMER_READ | AVG_TIMER_READ | MAX_TIMER_READ | COUNT_WRITE | SUM_TIMER_WRITE | MIN_TIMER_WRITE | AVG_TIMER_WRITE | MAX_TIMER_WRITE | COUNT_FETCH | SUM_TIMER_FETCH | MIN_TIMER_FETCH | AVG_TIMER_FETCH | MAX_TIMER_FETCH | COUNT_INSERT | SUM_TIMER_INSERT | MIN_TIMER_INSERT | AVG_TIMER_INSERT | MAX_TIMER_INSERT | COUNT_UPDATE | SUM_TIMER_UPDATE | MIN_TIMER_UPDATE | AVG_TIMER_UPDATE | MAX_TIMER_UPDATE | COUNT_DELETE | SUM_TIMER_DELETE | MIN_TIMER_DELETE | AVG_TIMER_DELETE | MAX_TIMER_DELETE |+-------------+---------------+-------------+------------+------------+----------------+----------------+----------------+----------------+------------+----------------+----------------+----------------+----------------+-------------+-----------------+-----------------+-----------------+-----------------+-------------+-----------------+-----------------+-----------------+-----------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+| TABLE    | wstest    | test2    | PRIMARY  |     6 |   139617054 |    8265600 |    23269509 |    42271164 |     0 |       0 |       0 |       0 |       0 |      6 |    139617054 |     8265600 |    23269509 |    42271164 |      0 |        0 |        0 |        0 |        0 |      0 |        0 |        0 |        0 |        0 |      6 |    139617054 |     8265600 |     23269509 |     42271164 |      0 |        0 |        0 |        0 |        0 || TABLE    | wstest    | test2    | idx_name  |     13 |   164544849 |    6575211 |    12657069 |    74654973 |     13 |   164544849 |    6575211 |    12657069 |    74654973 |      0 |        0 |        0 |        0 |        0 |     13 |    164544849 |     6575211 |    12657069 |    74654973 |      0 |        0 |        0 |        0 |        0 |      0 |        0 |        0 |        0 |        0 |      0 |        0 |        0 |        0 |        0 || TABLE    | wstest    | test2    | NULL    |     25 |   249500088 |     836154 |    9979974 |    72511083 |     19 |    76699233 |     836154 |    4036491 |    28997865 |      6 |    172800855 |    10806903 |    28800081 |    72511083 |     19 |    76699233 |     836154 |     4036491 |    28997865 |      6 |    172800855 |     10806903 |     28800081 |     72511083 |      0 |        0 |        0 |        0 |        0 |      0 |        0 |        0 |        0 |        0 |+-------------+---------------+-------------+------------+------------+----------------+----------------+----------------+----------------+------------+----------------+----------------+----------------+----------------+-------------+-----------------+-----------------+-----------------+-----------------+-------------+-----------------+-----------------+-----------------+-----------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+--------------+------------------+------------------+------------------+------------------+3 rows in set (0. 00 sec)得到，再次使用idx_name查询数据时，返回了6条数据，在统计结果中，idx_name的COUNT_STAR从7增加到了13（均为COUNT_READ，COUNT_READ从7变为13），据此，可使用该统计信息判断索引使用的频次。 sys库中的统计信息sys数据库中整合了performance_schema数据库的指标，例如： 12345678mysql&amp;gt; show create table sys. schema_index_statistics \G  *************************** 1. row ***************************        View: schema_index_statistics     Create View: CREATE ALGORITHM=MERGE DEFINER=`mysql. sys`@`localhost` SQL SECURITY INVOKER VIEW `sys`. `schema_index_statistics` (`table_schema`,`table_name`,`index_name`,`rows_selected`,`select_latency`,`rows_inserted`,`insert_latency`,`rows_updated`,`update_latency`,`rows_deleted`,`delete_latency`) AS select `performance_schema`. `table_io_waits_summary_by_index_usage`. `OBJECT_SCHEMA` AS `table_schema`,`performance_schema`. `table_io_waits_summary_by_index_usage`. `OBJECT_NAME` AS `table_name`,`performance_schema`. `table_io_waits_summary_by_index_usage`. `INDEX_NAME` AS `index_name`,`performance_schema`. `table_io_waits_summary_by_index_usage`. `COUNT_FETCH` AS `rows_selected`,`sys`. `format_time`(`performance_schema`. `table_io_waits_summary_by_index_usage`. `SUM_TIMER_FETCH`) AS `select_latency`,`performance_schema`. `table_io_waits_summary_by_index_usage`. `COUNT_INSERT` AS `rows_inserted`,`sys`. `format_time`(`performance_schema`. `table_io_waits_summary_by_index_usage`. `SUM_TIMER_INSERT`) AS `insert_latency`,`performance_schema`. `table_io_waits_summary_by_index_usage`. `COUNT_UPDATE` AS `rows_updated`,`sys`. `format_time`(`performance_schema`. `table_io_waits_summary_by_index_usage`. `SUM_TIMER_UPDATE`) AS `update_latency`,`performance_schema`. `table_io_waits_summary_by_index_usage`. `COUNT_DELETE` AS `rows_deleted`,`sys`. `format_time`(`performance_schema`. `table_io_waits_summary_by_index_usage`. `SUM_TIMER_DELETE`) AS `delete_latency` from `performance_schema`. `table_io_waits_summary_by_index_usage` where (`performance_schema`. `table_io_waits_summary_by_index_usage`. `INDEX_NAME` is not null) order by `performance_schema`. `table_io_waits_summary_by_index_usage`. `SUM_TIMER_WAIT` desccharacter_set_client: utf8mb4collation_connection: utf8mb4_0900_ai_ci1 row in set (0. 00 sec)与之对应的sys. x$schema_index_statistics则提供了更为精确的value，方便工具进行调用。 举例: 查询： 12345678910mysql&amp;gt; select * from sys. schema_index_statistics where table_schema='wstest' and table_name='test2';+--------------+------------+------------+---------------+----------------+---------------+----------------+--------------+----------------+--------------+----------------+| table_schema | table_name | index_name | rows_selected | select_latency | rows_inserted | insert_latency | rows_updated | update_latency | rows_deleted | delete_latency |+--------------+------------+------------+---------------+----------------+---------------+----------------+--------------+----------------+--------------+----------------+| wstest    | test2   | PRIMARY  |       0 | 0 ps      |       0 | 0 ps      |      6 | 139. 62 us   |      0 | 0 ps      || wstest    | test2   | idx_name  |       7 | **69. 87 us**    |       0 | 0 ps      |      0 | 0 ps      |      0 | 0 ps      |+--------------+------------+------------+---------------+----------------+---------------+----------------+--------------+----------------+--------------+----------------+2 rows in set (0. 00 sec)对应之前的再次按照idx_name查询，再次查询sys的统计信息： 123456789mysql&amp;gt; select * from sys. schema_index_statistics where table_schema='wstest' and table_name='test2';+--------------+------------+------------+---------------+----------------+---------------+----------------+--------------+----------------+--------------+----------------+| table_schema | table_name | index_name | rows_selected | select_latency | rows_inserted | insert_latency | rows_updated | update_latency | rows_deleted | delete_latency |+--------------+------------+------------+---------------+----------------+---------------+----------------+--------------+----------------+--------------+----------------+| wstest    | test2   | idx_name  |      13 | **164. 54 us**   |       0 | 0 ps      |      0 | 0 ps      |      0 | 0 ps      || wstest    | test2   | PRIMARY  |       0 | 0 ps      |       0 | 0 ps      |      6 | 139. 62 us   |      0 | 0 ps      |+--------------+------------+------------+---------------+----------------+---------------+----------------+--------------+----------------+--------------+----------------+2 rows in set (0. 00 sec)"
    }, {
    "id": 65,
    "url": "http://localhost:4000/index.php/2019/09/mysql-index-statistics-table/",
    "title": "MySQL索引统计信息INDEX_STATISTICS",
    "body": "2019/09/11 -  背景MySQL的开源版本MariaDB、Percona MySQL Server和AliSQL 5. 6版本支持统计索引的信息，即可以统计出使用某个索引扫描的行数。依照此，可以找出未被使用的，或者使用频率较低的索引，从而进行下线。本文主要介绍AliSQL 5. 6版本的使用方式，使用阿里云RDS环境。RDS MySQL5. 7开始不再具有该表，可以使用performance_schema中的统计信息table_io_waits_summary_by_index_usage进行查看 环境阿里云RDS 5. 6版本 现象测试表表结构： 1234567891011121314151617181920212223242526272829mysql&amp;gt; show create table wstest. test2 \G*************************** 1. row ***************************    Table: test2Create Table: CREATE TABLE if not exists `test2` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(30) DEFAULT '1', `status` int(11) DEFAULT '1', `addr` varchar(10) NOT NULL, `addr2` tinyint(4) NOT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`)) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8mysql&amp;gt; select * from wstest. test2;+----+--------+--------+------+-------+| id | name  | status | addr | addr2 |+----+--------+--------+------+-------+| 1 | aaaxyz |  110 |   |   0 || 2 | aaaxyz |  110 |   |   0 || 3 | aaaxyz |  110 |   |   0 || 4 | aaaxyz |  110 |   |   0 || 5 | aaax  |   5 |   |   0 || 6 | aaaxyz |  110 |   |   0 |+----+--------+--------+------+-------+6 rows in set (0. 01 sec). 注意：最开始查询 information_schema. INDEX_STATISTICS 表发现结果为空，需要打开参数才会进行统计。打开参数：loose_rds_indexstat=1 使用字段name上的索引进行查询数据： 123456789mysql&amp;gt; select * from wstest. test2 where name='aaax';+----+------+--------+------+-------+| id | name | status | addr | addr2 |+----+------+--------+------+-------+| 5 | aaax |   5 |   |   0 |+----+------+--------+------+-------+1 row in set (0. 00 sec)查看统计信息： 12345678910select * from information_schema. INDEX_STATISTICS where table_schema='wstest' and table_name='test2';+--------------+------------+------------+-----------+| TABLE_SCHEMA | TABLE_NAME | INDEX_NAME | ROWS_READ |+--------------+------------+------------+-----------+| wstest    | test2   | idx_name  |     1 || wstest    | test2   | PRIMARY  |  6314081 |+--------------+------------+------------+-----------+2 rows in set (0. 02 sec)说明：由于在使用idx_name查询数据时，扫描行数为1，所以在information_schema. INDEX_STATISTICS表的ROWS_READ字段对应的值为1；若再次使用idx_name查询，则ROWS_READ会再次加1。至此，索引的使用情况得以统计。 . . . 索引下线继而，结合业务的使用情况，找出使用频率较低的索引进行下线 设置索引不可见: 可以使用： 12alter table test2 alter index idx_name invisible;使索引不可见，避免突然下线导致某些应用出现慢查。 删除索引: 设置索引不可见之后，可以过一段时间，选择低峰期将索引进行删除： 12alter table test2 drop index idx_name;"
    }, {
    "id": 66,
    "url": "http://localhost:4000/index.php/2019/09/mysql-archive-tool-pt-archiver/",
    "title": "MySQL手记11 &#8212; MySQL归档工具：pt-archiver",
    "body": "2019/09/10 - 一、使用场景生产环境在运行一段时间后，往往有需要进行归档的“冷数据”，或者是不再需要的一些数据，会导致表变得“臃肿”，以至于对表的操作很缓慢。这时候，若直接使用delete进行删除，则会对数据库系统造成较大的影响。当然，我们也可以自己写工具通过索引逐步批量进行归档，对此，Percona的pt工具包（http://codercoder. cn/index. php/2020/04/mysql-note-7-mysql-utilities-introduction/） 提供了一个非常好用的工具：pt-archiver。 pt-archiver可以灵活的对归档的过程进行控制，常用的方面有： 灵活指定where条件（使用有索引的字段进行） 是否需要归档到新表（或者是直接删除） 每批删除的数据数量 每批次中间的间隔时间（负载较高时，可以延长间隔时间） 同样，通过–help可以查看到详情： pt-archiver –help 二、注意事项12pt-archiver --source h=HOST,P=3306,D=dbname,t=tbname,u=root,p=root --no-check-charset --where  gmt_create &lt;= date_sub(curdate(), interval 30 day)  --purge --no-check-charset --limit=1000 --sleep=1 --txn-size=100 --nosafe-auto-increment --noversion-check --why-quit --progress=100000 --sentinel=/tmp/pt-ttest 2&gt;&amp;1 &gt;&gt; archive. log2. 1 生产环境中的配置: （1）误删数据 –purge：是否删除原表的数据 –where；删除的条件 （2）字符集 若需要将数据归档到新表，则必须指定字符集，防止出现字符集不一致数据乱码的问题（比较恐怖的是：数据已经删除，但是目标表乱码的情况） （3）归档的速度 –limit：每条SQL删除的行数 –sleep：间隔的秒数 –sleep-coef：间隔的时间（停顿上次select的耗时*sleep-coef） –txn-size：每个事务中包含的行数 –bulk-delete：一条sql删除一批数据 –commit-each：每批数据commit一次 （4）停止 –sentinel：存在指定的文件，就停止 2. 2 注意：: （1）日志 可根据需要，调整–progress，即每隔多少行，打印一次日志 （2）测试 可以加上–dry-run选项，即不进行真实数据操作。配合 –statistics，获取到归档的大致情况 （3）where条件 where条件最好使用索引的字段，否则可能出现归档进程消耗大量CPU，导致慢查的情况。 （4）更改默认索引 默认pt-archiver使用PRIMARY KEY去分段查询符合条件的数据（可以从审计日志看出），可以在–source的DSN中指定”i=idx_create_time”指定性能更好的索引。 例如上例审计为： 12SELECT /*!40001 SQL_NO_CACHE */ `id`,`name` FROM dbname. tbname FORCE INDEX(`PRIMARY`) WHERE (gmt_create = '26160734')) ORDER BY `id` LIMIT 1000再将获得到的主键id，按照配置，进行删除，例如根据–bulk-delete/–commit-each/–txn-size选项判断。 对于生产环境的数据来说，DBA和业务部门需要配合起来，把数据进行“冷热隔离”，使整个系统运行起来更加流畅，归档往往按照时间，把历史数据归档到目标的库表中，并每日增量执行，以保证线上数据为“热数据”。 欢迎关注公众号：朔的话： "
    }, {
    "id": 67,
    "url": "http://localhost:4000/index.php/2019/09/mysql-duplicate-check-tool-pt-duplicate-key-checker/",
    "title": "MySQL重复索引检查工具：pt-duplicate-key-checker",
    "body": "2019/09/10 - 功能介绍：在MySQL数据库表中找出重复的索引和外键，这个工具会将重复的索引和外键都列出来，并生成删除重复索引的语句。 用法介绍：pt-duplicate-key-checker [OPTION…] [DSN]包含比较多的选项，具体的可以通过命令pt-duplicate-key-checker –help来查看具体支持那些选项。 使用示例：查看test数据库的重复索引和外键使用情况： 12pt-duplicate-key-checker --host=localhost --user=root --password=aaa123 --databases=test得到结果如下： 12345678910111213141516171819202122232425262728. . . . . . Key idx_Create_id ends with a prefix of the clustered indexKey definitions:  KEY `idx_Create_id` (`CREATE`,`ID`)  PRIMARY KEY (`ID`),Column types:  `create` timestamp not null default '0000-00-00 00:00:00'   `id` bigint(20) not null auto_incrementTo shorten this duplicate clustered index, execute:   **ALTER TABLE `test`. `OUTPUT_STAT` DROP INDEX `idx_GmtCreate_id`, ADD INDEX `idx_GmtCreate_id` (`GMT_CREATE`);**########################################################################Summary of indexes                           ########################################################################Size Duplicate Indexes 252Total Duplicate Indexes 8Total Indexes      149根据日志可以看出：1. 发现了重复索引 idx_Create_id (CREATE,ID) ，可以使用以下语句进行优化：  ALTER TABLE test. OUTPUT_STAT DROP INDEX idx_GmtCreate_id, ADD INDEX idx_GmtCreate_id (GMT_CREATE); 2. 索引情况的汇总信息 "
    }, {
    "id": 68,
    "url": "http://localhost:4000/index.php/2019/09/mysql-loose-index-scan-and-tight-index-scan-introduction/",
    "title": "MySQL数据库Loose Index Scan与Tight Index Scan介绍",
    "body": "2019/09/10 - 介绍本篇文章主要介绍Loose Index Scan与Tight Index Scan，次两种方法均为group by语法时候，MySQL进行的优化方法。官方文档：Group by Optimization Group by Optimization The most general way to satisfy a GROUP BY clause is to scan the whole table and create a new temporary table where all rows from each group are consecutive, and then use this temporary table to discover groups and apply aggregate functions (if any). In some cases, MySQL is able to do much better than that and to avoid creation of temporary tables by using index access. 通常情况下，GROUP BY 语法通过扫描全表、创建临时表，并使用这个临时表进行分组和聚合运算。在某些情况下，MySQL可以使用索引来规避创建临时表。  There are two ways to execute a GROUP BY query through index access, as detailed in the following sections. In the first method, the grouping operation is applied together with all range predicates (if any). The second method first performs a range scan, and then groups the resulting tuples. GROUP BY 有两种方式使用索引。第一：group运算和所有的可能的范围一起应用；第二种：首先执行range扫描，然后再group得到的元祖。 Loose Index Scan-松散索引扫描 The most efficient way to process GROUP BY is when an index is used to directly retrieve the grouping columns. With this access method, MySQL uses the property of some index types that the keys are ordered (for example, BTREE). This property enables use of lookup groups in an index without having to consider all keys in the index that satisfy all WHERE conditions. This access method considers only a fraction of the keys in an index, so it is called a loose index scan. When there is no WHERE clause, a loose index scan reads as many keys as the number of groups, which may be a much smaller number than that of all keys. If the WHERE clause contains range predicates (see the discussion of therangejoin type inSection 8. 8. 1, “Optimizing Queries with EXPLAIN”), a loose index scan looks up the first key of each group that satisfies the range conditions, and again reads the least possible number of keys. GROUP BY 最有效的方式是：group by的字段直接覆盖索引。在此情况下。MySQL使用已按key排序的合适索引类型（例如：BTREE）。这个特性使得对于索引字段group的查找不需要检索WHERE条件的所有索引字段。这种索引方式只扫描一个索引中的部分字段，所以称之为松散索引扫描。 当没有WHERE一句时，loose index scan reads需要扫描group by 中的字段，这也比扫描全部的字段更加的轻量。若在WHERE条件中包含range条件，则loose index scan reads查询满足range条件的group by 中的第一个字段，即仅扫描最少数量的字段。 The query is over a single table. The GROUP BY names only columns that form a leftmost prefix of the index and no other columns. (If, instead of GROUP BY, the query has a DISTINCT clause, all distinct attributes refer to columns that form a leftmost prefix of the index. ) For example, if a table t1 has an index on (c1,c2,c3), loose index scan is applicable if the query has GROUP BY c1, c2,. It is not applicable if the query has GROUP BY c2, c3 (the columns are not a leftmost prefix) or GROUP BY c1, c2, c4 (c4 is not in the index). The only aggregate functions used in the select list (if any) are MIN() and MAX(), and all of them refer to the same column. The column must be in the index and must immediately follow the columns in the GROUP BY. Any other parts of the index than those from the GROUP BY referenced in the query must be constants (that is, they must be referenced in equalities with constants), except for the argument of MIN() or MAX() functions. For columns in the index, full column values must be indexed, not just a prefix. For example, with c1 VARCHAR(20), INDEX (c1(10)), the index cannot be used for loose index scan. If loose index scan is applicable to a query, the EXPLAIN output shows Using index for group-by in the Extra column. Assume that there is an index idx(c1,c2,c3) on table t1(c1,c2,c3,c4). The loose index scan access method can be used for the following queries: 1234567891011121314SELECT c1, c2 FROM t1 GROUP BY c1, c2;SELECT DISTINCT c1, c2 FROM t1;SELECT c1, MIN(c2) FROM t1 GROUP BY c1;SELECT c1, c2 FROM t1 WHERE c1 &lt; const GROUP BY c1, c2;SELECT MAX(c3), MIN(c3), c1, c2 FROM t1 WHERE c2 &gt; const GROUP BY c1, c2;SELECT c2 FROM t1 WHERE c1 &lt; const GROUP BY c1, c2;SELECT c1, c2 FROM t1 WHERE c3 = const GROUP BY c1, c2;The following queries cannot be executed with this quick select method, for the reasons given:  There are aggregate functions other than MIN() or MAX(): 12SELECT c1, SUM(c2) FROM t1 GROUP BY c1; The columns in the GROUP BY clause do not form a leftmost prefix of the index: 12SELECT c1, c2 FROM t1 GROUP BY c2, c3; The query refers to a part of a key that comes after the GROUP BY part, and for which there is no equality with a constant: 12SELECT c1, c3 FROM t1 GROUP BY c1, c2;Were the query to include WHERE c3 = const, loose index scan could be used. The loose index scan access method can be applied to other forms of aggregate function references in the select list, in addition to the MIN() and MAX() references already supported: AVG(DISTINCT), SUM(DISTINCT), and COUNT(DISTINCT) are supported. AVG(DISTINCT) and SUM(DISTINCT) take a single argument. COUNT(DISTINCT) can have more than one column argument.  There must be no GROUP BY or DISTINCT clause in the query.  The loose scan limitations described earlier still apply.  Assume that there is an index idx(c1,c2,c3) on table t1(c1,c2,c3,c4). The loose index scan access method can be used for the following queries: 1234SELECT COUNT(DISTINCT c1), SUM(DISTINCT c1) FROM t1;SELECT COUNT(DISTINCT c1, c2), COUNT(DISTINCT c2, c1) FROM t1;Tight Index Scan-紧凑索引扫描 A tight index scan may be either a full index scan or a range index scan, depending on the query conditions. 紧凑索引扫描即，要么是覆盖索引扫描或者范围索引扫描，依查询条件而定。  When the conditions for a loose index scan are not met, it still may be possible to avoid creation of temporary tables for GROUP BY queries. If there are range conditions in the WHERE clause, this method reads only the keys that satisfy these conditions. Otherwise, it performs an index scan. Because this method reads all keys in each range defined by the WHERE clause, or scans the whole index if there are no range conditions, we term it a tight index scan. With a tight index scan, the grouping operation is performed only after all keys that satisfy the range conditions have been found. 在没有满足loose index scan之前，GROUP BY查询同样是可以避免创建临时表的。如果在WHERE中有range条件，MySQL会扫描这些字段。此外，更趋向于索引扫描。因为这种方法扫描所有符合WHERE条件range中的字段，或者所有字段（没有range条件时），所以称之为tight index scan。  Assume that there is an index idx(c1,c2,c3) on table t1(c1,c2,c3,c4). The following queries do not work with the loose index scan access method described earlier, but still work with the tight index scan access method. 不能用loose index scan，但是能使用tight index scan的情况： There is a gap in the GROUP BY, but it is covered by the condition c2 = ‘a’: 12SELECT c1, c2, c3 FROM t1 WHERE c2 = 'a' GROUP BY c1, c3;The GROUP BY does not begin with the first part of the key, but there is a condition that provides a constant for that part: 12SELECT c1, c2, c3 FROM t1 WHERE c1 = 'a' GROUP BY c2, c3;"
    }, {
    "id": 69,
    "url": "http://localhost:4000/index.php/2019/09/mysql-onlineddl-error-the-total-number-of-locks-exceeds-the-lock-table-size/",
    "title": "MySQL使用原生OnlineDDL进行结构变更报错：The total number of locks exceeds the lock table size",
    "body": "2019/09/10 - 情况介绍阿里云RDS MySQL5. 6在使用原生OnlineDDL进行结构变更时报错： 12ERROR 1206 (HY000): The total number of locks exceeds the lock table size，在错误日志中： 1234567891011121314=====================================InnoDB: WARNING: over 67 percent of the buffer pool is occupied bylock heaps or the adaptive hash index! Check that yourtransactions do not set too many row locks. Your buffer pool size is 64 MB. Maybe you should make the buffer pool bigger?Starting the InnoDB Monitor to print diagnostics, including lock heap and hash index sizes. . . . . . . 问题排查1. 确认环境参数：: 查看当前的配置：max_write_lock_count =102400，该参数在MySQL5. 6 64位的环境默认值为18446744073709551615 ~ 2. 解决: 发现这个参数配置得太小了，但是阿里云RDS默认权限不允许大于102400，所以采用pt-online-schema-change进行。  若为自建的MySQL Server，可以配置： set global max_write_lock_count =18446744073709551615 在MySQL官方文档中，对于该参数的说明： "
    }, {
    "id": 70,
    "url": "http://localhost:4000/index.php/2019/09/travel-in-beijing/",
    "title": "北京游玩攻略",
    "body": "2019/09/08 - 本文按照游览顺序，介绍去北京时候游览的景点，作为攻略参考。注：故宫一定要提前在官网订票，因为每天限制3万人，不预约就游览不了了 Day11. 1 颐和园: 建议选择下午的时间去游览，早上的时间，去一些需要早起的景点：例如升旗，长城等，下文也会有介绍 颐和园为慈禧命人修建，仿照了数个著名景点，小学课本中的“十七孔桥”也在颐和园之中。游览时间3小时：从北边门进，进门后从右手边开始逐一游览，最后从东门出，东门距离地铁站近一些~ 1. 2 南锣鼓巷: 早就听闻南锣鼓巷，胡同作为北京的标志，当然必须打卡。 从颐和园东门出来之后，直接去地铁站坐地铁到南锣鼓巷，大概需要一个小时左右时间。到了南锣鼓巷，千万别先开吃，酒香不怕巷子深，去附近的胡同里，才是美食的天地~ 北冰洋为必喝饮料哈 1. 3 住宿: 北京市区的住宿不算便宜，提前预定了快捷酒店，大概300块的样子。第一天美美的结束，回酒店好好休息咯~ 对了，由于第二天行程有长城，所以最好是买一些干粮和水果，到时候带过去解决吃饭问题。 Day22. 1 长城: 毛泽东的一句：不到长城非好汉。带动了大家爬长城的热情。早上早早起床，坐第一趟地铁去换成去长城大巴，大巴收费是12块（大巴可以按照地图推荐），每辆大巴上都有导游，进行简单的介绍，要到长城时候就会比较堵车，全程大概2~3小时。 长城上下坡可以选择：索道、滑车、走路。可以根据天气进行选择，我选择的是滑车上坡，走路下坡，因为太兴奋，想要看到山上的美景。其实滑索和滑车都只是到达半山腰，剩下的部分需要自己领略。 不得不说，那么早起床过来，都是很多人，可以说是超级热门景点了。长城风景很美，好汉坡好汉很多。 2. 2 798艺术街区: 从长城原路返回，直奔798艺术区，在艺术区门口买了“烤冷面”，也算是填饱了肚子哈哈。 798艺术区是由以前的工厂区改造的，是大部分文艺青年的打卡地。 艺术区里面，还大量保留了以前的工厂厂房，还有很多有意思的涂鸦，涂鸦文化其实也是一种宣扬，展示自己的主张是一件很酷的事~ 话不多说，上图： 2. 3 三里屯太古里: 下午逛完798，晚上就想去逛逛商场了哈哈，那就去太古里吧~ 太古里就是普通的商场样子，可以在里面吃晚餐吃完喝完，就可以回酒店休息了，第二天的行程安排比较紧凑，很累了~ Day3需要去天安门看升旗，所以需要提前查好升旗的时间，提前2小时到达时最好的。 Day33. 1 天安门广场: 天安门广场的升级绝对是能激起爱国情怀的地方。 早上4点就起床了（据说有的游客是第一天直接在天安门睡觉），简单打理就直奔天安门。是打车去的，地铁还没有运行，北京打车价格打表，不算是特别贵。一定要带上身份证 一定带上自拍杆 到了之后，跟着人群，一起去过安检，过完安检之后，就可以去到天安门前面的长安街（十里长街送总理就是长安街），人很多，所以大家都是用自拍杆居高拍照不然根本看不到仪仗队了。 时间到了，仪仗队从天安门出来，越过长安街，走到升旗台，整个过程端庄有序，音乐声音很小，但是整个过程大家都保持安静。\ &lt;/source&gt;&lt;http://codercoder. cn/wp-content/uploads/2019/09/2019-09-0816. mp4&gt;[/video] 当然天安门的国旗也是非常多 3. 2 园博园: 国庆期间，园博园里举办了中国戏曲文化节，非常有意思，在科技进步的同时，文化的传承也尤为重要\ &lt;/source&gt;&lt;http://codercoder. cn/wp-content/uploads/2019/09/2019-09-0816. mp4&gt;[/video]园博园除了有表演以外，还有很多游客可以参与的地方，cosplay，剪纸，变脸涂鸦等等 ## 3. 3 晚餐 园博园出来，坐地铁到了酒店附近，找打一家涮羊肉的火锅店，要了一个铜锅，蘸着老北京麻酱，美滋滋~ 3. 4 奥体中心: 坐地铁到奥体中心，看看奥运会时候的建筑，仍然觉得焕然一新，科技感十足 Day4Day4安排的行程都是小景点，可以慢悠悠的逛逛~ 天坛: 天坛为历史上皇帝进行祭祀的用地，所以会有很多的风水讲究，可以听听沿路的导游对于景点的介绍。 天坛的票是按照景点验票的，一个景点只能进一次 白塔: 天坛出来之后，想要去白塔看看，毕竟小时候学过一首：小船儿轻轻，飘荡在水中~ 就想看看是什么样的白塔门票不贵，10元 天安门城楼: 今天想要早一点回去休息，就选择去了天安门（比较近）和旁边的王府井 Day5故宫: 本来第一天就想到故宫了，需要预约，所以~ 好不容易预约到了名额~ 故宫有很多奇闻异事，走的时候听听沿路的导游的介绍，又或者租用一个讲解器，都是非常不错的选择 故宫实在太美，在此先放两张图，文末就是故宫图集啦 西单小吃: 特意去西单吃一点小吃 北京地铁: 背景地铁的建设，相当完善，所以建议办卡，回程的时候在高铁站可以进行退卡，很方便。 故宫图集 "
    }, {
    "id": 71,
    "url": "http://localhost:4000/index.php/2019/09/mysql-sersion-introduction/",
    "title": "MySQL版本区分",
    "body": "2019/09/08 - alpha暗示这是一个以展示新特性为目的的版本，存在比较多的不稳定因素，还会向代码中添加新新特性 beta以后的beta版、发布版或产品发布中，所有API、外部可视结构和SQL命令列均不再更改,不再向代码中添加影响代码稳定性的新特性。 RC指 Release Candidate. Release candidates被认为是稳定的, 通过了mysql所有的内部测试, 修正了所有已知的致命bug. 但是rc版本还没有经历足够长的时间来确认所有bug都已经发现，但是对rc版本只会做些小的bug修正 GA如果没有后缀,则暗示这是一个大多数情况下可用版本或者是产品版本。. GA releases是稳定的, 并通过了早期版本的测试，并显示其可用性， 解决了所有严重的bug, 并且适合在生产环境中使用. 只有少数较为严重的bug修改才会添加到该版本中。 通常来讲我们在生产环境中还是建议使用GA版本🙂 "
    }, {
    "id": 72,
    "url": "http://localhost:4000/index.php/2019/09/mysql5-7-lossless-semi-replication/",
    "title": "MySQL5.7 lossless 半同步复制",
    "body": "2019/09/08 - 1. 简介MySQL5. 7版本的半同步复制（semi-synchronous ），解决了在主机或者网络在数据同步阶段出现问题时数据不一致的问题，所以官方称其为lossless replication。 在半同步复制过程中，使用普通方式（after commit）还是无损复制（after sync），使用rpl_semi_sync_master_wait_point进行配置，该参数有两种值，本文将进行介绍。 2. AFTER SYNC &amp; AFTER COMMIT&amp; 在官方文档中，有如下两种数据同步的方式： AFTER_SYNC (the default): The master writes each transaction to its binary log and the slave, and syncs the binary log to disk. The master waits for slave acknowledgment of transaction receipt after the sync. Upon receiving acknowledgment, the master commits the transaction to the storage engine and returns a result to the client, which then can proceed. 主库把每一个事务写到二进制日志并保存磁盘上，且发送给从库。主库在等待从库写到自己的relay-log里确认信息。在接到确认信息后，主数据库把事务写到存储引擎里并把相应结果反馈给客户端，客户端将在那时进行处理。 AFTER_COMMIT: The master writes each transaction to its binary log and the slave, syncs the binary log, and commits the transaction to the storage engine. The master waits for slave acknowledgment of transaction receipt after the commit. Upon receiving acknowledgment, the master returns a result to the client, which then can proceed. 主库把每一个事务写到二进制日志并保存磁盘上，且发送给从库，并把事务写到存储引擎里。主库在等待从库写到自己的relay-log里确认信息。在接到确认信息后，主库把相应结果反馈给客户端，客户端将在那时进行处理。 3. 两种数据commit方式的差异：• With AFTER_SYNC, all clients see the committed transaction at the same time: After it has been acknowledged by the slave and committed to the storage engine on the master. Thus, all clients see the same data on the master. In the event of master failure, all transactions committed on the master have been replicated to the slave (saved to its relay log). A crash of the master and failover to the slave is lossless because the slave is up to date. Note, however, that the master cannot be restarted in this scenario and must be discarded, because its binary log might contain uncommitted transactions that would cause a conflict with the slave when externalized after binary log recovery. AFTER_SYNC: 当master宕机时，所有在maser上已经提交的事务已经被复制到slave上（slave的relay log中）。所以master的宕机对于从库来说，是不会丢失数据的，因为slave已经有了最新的数据。注意：若master宕机，不能将主机重新进入集群，必须将其从集群中“踢出”，因为master的binary log可能已经包含了未提交的事务（uncommitted transactions），当master重启进行binary log recovery时，会导致这部分事务和slave的已提交的事务冲突。 • With AFTER_COMMIT, the client issuing the transaction gets a return status only after the server commits to the storage engine and receives slave acknowledgment. After the commit and before slave acknowledgment, other clients can see the committed transaction before the committing client. If something goes wrong such that the slave does not process the transaction, then in the event of a master crash and failover to the slave, it is possible that such clients will see a loss of data relative to what they saw on the master. AFTER_COMMIT: 当slave没有收到master发送的数据(binlog)时，此时master宕机，在slave上将不能看到在master上已经提交的这部分事务的数据。 4. 两种方式性能对比两种方式的commit路径： 在半同步复制中，若出现复制线程卡主，可以看到“Waiting for semi-sync ACK from slave” 的状态。那此时两种路径，等待的阶段则不同：  对于after sync（即lossless），事务阻塞在等待slave将binary log写入relay log并flush disk的ACK，此时事务没有commit; 对于after commit（即普通的semi-sync），事务commit后，等待slave将binary log写入relay log并flush disk的ACK。**由此可推断：after sync的性能优于after commit： **  因为after sync在等到从库写relay log时，可以堆积事务，在下一个commit阶段进行group commit。 5. rpl_semi_sync_master_timeout配置对于数据的一致性，可通过rpl_semi_sync_master_timeout进行配置： 变量解释：  A value in milliseconds that controls how long the master waits on a commit for acknowledgment from a slave before timing out and reverting to asynchronous replication 即当semi-synchronous等待超时时，转为异步同步的超时时间。 根据CAP理论：  【C】 一致性 【A】 可用性 【P】 分区容忍性三者不可兼得，至少需牺牲其中一个  若将rpl_semi_sync_master_timeout设置为很大，即牺牲可用性，则可以得到数据的强一致性； 若将rpl_semi_sync_master_timeout设置为很小或直接使用原生的异步复制，即牺牲强一致性，能获取到更快的速读（可用性）。在实际生产环境中需要进行权衡，配置合适的值。 "
    }, {
    "id": 73,
    "url": "http://localhost:4000/index.php/2019/09/mysql-deadlock-unique-index-example/",
    "title": "MySQL死锁案例_唯一索引",
    "body": "2019/09/08 - 1. 情况描述近期在MySQL数据库中产生了死锁的情况，与通常的死锁不同，由于表中有唯一索引，所以加锁方式也比较有趣，本文将对于该例进行阐述(本文将对数据进行脱敏操作)： 环境描述:+ 隔离级别：READ-COMMITTED 表结构： 12345678910111213141516show create table \GCREATE TABLE if not exists `uniq` (`id` int(11) NOT NULL AUTO_INCREMENT,`aa` int(11) DEFAULT NULL,`bb` int(11) DEFAULT NULL,PRIMARY KEY (`id`),UNIQUE KEY `uniq_ab` (`aa`,`bb`)) ENGINE=InnoDB DEFAULT CHARSET=utf8注意其中存在唯一索引：UNIQUE KEY uniq_ab (aa,bb) 2. 分析SQL执行顺序： 问题解析：+ 对于唯一索引，insert成功后，会加上X lock；  对于唯一索引的插入，需要在插入前进行duplicate key的检查，所以需要申请加上S lock，由于S lock与X lock不兼容，所以产生锁等待； 由于GAP与INSERT_INTENTION不兼容，所以产生锁等待，至此死锁产生。3. 基本概念MySQL Innodb中的锁：(参照：https://dev. mysql. com/doc/refman/8. 0/en/innodb-locking. html)：  S LOCK：共享锁，也称读锁 X LOCK：排它锁，也称写锁 IS LOCK：暗示一个事务需要加共享锁 IX LOCK：暗示一个事务需要加排它锁对应的兼容关系： 此外，还有一套更为精准的判断逻辑，以符合更多场景，所以MySQL还具有以下几类的锁类型：  Record lock(记录锁)：加在索引行上的锁。 GAP lock(间隙锁)：加在record两侧间隙上的锁，但是不包括数据本身。 Next-key lock：Record lock + GAP lock INSERT_INTENTION lock(插入意向锁)：在insert之前，需要申请INSERT_INTENTION lock举例: 1234567891011  Session1:                   mysql&gt; CREATE TABLE if not exists child (id int(11) NOT NULL, PRIMARY KEY(id)) ENGINE=InnoDB;                mysql&gt; INSERT INTO child (id) values (90),(102);                       mysql&gt; START TRANSACTION;                       mysql&gt; SELECT * FROM child WHERE id &gt; 100 FOR UPDATE;            Session2:  mysql&gt; START TRANSACTION;                                  mysql&gt; INSERT INTO child (id) VALUES (101);      则Session2会产生INSERT_INTENTION lock waiting  Insert对于唯一索引的加锁方式： 对于insert的行，加上X lock，在Insert之前，需要加上 INSERT_INTENTION lock。 4. 问题解决（1）方案一(调整后端)： 由于事发的逻辑为：一个事务中进行多次insert。在数据库层面的展示即为多次申请锁资源，并且是并发的事务，所以当插入的数据出现资源抢占时，容易发生死锁。 所以建议：insert时插入多个值，一次性申请该sql的所有锁资源。这样，则可以避免多次申请锁资源，同时在性能上也能得以提升。 （2）方案二(调整前端逻辑)： 规避重复触发的情况，防止不同事务在唯一索引上插入相同数据。 5. 附加innodb-record-level-locks Gap locking can be disabled explicitly. This occurs if you change the transaction isolation level to READ COMMITTED or enable the innodb_locks_unsafe_for_binlog system variable. Under these circumstances, gap locking is disabled for searches and index scans and is used only for foreign-key constraint checking and duplicate-key checking. 间隙锁定可以显式禁用：将事务隔离级别更改为READ-COMMITTED或启用innodb_locks_unsafe_for_binlog系统变量。在这种情况下，对于搜索和索引扫描，间隙锁定将被禁用，此时gap锁仅用于外键约束检查和重复键检查。 "
    }, {
    "id": 74,
    "url": "http://localhost:4000/index.php/2019/09/mysql-the-datetime-column-rounding-causes-data-inconsistency/",
    "title": "MySQL datetime字段“四舍五入”导致数据不一致",
    "body": "2019/09/08 - 情况介绍近日，在两个数据库比对中发现数据不一致的情况，相同的插入语句（由mybatis生成），在查询时，发现其中一个的insert_time为’2018-07-27 10:59:59’，另一个为’2018-07-27 11:00:00’。想到是插入时候时间精度不一致的原因，进行排查。 在审计中可以看到两次的插入datetime不一样，一次为’2018-07-27 10:59:59’，另一哥insert为：’2018-07-27 10:59:59. 881’，原因找到，可是基本原理是什么呢？ 猜想MySQL进行了“四舍五入”的操作，导致两边数据出现不一致的问题，数据库环境为MySQL 5. 6. 16，查看官方文档：Fractional Seconds in Time Values MySQL 5. 6. 4 and up expands fractional seconds support for TIME, DATETIME, and TIMESTAMP values, with up to microseconds (6 digits) precision:  从MySQL 5. 6. 4起，对于TIME, DATETIME, TIMESTAMP字段，最高可支持到微秒（小数点后6位）的精度 Inserting a TIME, DATE, or TIMESTAMP value with a fractional seconds part into a column of the same type but having fewer fractional digits results in rounding, as shown in this example: No warning or error is given when such rounding occurs. This behavior follows the SQL standard, and is not affected by the server’s sql_mode setting. 插入到相同或者精度更短的字段中时，会进行“四舍五入”，并且不会有任何提示。 此外，JDBC同样也向数据库中提交了毫秒的精度：  5. 1. 6版本：直接舍弃毫秒部分 5. 1. 30版本：保留毫秒部分并发送到server解决思路 通过在程序中截断毫秒的部分：实现com. ibatis. sqlmap. client. extensions. TypeHandlerCallback接口，对ibatis针对java. util. Date类型的赋值前进行拦截，强制丢弃毫秒部分。 若需要存储毫秒精度，则在表定义时进行配置。"
    }, {
    "id": 75,
    "url": "http://localhost:4000/index.php/2019/09/checks-to-successfully-upgrade-mongodb/",
    "title": "MongoDB升级注意事项",
    "body": "2019/09/08 - 7 Checks to Successfully Upgrade MongoDB Replica Set in Production 注：本篇文章介绍的“升级检查”，同样可以适用于其它数据库关于升级前的检查项。 1. 数据兼容性在release changes里面进行查看，是否有configurations, metadata, protocol version, validations, indexes or options等的一些变化 2. 驱动兼容性可以在网站上进行对比: The driver compatibility matrix lists the versions of MongoDB and language-specific versions that are compatible with those versions. 3. 更新的顺序不要跨多个版本进行升级，例如想要从3. 4升级到4. 0，请先升级到3. 6  Upgrade your current MongoDB version to the latest revision of current release series Go to check 1 and plan your upgrade4. 设置兼容配置Feature Compatibility Flags， 可以setFeatureCompatibilityVersion allows you to set the features those are incompatible with the previous versions ON or OFF. 5. 在测试环境先进行演练Now that you’re prepared, you can upgrade the MongoDB replica set in rolling fashion. This upgrade will involve the DB upgrade, driver upgrades and application code that is compatible with this driver version and DB version. To minimize the impact, upgrade secondaries in a replica set first, followed by stepping down a primary and its upgrade. Test your downgrade path:Prepare for downgrading in the test environment. A MongoDB replica set must follow the downgrade path from the path to be upgraded to, to the latest revision of the currently used release series. 为使影响最小，先升级从节点secondaries ，再升级主节点primary。 制定降级方案。 6. 预发布 Allow a Burn-in Period出现问题可以按照4进行配置（甚至是回滚） 7. Upgrade MongoDB Tools Upgrade the mongo shell to the same version as the MongoDB deployment Upgrade mongodump and mongorestore versions used in your backup and restore scripts.  Use the same version of mongodump/mongorestore to backup/restore deployment of the same version on MongoDB. 使用相同版本的mongo shell，升级mongodump和mongorestore 工具。 "
    }, {
    "id": 76,
    "url": "http://localhost:4000/index.php/2019/09/log4j-oom/",
    "title": "打日志还能出问题？记一次log4j日志导致线上OOM问题案例",
    "body": "2019/09/07 - 最近一个服务突然出现 OutOfMemoryError，两台服务因为这个原因挂掉了，一直在full gc。还因为这个问题我们小组吃了一个线上故障。很是纳闷，一直运行的好好的，怎么突然就不行了呢。。。配置了一个 -XX:+HeapDumpOnOutOfMemoryError（该参数作用是在第一次发生OOM错误时候会打印dump内存信息），便开始通过dump文件开始查找问题。 项目各项环境参数：项目使用dubbo框架，dubbo线程池配置500项目内存配置2G，old区1. 5G项目使用 Log4j + Disruptor 实现的异步记录日志log4j-api版本2. 6. 2 log4j-core版本2. 6. 2disruptor版本3. 3. 6 问题分析:都知道发生OOM问题是因为内存不够，造成原因却有很多。具体的场景具体分析，通过gc日志发现每次full gc回收的内存越来越少，造成最后OutOfMemoryError: GC overhead limit exceeded。通过Java MAT工具分析dump发现，一个最大dubbo线程占用内存12M，总的dubbo线程占用内存加起来都已经1. 6G了。 为什么一个dubbo线程会占用这个大的内存呢，很是奇怪，节点打开一个具体线程信息看到， 一个dubbo线程是有一个threadlocal对象，threadlocal对象里面引用了一个java StringBuilder对象，改对象有char数组6百多万，占用内存12M。通过ThreadLocalMap$Entry对象里referent属性找到引用ThreadLocal对象: 看到这里，觉得有点希望了，继续打开代码搜索log4j中ParameterizedMessage类，看到里面有一行代码： // storing JDK classes in ThreadLocals does not cause memory leaks in web apps, so this is okay&lt;br&gt;&lt;/br&gt;  private static ThreadLocal threadLocalStringBuilder = new ThreadLocal();这个StringBuilder不就是上面看到打对象吗，知道了这个对象，接下来就是看这个ThreadLocal是怎么使用的啦。继续查看log4j + Disurptor源码。。。发现在打日志代码中，RingBufferLogEvent中setMessage方法会进行打印日志的一个格式化， 继续跟进去，看看格式化具体做了什么即 ParameterizedMessage. getFormattedmessage()方法 问题就出在这个方法里，方法是从当前线程ThreadLocal里面拿到StringBuilder对象，然后每次将length置0，然后将日志append进去所以从这里就知道，只要有一次日志内容打印很多情况下，会造成StringBuilder里字段串对象很大，而且是不会销毁（除非当前ThreadLocal线程死了，前面说了项目配置了dubbo 500个线程，dubbo线程不死，所以这个对象一直都在），打印大日志对象次数多了，基本上造成所有dubbo线程ThreadLocal StringBuilder对象都很大。正如第一幅图看到一样，最终造成OOM。 log4j 2. 6. 2这里进行日志格式化，打印日志内容过大时候确实会造成这个问题然后拉取了下log4j新一些的，发现在log4j 在2. 9. 0版本解决了这个问题，如何解决的呢，具体来看看代码吧，还是ParameterizedMessage. getFormattedmessage()这个方法： 发现只多了一行代码，继续看： 这里回判断如果stringbuilder不为null并且容量大于maxSize（这个参数可配，默认518），会将长度置为maxSize，然后调用trimToSize方法， 刚方法就是将原char数组进行了一次copy，copy了一个maxSize大小的数组。这样即就是每次格式化之后会进行一次判断，如果对象ThreadLocal stringbuilder对象太大会将该对象重新copy一个固定大小，避免老版本出现OOM问题。 "
    }, {
    "id": 77,
    "url": "http://localhost:4000/index.php/2019/09/dubbo-interview/",
    "title": "Dubbo面试大纲",
    "body": "2019/09/07 - Dubbo: 简介: 本篇文章不是进行详细的Dubbo实现以及原理分析的文章，适用于用过Dubbo，对Dubbo有一定了解准备面试的小伙伴阅读。下面列的一些点，如果能在面试时候说到，那面试官肯定觉得不错了。 服务暴露1. 从xml读取ServiceBean配置，订阅了spring容器上下文刷新事件进行export动作2. 暴露过程中，如果是延迟暴露，则启动一个线程，延迟delay时长在进行doExport动作3. 会遍历所有的协议，所有的url进行暴露。（这也就是dubbo支持多协议多注册中心）4. 接下来就是一系列的构建url操作（获取ip，端口，提供方法等）5. 将bean进行一个代理（最终调用就不是通过反射调用）换成一个Invoker对象6. 将Invoker对象去注册中心上进行export动作  本地进行暴露，主要就是根据传输层协议扩展点启动一个netty服务，监听一个端口，返回一个exporter对象 将提供者url信息注册到zookeeper，并且监听provider下目录数据的变化服务引用1. 从xml读取ReferenceBean配置，ReferenceBean实现了FactoryBean接口，会调用getObject进行引用ref2. 通过注册中心想provider目录下的consumers目录下注册本机消费者地址，同时订阅provider下providers、configurators、routers目录数据变化3. 通过获取到provider的url，将提供者的url列表转换成invoker列表– 转换的过程中，每一个url会初始化创建一个netty新连接，以及开启心跳 4. 最终将多个invoker，封装成一个invoker对外使用，封装出来的invoker就继承了集群，负载均衡，容错等功能5. 最后将ReferenceBean进行一个代理，传入上面获取的invoker 服务调用 消费方调用provider方法，会进入到invoker. invoke方法，判断是否走mock，以及集群，容错，负载，在经过一系列的filter，最终调用到具体的一个invoker对象。通过ref时候的client连接向服务端发送一个请求。consumer :MockClusterInvoker-&gt;FailoverClusterInvoke-&gt;ListenerInvokerWrapper-&gt;ProtocolFilterWrapper-&gt;&lt;br&gt;&lt;/br&gt;ConsumerTraceFilter-&gt;InvokeResultLogFilter-&gt;FutureFilter-&gt;MonitorFilter-&gt;DubboInvoker 提供方接受到请求后，进行消息解码，消息转换成Invocation对象，从exporterMap中获取到exporter和Invoker对象，根据方法名调用provider方法，得到返回结果返回SPI: 1. 普通扩展点2. 自适应扩展点3. wrapper扩站点4. 自动激活扩展点 负载均衡-LoadBalance:  基于权重的随机（默认负载均衡策略）。首先判断权重是否都相同，如果都相同则直接随机选取，如果权重不一样，则根据权重得到一个总和，遍历来确定某个提供者 基于权重的轮询。同样的首先判断权重是否都相同，如果都相同则根据序号取模轮询，如果不同则序号对最大权重取模得到当前权重，遍历获得比当前权重大的集合在轮询 最少活跃连接数。为每个提供者维护了一个活跃连接数值，获得最少的活跃连接数列表，然后随机取值。 一致性hash。默认一个提供者对应的160个虚拟节点集群-Cluster:  失败转移/失败重试（failover）默认策略）。当调用失败后，根据配置重试次数重新选取另一个提供者进行调用，直至成功或者最大重试次数 可用（available）。遍历所有提供者，只要一个可用就返回 广播（broadcast）。遍历所有提供者，所有都调用一次 失败降级（failback）。调用失败降级，后台记录失败请求，定时重发，适用消息通知操作 快速失败（failfast）。调用失败后，直接报错 失败安全（failsafe）。调用失败后，降级，只记录失败日志，可用户写入审计日志 并行调用（forking）。并行调用，只要有一个成功就返回，通常适用于实时性要求较高场景，但会浪费更多服务资源使用dubbo过程中遇到的坑:  使用(2. 5. 3)时候，异步调用存在传递，A调B异步调用，B里面去调用C的时候也变成异步调用，拿到是NULL解决：在B里面手动调用从RpcContext attachements里面删除异步调用key新版本解决这个问题，ContextFilter里面删除了异步调用KEY 版本：（2. 6. 5）dubbo优雅关闭，spring容器关闭了，dubbo可能还未关闭，造成dubbo请求去获取redis连接时候报连接池已经关闭，报错。解决：利用spring关闭提供的Lifecycle接口start, stop钩子，执行时机在spring关闭destroyBean之前，这样等dubbo关闭了spring在关闭利用spring关闭提供的ContextCloseEvent事件 使用(2. 5. 3)时候，Provider方在ContextFilter之前如果自己设置参数到RpcContext#attachements中，到后面就没有了，经过ContextFilter就被覆盖了2. 6. 5相较于2. 5. 3 diff: 1. 替换zkClient为Apache Curator2. 增加QOS模块3. 外部化配置4. ServiceConfig hostToRegistry 不好的点:  很多兼容的代码，和很多重复的判断，可以去掉精简使用到设计模式：: 1. 模版模式2. 代理模式3. 装饰器模式 1. SPI ExtensionLoader2. ServiceConfig export服务暴露2. ReferenceConfig refer服务引用3. 服务一次调用过程 provider接收请求处理类流程:NettyHandler-&gt;MultiMessageHandler-&gt;HeartbeatHandler-&gt;AllChannelHandler-&gt;DecodeHandler-&gt;HeaderExchangeHandler-&gt;DubboProtocol(requestHandler) consumer filter:MockClusterInvoker-&gt;FailoverClusterInvoke-&gt;ListenerInvokerWrapper-&gt;ProtocolFilterWrapper-&gt;ConsumerTraceFilter-&gt;InvokeResultLogFilter-&gt;FutureFilter-&gt;MonitorFilter-&gt;DubboInvoke "
    }, {
    "id": 78,
    "url": "http://localhost:4000/index.php/2019/09/pt-online-schema-change-introduction/",
    "title": "MySQL手记10 &#8212; pt-online-schema-change使用简介",
    "body": "2019/09/06 -  1. 功能介绍：pt-online-schema-change，即pt-osc，目的为在alter操作更改表结构的时候不用长时间锁定表，执行alter的时候不会阻塞写和读取操作。 12注意：执行这个工具的时候 **必须做好备份** ，操作之前详细读一下官方文档[pt-online-schema-change](https://www. percona. com/doc/percona-toolkit/3. 0/pt-online-schema-change. html  pt-online-schema-change ) 2. 工作原理根据pt-osc在执行时打印的日志，可以大致了解到其工作原理：1. 创建新表，并在新表上变更2. 从原表中copy原始数据到表结构修改后的表 12在copy数据的过程中，任何在原表的更新操作都会更新到新表，因为这个工具在会在原表上创建触发器，触发器会将在原表上更新的内容更新到新表。**如果表中已经定义了其它触发器，这个工具就不能工作了！**3. 当数据copy完成以后就会将原表移走，用新表代替原表，默认动作是将原表drop掉，drop操作很危险，需要按照实际情况评估。 在rename的过程，会短暂的锁表，为了得到全局的数据一致。 drop表会消耗大量的IO，可以通过如下方式解决： （1）MySQL安全删除大表drop table （2）先把老的表数据进行归档，再进行drop删除老的表 3. 用法及注意事项3. 1 用法: 12pt-online-schema-change [OPTIONS] DSNoptions可以自行查看help，DNS为你要操作的数据库和表。 （1）通常用法介绍: 在线更改表的的引擎，这个尤其在整理innodb表的时候非常有用，示例如下： 12pt-online-schema-change --user=root --password=wang123 --host=localhost --lock-wait-time=120 --alter= ENGINE=InnoDB  D=test,t=tb1 --execute 从下面的日志中可以看出它的执行过程： 123456789101112131415161718192021222324252627282930313233      Altering `test`. `tb1`. . . # 创建新表，并变更      Creating new table. . .       Created new table test. _tb1_new OK.       Altering new table. . .       Altered `test`. `_tb1_new` OK. #创建触发器      Creating triggers. . .    Created triggers OK. #copy数据到新表      Copying approximately 995696 rows. . .       Copied rows OK. #切换新表和老表      Swapping tables. . .       Swapped original and new tables OK. #删除老表      Dropping old table. . .       Dropped old table `test`. `_tb1_old` OK. #删除触发器      Dropping triggers. . .       Dropped triggers OK. Successfully altered `test`. `tb1`. 3. 2 注意事项: 3. 2. 1 删除原表: 在参数配置时，注意是否需要–drop-new-table、–drop-old-table 所以在使用pt-osc工具前，一定要仔细阅读官方文档，并进行测试。 3. 2. 2 变更时候的负载控制: （1）根据主从延时在添加了–check-slave-lag时候，配置–max-lag，延迟低于–max-lag的时候才继续，多个slave可以使用–recursion-method 参数： 指定–recursion-method=”dsn=D=database,t=dsns” 123456789CREATE TABLE if not exists `dsns`(  `id` int(11) NOT NULL AUTO_INCREMENT,  `parent_id` int(11) DEFAULT NULL,  `dsn` varchar(255) NOT NULL,  PRIMARY KEY(`id`) );INSERT INTO dsns(parent_id , dsn) VALUES (1, 'h=10. 10. 1. 16,u=*,p=*,P=3306');INSERT INTO dsns( parent_id , dsn) VALUES (1, 'h=10. 10. 1. 17,u=*,p=*,P=3306');（2）根据活跃连接数–max-load=： Examine SHOW GLOBAL STATUS after every chunk, and pause if any status variables are higher than their thresholds (default Threads_running=25) 根据 SHOW GLOBAL STATUS去判断Threads_running的大小，超过阈值，则pt-osc进程暂停。 3. 2. 3 变更主键: 例如需要更高联合主键为一个id自增主键时，应在一个alter中进行如下操作： a. 删除复合主键定义 b. 添加新的自增主键 c. 原复合主键字段，修改成唯一索引在c中，修改成唯一索引的原因： percona手册里有两个地方对修改主键进行了特殊注解： –alter 和 –[no]check-alter A notable exception is when a PRIMARY KEY or UNIQUE INDEX is being created from existing columns as part of the ALTER clause; in that case it will use these column(s) for the DELETE trigger. 123DROP PRIMARY KEYIf –alter contain DROP PRIMARY KEY (case- and space-insensitive), a warning is printed and the tool exits unless –dry-run is specified. Altering the primary key can be dangerous, but the tool can handle it. The tool’s triggers, particularly the DELETE trigger, are most affected by altering the primary key because the tool prefers to use the primary key for its triggers. You should first run the tool with –dry-run and –print and verify that the triggers are correct. pt-online-schema-change会在原表t1上创建 AFTER DELETE/UPDATE/INSERT 三个触发器，而对于主键的操作，会影响delete触发器，因为触发器依赖于主键。 123CREATE TRIGGER `pt_osc_confluence_sbtest3_del` AFTER DELETE ON `confluence`. `sbtest3` FOR EACH ROW DELETE IGNORE FROM `confluence`. `_sbtest3_new` WHERE `confluence`. `_sbtest3_new`. `id` = OLD. `id` AND `confluence`. `_sbtest3_new`. `k` = OLD. `k`注：sbtest3表上以(id,k)作为复合主键 所以，如果id或k列上没有索引，这个删除的代价非常高，所以一定要同时添加复合（唯一）索引 (id,k) 。如果使用pt-osc去修改删除主键，务必同时添加原主键为 UNIQUE KEY，否则很有可能导致性能问题。 123而对于INSERT,UPDATE的触发器，依然是 **REPLACE INTO** 语法，因为它采用的是先插入，如果违反主键或唯一约束，则根据主键或意义约束删除这条数据，再执行插入。  (**但是注意不能依赖于新表的主键递增，因为如果原表有update，新表就会先插入这一条，导致id与原表记录所在顺序不一样**）3. 2. 4 变更主键介绍: (1)dry-run: 12$ pt-online-schema-change --user=user--password=userpwd --host=10. 10. 10. 34 --alter  DROP PRIMARY KEY,add column pk int auto_increment primary key,add unique key uk_id_k(id,k)  D=confluence,t=sbtest3--print --dry-run部分日志如下所示 123456789101112131415161718--alter contains 'DROP PRIMARY KEY'.  Dropping and altering the primary key can be dangerous, ** especially if the original table does not have other unique indexes. **  ==&gt;注意 dry-run的输出ALTER TABLE `confluence`. `_sbtest3_new` DRO PPRIMARY KEY, add column pk int auto_increment primary key, add unique key uk_id_k(id,k)Altered `confluence`. `_sbtest3_new` OK. Using original table index PRIMARY for the DELETE trigger instead of new table index PRIMARY because ==&gt;使用原表主键值判断the new table index uses column pk which does not exist in the original table. CREATE TRIGGER `pt_osc_confluence_sbtest3_del` AFTER DELETEON `confluence`. `sbtest3` FOR EACH ROW DELETE IGNORE FROM `confluence`. `_sbtest3_new`WHERE `confluence`. `_sbtest3_new`. `id` = OLD. `id` AND `confluence`. `_sbtest3_new`. `k` = OLD. `k`(2)主键有0值: 主键有0值时，需要注意 pt-online-schema-change会设置 SQL_MODE中NO_AUTO_VALUE_ON_ZERO！！！LP #1709650: pt-online-schema-change eating portion of a table 3. 4 相关报错及解决方案: 3. 4. 1 大表变更: 在对大表进行结构变更时，报错退出： pt-online-schema-change 3. 0. 4 MySQL 5. 7. 17 执行语句为： 12pt-online-schema-change --alter  add column addr varchar(200)  --print --charset utf8 --chunk-size=50000 --max-load Threads_running=100 --recurse=1 --alter-foreign-keys-method=none --force --execute --statistics --max-lag 3. 000000 --noversion-check --recursion-method=processlist --progress percentage,1 D=osc,t=test报错信息如下： 123456789101112131415161718. . . . . . Copying `osc`. `test`: 34% 02:05:40 remain**Exiting on SIGHUP. **Not dropping triggers because the tool was interrupted.  To drop the triggers, execute:DROP TRIGGER IF EXISTS `osc`. `pt_osc_osc_test_del`DROP TRIGGER IF EXISTS `osc`. ` pt_osc_osc_test_upd`DROP TRIGGER IF EXISTS `osc`. ` pt_osc_osc_test_ins`Not dropping the new table `osc`. `_test_new` because the tool was interrupted.  To drop the new table, execute:DROP TABLE IF EXISTS `osc`. `_test_new`;由于没有具体的报错信息，只有一个：** Exiting on SIGHUP. ** 解决猜测可能是由于资源不够导致的，因为毕竟都已经执行到了：Copying osc. test: 34% 02:05:40 remain —-&gt;所以调整Threads_running=50，再次进行测试，没有再出现这个问题，done! 即如果遇到此类问题，可能是由于资源不够了，可以降低变更时候的工作负载。 欢迎关注公众号：朔的话： "
    }, {
    "id": 79,
    "url": "http://localhost:4000/index.php/2019/09/mysql-mvcc-phantom-read/",
    "title": "MySQL中MVCC是否也能防止幻读",
    "body": "2019/09/03 - 前言前段时间，小伙伴问了我一个问题：在RR级别下，MVCC是否也能防止幻读的产生？ 本篇文章主要分析一下这个问题，不重点介绍MVCC（InnoDB Multi-Versioning, 多版本并发控制）和幻读的概念。 MVCC与幻读概念MVCC：将变更的数据行保存为不同的版本，以应对不同的并发线程。 幻读：表述在同一个事务中的连续多次查询，返回不同的结果。例如第二次查询中读取到了第一次查询没有的rows。 Gap锁：A gap lock is a lock on a gap between index records, or a lock on the gap before the first or after the last index record. MVCC防止幻读对于select: 在RR（Repeatable-Read）隔离级别下，第一个线程的select语句，可以通过MVCC，不读取在事务begin后的数据行version，即只有select查询时，可以通过MVCC防止读取到其它线程插入的数据。 对于数据变更DML: 同样在RR隔离级别下，由于DML需要读取到最新的数据版本（也称为：当前读），MVCC只能根据数据版本进行是否能够读取，DML在操作数据时候，则会把其它线程更改的数据也视为符合条件，导致出现DML操作了不该操作的数据，所以不能符合要求。 此时，就需要一个锁来锁住这个间隙，防止出现幻读的现象，这个锁在MySQL中为Gap锁。 Gap锁防止幻读: 在事务中执行DML时，为了防止符合where条件的结果集被改变，所以需要进行加锁，需要根据锁类型的不同（主键索引，非主键索引（又包括唯一索引和普通索引）），加上不同的区间：通用： 符合条件的index需要加next-key，左开右闭区间主键/唯一索引： 等值查询： 只加在必要的行上 区间查询： 向右遍历到不符合条件的index为止普通索引： 等值查询： 按照 通用 的规则，加next-key锁 区间查询： 向右遍历到第一个不满足条件的index，此时next-key退化为gap 通过以上的加锁方式，线程访问的时候，防止其它线程对结果集进行修改，从而达到防止幻读的情况。所以，通常我们说：在RR隔离级别下，采用Gap锁防止幻读的产生。 "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});